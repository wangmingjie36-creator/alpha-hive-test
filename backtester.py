#!/usr/bin/env python3
"""
ğŸ”„ Alpha Hive å›æµ‹åé¦ˆå¾ªç¯ï¼ˆPhase 6ï¼‰

T+1 / T+7 / T+30 è‡ªåŠ¨å›çœ‹é¢„æµ‹åå·®ï¼š
1. ä¿å­˜é¢„æµ‹ï¼šæ¯æ¬¡æ‰«æåå°†èœ‚ç¾¤è¯„åˆ†+æ–¹å‘å†™å…¥ predictions è¡¨
2. å›æµ‹æ£€éªŒï¼šå®šæœŸæ£€æŸ¥åˆ°æœŸçš„é¢„æµ‹ï¼Œç”¨ yfinance è·å–å®é™…æ”¶ç›Šç‡
3. è¯„ä¼°å‡†ç¡®ç‡ï¼šæŒ‰ Agentã€ç»´åº¦ã€æ ‡çš„ç»´åº¦ç»Ÿè®¡æ–¹å‘å‡†ç¡®ç‡
4. æƒé‡è‡ªé€‚åº”ï¼šæ ¹æ®å†å²å‡†ç¡®ç‡è‡ªåŠ¨è°ƒæ•´ 5 ç»´å…¬å¼æƒé‡
"""

import json
import sqlite3
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple

try:
    import yfinance as yf
except ImportError:
    yf = None

from hive_logger import PATHS, get_logger

_log = get_logger("backtester")

DB_PATH = PATHS.db


class PredictionStore:
    """é¢„æµ‹è®°å½•å­˜å‚¨ï¼ˆSQLiteï¼‰"""

    TABLE = "predictions"

    def __init__(self, db_path: str = DB_PATH):
        self.db_path = db_path
        self._init_table()

    def _init_table(self):
        conn = None
        try:
            conn = sqlite3.connect(self.db_path)
            conn.execute(f"""
                CREATE TABLE IF NOT EXISTS {self.TABLE} (
                    id                 INTEGER PRIMARY KEY AUTOINCREMENT,
                    date               TEXT NOT NULL,
                    ticker             TEXT NOT NULL,
                    final_score        REAL NOT NULL,
                    direction          TEXT NOT NULL,
                    price_at_predict   REAL,
                    dimension_scores   TEXT,
                    agent_directions   TEXT,
                    -- æœŸæƒåˆ†æå­—æ®µ
                    options_score      REAL,
                    iv_rank            REAL,
                    put_call_ratio     REAL,
                    gamma_exposure     REAL,
                    flow_direction     TEXT,
                    -- T+1 å›æµ‹
                    price_t1           REAL,
                    return_t1          REAL,
                    correct_t1         INTEGER,
                    checked_t1         INTEGER DEFAULT 0,
                    iv_rank_t1         REAL,
                    -- T+7 å›æµ‹
                    price_t7           REAL,
                    return_t7          REAL,
                    correct_t7         INTEGER,
                    checked_t7         INTEGER DEFAULT 0,
                    -- T+30 å›æµ‹
                    price_t30          REAL,
                    return_t30         REAL,
                    correct_t30        INTEGER,
                    checked_t30        INTEGER DEFAULT 0,
                    created_at         TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE(date, ticker)
                )
            """)
            conn.execute(f"CREATE INDEX IF NOT EXISTS idx_pred_date ON {self.TABLE}(date)")
            conn.execute(f"CREATE INDEX IF NOT EXISTS idx_pred_ticker ON {self.TABLE}(ticker)")
            # è¿ç§»ï¼šå¦‚æœæ—§è¡¨ç¼ºå°‘æœŸæƒå­—æ®µï¼Œæ·»åŠ å®ƒä»¬
            self._migrate_options_columns(conn)
            conn.commit()
        except (sqlite3.Error, OSError) as e:
            _log.warning("é¢„æµ‹è¡¨åˆå§‹åŒ–å¤±è´¥: %s", e)
        finally:
            if conn:
                conn.close()

    def _migrate_options_columns(self, conn):
        """ä¸ºæ—§è¡¨æ·»åŠ æœŸæƒç›¸å…³å­—æ®µï¼ˆå…¼å®¹å·²æœ‰æ•°æ®åº“ï¼‰"""
        new_columns = [
            ("options_score", "REAL"),
            ("iv_rank", "REAL"),
            ("put_call_ratio", "REAL"),
            ("gamma_exposure", "REAL"),
            ("flow_direction", "TEXT"),
            ("iv_rank_t1", "REAL"),
            ("pheromone_compact", "TEXT"),  # NA5: Agent è‡ªè¯„åˆ†å¿«ç…§
        ]
        for col_name, col_type in new_columns:
            try:
                conn.execute(f"ALTER TABLE {self.TABLE} ADD COLUMN {col_name} {col_type}")
            except sqlite3.OperationalError:
                pass  # åˆ—å·²å­˜åœ¨

    def save_prediction(
        self,
        ticker: str,
        final_score: float,
        direction: str,
        price: float,
        dimension_scores: Dict = None,
        agent_directions: Dict = None,
        options_data: Dict = None,
        pheromone_compact: list = None,
    ) -> bool:
        """ä¿å­˜ä¸€æ¡é¢„æµ‹è®°å½•ï¼ˆå«æœŸæƒåˆ†ææ•°æ® + Agent è‡ªè¯„åˆ†å¿«ç…§ï¼‰"""
        conn = None
        opts = options_data or {}
        try:
            conn = sqlite3.connect(self.db_path)
            conn.execute(f"""
                INSERT OR REPLACE INTO {self.TABLE}
                (date, ticker, final_score, direction, price_at_predict,
                 dimension_scores, agent_directions,
                 options_score, iv_rank, put_call_ratio, gamma_exposure, flow_direction,
                 pheromone_compact)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                datetime.now().strftime("%Y-%m-%d"),
                ticker,
                final_score,
                direction,
                price,
                json.dumps(dimension_scores or {}),
                json.dumps(agent_directions or {}),
                opts.get("options_score"),
                opts.get("iv_rank"),
                opts.get("put_call_ratio"),
                opts.get("gamma_exposure"),
                opts.get("flow_direction"),
                json.dumps(pheromone_compact or []),
            ))
            conn.commit()
            return True
        except (sqlite3.Error, OSError, TypeError) as e:
            _log.warning("ä¿å­˜é¢„æµ‹å¤±è´¥ (%s): %s", ticker, e)
            return False
        finally:
            if conn:
                conn.close()

    def get_pending_checks(self, period: str) -> List[Dict]:
        """
        è·å–å¾…å›æµ‹çš„é¢„æµ‹è®°å½•

        period: "t1" / "t7" / "t30"
        """
        days_map = {"t1": 1, "t7": 7, "t30": 30}
        days = days_map.get(period, 7)
        checked_col = f"checked_{period}"

        # ç›®æ ‡æ—¥æœŸï¼šé¢„æµ‹æ—¥ + N å¤© <= ä»Šå¤©
        cutoff = (datetime.now() - timedelta(days=days)).strftime("%Y-%m-%d")

        conn = None
        try:
            conn = sqlite3.connect(self.db_path)
            conn.row_factory = sqlite3.Row
            rows = conn.execute(f"""
                SELECT * FROM {self.TABLE}
                WHERE date <= ? AND {checked_col} = 0
                ORDER BY date ASC
            """, (cutoff,)).fetchall()
            return [dict(r) for r in rows]
        except (sqlite3.Error, OSError) as e:
            _log.warning("è·å–å¾…å›æµ‹è®°å½•å¤±è´¥: %s", e)
            return []
        finally:
            if conn:
                conn.close()

    def update_check_result(
        self, pred_id: int, period: str,
        price: float, ret: float, correct: bool
    ) -> bool:
        """æ›´æ–°å›æµ‹ç»“æœ"""
        conn = None
        try:
            conn = sqlite3.connect(self.db_path)
            conn.execute(f"""
                UPDATE {self.TABLE}
                SET price_{period} = ?, return_{period} = ?,
                    correct_{period} = ?, checked_{period} = 1
                WHERE id = ?
            """, (price, ret, 1 if correct else 0, pred_id))
            conn.commit()
            return True
        except (sqlite3.Error, OSError) as e:
            _log.warning("æ›´æ–°å›æµ‹ç»“æœå¤±è´¥: %s", e)
            return False
        finally:
            if conn:
                conn.close()

    def get_accuracy_stats(self, period: str = "t7", days: int = 90) -> Dict:
        """
        è·å–å‡†ç¡®ç‡ç»Ÿè®¡

        è¿”å›: {
            overall_accuracy, total_checked, correct_count,
            avg_return, by_direction: {bullish: {}, bearish: {}, neutral: {}},
            by_ticker: {NVDA: {}, ...}
        }
        """
        cutoff = (datetime.now() - timedelta(days=days)).strftime("%Y-%m-%d")
        checked_col = f"checked_{period}"
        correct_col = f"correct_{period}"
        return_col = f"return_{period}"

        conn = None
        try:
            conn = sqlite3.connect(self.db_path)
            conn.row_factory = sqlite3.Row

            # æ€»ä½“å‡†ç¡®ç‡
            row = conn.execute(f"""
                SELECT
                    COUNT(*) as total,
                    SUM({correct_col}) as correct,
                    AVG({return_col}) as avg_ret,
                    AVG(final_score) as avg_score
                FROM {self.TABLE}
                WHERE {checked_col} = 1 AND date >= ?
            """, (cutoff,)).fetchone()

            total = row["total"] or 0
            correct = row["correct"] or 0
            overall_acc = correct / total if total > 0 else 0.0

            # æŒ‰æ–¹å‘åˆ†ç»„
            by_direction = {}
            for direction in ["bullish", "bearish", "neutral"]:
                r = conn.execute(f"""
                    SELECT
                        COUNT(*) as total,
                        SUM({correct_col}) as correct,
                        AVG({return_col}) as avg_ret
                    FROM {self.TABLE}
                    WHERE {checked_col} = 1 AND direction = ? AND date >= ?
                """, (direction, cutoff)).fetchone()
                t = r["total"] or 0
                by_direction[direction] = {
                    "total": t,
                    "correct": r["correct"] or 0,
                    "accuracy": (r["correct"] or 0) / t if t > 0 else 0.0,
                    "avg_return": round(r["avg_ret"] or 0, 2),
                }

            # æŒ‰æ ‡çš„åˆ†ç»„
            by_ticker = {}
            rows = conn.execute(f"""
                SELECT
                    ticker,
                    COUNT(*) as total,
                    SUM({correct_col}) as correct,
                    AVG({return_col}) as avg_ret,
                    AVG(final_score) as avg_score
                FROM {self.TABLE}
                WHERE {checked_col} = 1 AND date >= ?
                GROUP BY ticker
                ORDER BY total DESC
            """, (cutoff,)).fetchall()
            for r in rows:
                t = r["total"] or 0
                by_ticker[r["ticker"]] = {
                    "total": t,
                    "correct": r["correct"] or 0,
                    "accuracy": (r["correct"] or 0) / t if t > 0 else 0.0,
                    "avg_return": round(r["avg_ret"] or 0, 2),
                    "avg_score": round(r["avg_score"] or 0, 1),
                }

            return {
                "period": period,
                "days_window": days,
                "overall_accuracy": round(overall_acc, 3),
                "total_checked": total,
                "correct_count": correct,
                "avg_return": round(row["avg_ret"] or 0, 3),
                "avg_score": round(row["avg_score"] or 0, 1),
                "by_direction": by_direction,
                "by_ticker": by_ticker,
            }
        except (sqlite3.Error, OSError, KeyError, TypeError) as e:
            _log.warning("è·å–å‡†ç¡®ç‡ç»Ÿè®¡å¤±è´¥: %s", e)
            return {"overall_accuracy": 0, "total_checked": 0}
        finally:
            if conn:
                conn.close()

    def get_all_predictions(self, days: int = 30) -> List[Dict]:
        """è·å–æœ€è¿‘ N å¤©æ‰€æœ‰é¢„æµ‹"""
        cutoff = (datetime.now() - timedelta(days=days)).strftime("%Y-%m-%d")
        conn = None
        try:
            conn = sqlite3.connect(self.db_path)
            conn.row_factory = sqlite3.Row
            rows = conn.execute(f"""
                SELECT * FROM {self.TABLE}
                WHERE date >= ? ORDER BY date DESC, ticker
            """, (cutoff,)).fetchall()
            return [dict(r) for r in rows]
        except (sqlite3.Error, OSError) as e:
            _log.warning("è·å–é¢„æµ‹åˆ—è¡¨å¤±è´¥: %s", e)
            return []
        finally:
            if conn:
                conn.close()


class Backtester:
    """
    å›æµ‹å¼•æ“ - è‡ªåŠ¨æ£€éªŒé¢„æµ‹å‡†ç¡®ç‡

    å·¥ä½œæµï¼š
    1. save_predictions()ï¼šæ‰«æç»“æŸåä¿å­˜æ‰€æœ‰é¢„æµ‹
    2. run_backtest()ï¼šæ£€æŸ¥åˆ°æœŸçš„é¢„æµ‹ï¼Œè·å–å®é™…ä»·æ ¼ï¼Œè®¡ç®—æ”¶ç›Šç‡
    3. print_report()ï¼šè¾“å‡ºå‡†ç¡®ç‡æŠ¥å‘Š
    4. adapt_weights()ï¼šæ ¹æ®å‡†ç¡®ç‡è°ƒæ•´ 5 ç»´å…¬å¼æƒé‡
    """

    def __init__(self, db_path: str = DB_PATH):
        self.store = PredictionStore(db_path)

    # ==================== ä¿å­˜é¢„æµ‹ ====================

    def save_predictions(self, swarm_results: Dict) -> int:
        """
        å°†èœ‚ç¾¤æ‰«æç»“æœä¿å­˜ä¸ºé¢„æµ‹è®°å½•

        Args:
            swarm_results: {ticker: {final_score, direction, dimension_scores, ...}}

        Returns:
            ä¿å­˜çš„è®°å½•æ•°
        """
        saved = 0
        for ticker, data in swarm_results.items():
            if not isinstance(data, dict):
                continue

            # æ”¶é›†å„ Agent çš„æ–¹å‘ï¼ˆä» QueenDistiller çš„ agent_directions å­—æ®µï¼‰
            agent_dirs = data.get("agent_directions", {})

            # è·å–é¢„æµ‹æ—¶çš„ä»·æ ¼
            price = 0.0
            try:
                if yf:
                    stock = yf.Ticker(ticker)
                    price = stock.fast_info.get("lastPrice", 0)
            except (ConnectionError, TimeoutError, OSError, ValueError, KeyError, AttributeError) as e:
                _log.debug("Price fetch failed for %s: %s", ticker, e)

            # æå–æœŸæƒåˆ†ææ•°æ®ï¼ˆå¦‚æœèœ‚ç¾¤ç»“æœä¸­åŒ…å«ï¼‰
            options_data = data.get("options_data") or {}

            ok = self.store.save_prediction(
                ticker=ticker,
                final_score=data.get("final_score", 5.0),
                direction=data.get("direction", "neutral"),
                price=price,
                dimension_scores=data.get("dimension_scores"),
                agent_directions=agent_dirs,
                options_data=options_data,
                pheromone_compact=data.get("pheromone_compact", []),
            )
            if ok:
                saved += 1

        return saved

    # ==================== æ‰§è¡Œå›æµ‹ ====================

    def run_backtest(self) -> Dict:
        """
        æ‰§è¡Œå›æµ‹æ£€éªŒï¼šæ£€æŸ¥æ‰€æœ‰åˆ°æœŸçš„é¢„æµ‹

        è¿”å›: {t1: {checked, correct}, t7: {...}, t30: {...}}
        """
        # å›æµ‹æ£€éªŒ
        results = {}

        for period in ["t1", "t7", "t30"]:
            pending = self.store.get_pending_checks(period)
            if not pending:
                results[period] = {"checked": 0, "correct": 0, "skipped": 0}
                continue

            days_map = {"t1": 1, "t7": 7, "t30": 30}
            days = days_map[period]
            checked = 0
            correct = 0
            skipped = 0

            # {period.upper()} å›æµ‹

            for pred in pending:
                ticker = pred["ticker"]
                predict_date = pred["date"]
                predict_price = pred.get("price_at_predict", 0)
                direction = pred["direction"]

                if not predict_price or predict_price <= 0:
                    skipped += 1
                    continue

                # è·å– T+N æ—¥çš„å®é™…ä»·æ ¼
                actual_price = self._get_price_at_date(
                    ticker, predict_date, days
                )

                if actual_price is None or actual_price <= 0:
                    skipped += 1
                    continue

                # è®¡ç®—æ”¶ç›Šç‡
                ret = (actual_price - predict_price) / predict_price * 100

                # åˆ¤æ–­æ–¹å‘æ˜¯å¦æ­£ç¡®
                is_correct = self._check_direction(direction, ret)

                self.store.update_check_result(
                    pred["id"], period, actual_price, round(ret, 3), is_correct
                )

                # T+1 æœŸæƒå›éªŒï¼šè®°å½• T+1 çš„ IV Rank å˜åŒ–
                if period == "t1" and pred.get("iv_rank") is not None:
                    self._check_options_t1(pred)

                checked += 1
                if is_correct:
                    correct += 1

            results[period] = {
                "checked": checked,
                "correct": correct,
                "skipped": skipped,
                "accuracy": correct / checked if checked > 0 else 0,
            }

            pass  # å‡†ç¡®ç‡å·²è®¡ç®—

        return results

    def _get_price_at_date(
        self, ticker: str, predict_date: str, days_ahead: int
    ) -> Optional[float]:
        """è·å–é¢„æµ‹æ—¥å N å¤©çš„æ”¶ç›˜ä»·"""
        if yf is None:
            return None

        try:
            target_date = datetime.strptime(predict_date, "%Y-%m-%d") + timedelta(days=days_ahead)
            # å‘åå¤šå–å‡ å¤©ä»¥è¦†ç›–å‘¨æœ«/å‡æ—¥
            end_date = target_date + timedelta(days=5)

            stock = yf.Ticker(ticker)
            hist = stock.history(
                start=target_date.strftime("%Y-%m-%d"),
                end=end_date.strftime("%Y-%m-%d"),
            )

            if hist.empty:
                return None

            # å–ç¬¬ä¸€ä¸ªäº¤æ˜“æ—¥çš„æ”¶ç›˜ä»·
            return float(hist["Close"].iloc[0])

        except (ConnectionError, TimeoutError, OSError, ValueError, KeyError) as e:
            _log.debug("Future price fetch failed for %s +%dd: %s", ticker, days_ahead, e)
            return None

    def _check_options_t1(self, pred: Dict):
        """T+1 æœŸæƒå›éªŒï¼šè·å– T+1 çš„ IV Rank ç”¨äºå¯¹æ¯”"""
        ticker = pred["ticker"]
        try:
            from options_analyzer import OptionsAgent
            agent = OptionsAgent()
            result = agent.analyze(ticker)
            iv_rank_t1 = result.get("iv_rank")

            if iv_rank_t1 is not None:
                conn = None
                try:
                    conn = sqlite3.connect(self.store.db_path)
                    conn.execute(f"""
                        UPDATE {PredictionStore.TABLE}
                        SET iv_rank_t1 = ?
                        WHERE id = ?
                    """, (iv_rank_t1, pred["id"]))
                    conn.commit()
                except (sqlite3.Error, OSError) as e:
                    _log.debug("IV Rank T+1 update failed: %s", e)
                finally:
                    if conn:
                        conn.close()

        except (ImportError, ConnectionError, TimeoutError, OSError,
                ValueError, KeyError, TypeError) as e:
            _log.debug("Options T+1 check skipped for %s: %s", ticker, e)

    def _check_direction(self, direction: str, actual_return: float) -> bool:
        """
        æ£€æŸ¥é¢„æµ‹æ–¹å‘æ˜¯å¦æ­£ç¡®

        è§„åˆ™:
        - bullish: å®é™…æ”¶ç›Š > -1%ï¼ˆå…è®¸å°å¹…å›è°ƒï¼‰
        - bearish: å®é™…æ”¶ç›Š < +1%
        - neutral: å®é™…æ”¶ç›Šåœ¨ Â±3% å†…
        """
        if direction == "bullish":
            return actual_return > -1.0
        elif direction == "bearish":
            return actual_return < 1.0
        else:  # neutral
            return abs(actual_return) < 3.0

    # ==================== å‡†ç¡®ç‡æŠ¥å‘Š ====================

    def print_report(self, days: int = 90) -> str:
        """è¾“å‡ºå®Œæ•´çš„å‡†ç¡®ç‡æŠ¥å‘Š"""
        lines = []
        lines.append("\n" + "=" * 70)
        lines.append("  ğŸ“Š Alpha Hive å›æµ‹å‡†ç¡®ç‡æŠ¥å‘Š")
        lines.append(f"  ğŸ“… ç»Ÿè®¡çª—å£ï¼šæœ€è¿‘ {days} å¤©")
        lines.append("=" * 70)

        for period in ["t1", "t7", "t30"]:
            label = {"t1": "T+1ï¼ˆæ¬¡æ—¥ï¼‰", "t7": "T+7ï¼ˆä¸€å‘¨ï¼‰", "t30": "T+30ï¼ˆä¸€æœˆï¼‰"}
            stats = self.store.get_accuracy_stats(period, days)

            total = stats.get("total_checked", 0)
            if total == 0:
                lines.append(f"\n  [{label[period]}] æš‚æ— æ•°æ®")
                continue

            acc = stats["overall_accuracy"]
            avg_ret = stats["avg_return"]
            lines.append(f"\n  [{label[period]}]")
            lines.append(f"  æ€»ä½“å‡†ç¡®ç‡: {acc*100:.1f}% ({stats['correct_count']}/{total})")
            lines.append(f"  å¹³å‡æ”¶ç›Šç‡: {avg_ret:+.2f}%")
            lines.append(f"  å¹³å‡è¯„åˆ†: {stats.get('avg_score', 0):.1f}/10")

            # æŒ‰æ–¹å‘
            by_dir = stats.get("by_direction", {})
            if by_dir:
                lines.append("  æŒ‰æ–¹å‘:")
                for d, info in by_dir.items():
                    if info["total"] > 0:
                        label_cn = {"bullish": "çœ‹å¤š", "bearish": "çœ‹ç©º", "neutral": "ä¸­æ€§"}.get(d, d)
                        lines.append(
                            f"    {label_cn}: {info['accuracy']*100:.0f}% "
                            f"({info['correct']}/{info['total']}) "
                            f"å¹³å‡æ”¶ç›Š {info['avg_return']:+.2f}%"
                        )

            # æŒ‰æ ‡çš„
            by_ticker = stats.get("by_ticker", {})
            if by_ticker:
                lines.append("  æŒ‰æ ‡çš„:")
                for t, info in sorted(by_ticker.items(), key=lambda x: x[1]["total"], reverse=True):
                    lines.append(
                        f"    {t}: {info['accuracy']*100:.0f}% "
                        f"({info['correct']}/{info['total']}) "
                        f"å¹³å‡æ”¶ç›Š {info['avg_return']:+.2f}%"
                    )

        # æœŸæƒåˆ†æå›éªŒç»Ÿè®¡
        lines.append("\n  [æœŸæƒä¿¡å·å›éªŒ]")
        try:
            conn = sqlite3.connect(self.store.db_path)
            conn.row_factory = sqlite3.Row
            opts_row = conn.execute(f"""
                SELECT COUNT(*) as total,
                       AVG(options_score) as avg_opts_score,
                       AVG(iv_rank) as avg_iv_rank,
                       AVG(put_call_ratio) as avg_pc_ratio
                FROM {PredictionStore.TABLE}
                WHERE options_score IS NOT NULL AND date >= ?
            """, ((datetime.now() - timedelta(days=days)).strftime("%Y-%m-%d"),)).fetchone()

            if opts_row and opts_row["total"] > 0:
                lines.append(f"  æœŸæƒæ•°æ®è®°å½•: {opts_row['total']} æ¡")
                lines.append(f"  å¹³å‡æœŸæƒè¯„åˆ†: {opts_row['avg_opts_score']:.1f}/10")
                lines.append(f"  å¹³å‡ IV Rank: {opts_row['avg_iv_rank']:.1f}")
                lines.append(f"  å¹³å‡ P/C Ratio: {opts_row['avg_pc_ratio']:.2f}")

                # IV Rank å˜åŒ–ï¼ˆT+1ï¼‰
                iv_change_row = conn.execute(f"""
                    SELECT COUNT(*) as cnt,
                           AVG(iv_rank_t1 - iv_rank) as avg_iv_change
                    FROM {PredictionStore.TABLE}
                    WHERE iv_rank IS NOT NULL AND iv_rank_t1 IS NOT NULL AND date >= ?
                """, ((datetime.now() - timedelta(days=days)).strftime("%Y-%m-%d"),)).fetchone()

                if iv_change_row and iv_change_row["cnt"] > 0:
                    lines.append(f"  IV Rank T+1 å‡å€¼å˜åŒ–: {iv_change_row['avg_iv_change']:+.1f}")
            else:
                lines.append("  æš‚æ— æœŸæƒåˆ†ææ•°æ®")

            conn.close()
        except (sqlite3.Error, OSError, KeyError, TypeError) as e:
            lines.append(f"  æœŸæƒå›éªŒæŸ¥è¯¢å¤±è´¥: {e}")

        # æœ€è¿‘é¢„æµ‹åˆ—è¡¨
        recent = self.store.get_all_predictions(days=14)
        if recent:
            lines.append(f"\n  æœ€è¿‘é¢„æµ‹è®°å½• ({len(recent)} æ¡):")
            lines.append(f"  {'æ—¥æœŸ':<12} {'æ ‡çš„':<6} {'è¯„åˆ†':>5} {'æ–¹å‘':<8} "
                         f"{'ä»·æ ¼':>8} {'T+1':>8} {'T+7':>8} {'T+30':>8} {'OPT':>5}")
            lines.append("  " + "-" * 76)

            for p in recent[:20]:
                t1_str = f"{p['return_t1']:+.1f}%" if p.get("checked_t1") else "å¾…æ£€"
                t7_str = f"{p['return_t7']:+.1f}%" if p.get("checked_t7") else "å¾…æ£€"
                t30_str = f"{p['return_t30']:+.1f}%" if p.get("checked_t30") else "å¾…æ£€"
                opt_str = f"{p['options_score']:.0f}" if p.get("options_score") else "-"
                dir_cn = {"bullish": "çœ‹å¤š", "bearish": "çœ‹ç©º", "neutral": "ä¸­æ€§"}.get(
                    p["direction"], p["direction"]
                )
                lines.append(
                    f"  {p['date']:<12} {p['ticker']:<6} "
                    f"{p['final_score']:5.1f} {dir_cn:<8} "
                    f"${p.get('price_at_predict', 0):7.1f} "
                    f"{t1_str:>8} {t7_str:>8} {t30_str:>8} {opt_str:>5}"
                )

        lines.append("\n" + "=" * 70)

        report = "\n".join(lines)
        _log.info(report)
        return report

    # ==================== æƒé‡è‡ªé€‚åº” ====================

    def analyze_self_score_bias(
        self, period: str = "t1", min_samples: int = 5
    ) -> Dict[str, float]:
        """
        NA5ï¼šåˆ†æå„ Agent çš„ self_score ç³»ç»Ÿæ€§åå·®

        åå·®å®šä¹‰ï¼šAgent é¢„æµ‹é”™è¯¯æ—¶ self_score çš„å‡å€¼ - é¢„æµ‹æ­£ç¡®æ—¶ self_score çš„å‡å€¼
          æ­£å€¼ï¼ˆ>0ï¼‰= ç³»ç»Ÿæ€§ä¹è§‚ï¼šé«˜åˆ†æ—¶ç»å¸¸é”™ï¼Œoverconfident
          è´Ÿå€¼ï¼ˆ<0ï¼‰= ç³»ç»Ÿæ€§ä¿å®ˆï¼šä½åˆ†æ—¶åè€Œå¯¹ï¼Œunderconfident
          ~0       = è‡ªè¯„æ ¡å‡†è‰¯å¥½

        è¿”å›: {agent_id_abbrev_8chars: bias_float}ï¼Œæ ·æœ¬ä¸è¶³çš„ Agent è¿”å› 0.0
        """
        # agent å…¨å â†’ ç¼©å†™ï¼ˆpheromone_compact ç”¨ agent_id[:8] æˆªå–ï¼‰
        # æ³¨æ„ï¼šOracleBeeEcho[:8] = "OracleBe"ï¼ˆé "OracleBee"ï¼‰
        agent_abbrevs = {
            "ScoutBeeNova":      "ScoutBee",
            "OracleBeeEcho":     "OracleBe",   # [:8] = "OracleBe"ï¼Œä¸æ˜¯"OracleBee"
            "BuzzBeeWhisper":    "BuzzBeeW",
            "ChronosBeeHorizon": "ChronosB",
            "GuardBeeSentinel":  "GuardBee",
            "RivalBeeVanguard":  "RivalBee",
        }

        bias: Dict[str, float] = {abbrev: 0.0 for abbrev in agent_abbrevs.values()}
        conn = None
        try:
            conn = sqlite3.connect(self.store.db_path)
            conn.row_factory = sqlite3.Row
            cutoff = (datetime.now() - timedelta(days=90)).strftime("%Y-%m-%d")
            rows = conn.execute(f"""
                SELECT pheromone_compact, correct_{period}, return_{period}
                FROM {PredictionStore.TABLE}
                WHERE checked_{period} = 1
                  AND pheromone_compact IS NOT NULL
                  AND date >= ?
            """, (cutoff,)).fetchall()

            # {abbrev: {correct: [self_scores], wrong: [self_scores]}}
            buckets: Dict[str, Dict[str, list]] = {
                a: {"correct": [], "wrong": []} for a in agent_abbrevs.values()
            }

            for row in rows:
                try:
                    compact = json.loads(row["pheromone_compact"] or "[]")
                    correct = bool(row[f"correct_{period}"])
                    ret = row[f"return_{period}"]
                    if ret is None:
                        continue
                    for entry in compact:
                        abbrev = entry.get("a", "")
                        if abbrev in buckets:
                            ss = entry.get("s", 5.0)
                            bucket_key = "correct" if correct else "wrong"
                            buckets[abbrev][bucket_key].append(ss)
                except (json.JSONDecodeError, KeyError, TypeError):
                    continue

            for abbrev, b in buckets.items():
                n_correct = len(b["correct"])
                n_wrong = len(b["wrong"])
                if n_correct + n_wrong < min_samples:
                    continue
                mean_correct = sum(b["correct"]) / n_correct if n_correct else 5.0
                mean_wrong = sum(b["wrong"]) / n_wrong if n_wrong else 5.0
                # ä¹è§‚åå·® = é”™è¯¯æ—¶å‡å€¼ - æ­£ç¡®æ—¶å‡å€¼ï¼ˆè¶Šå¤§è¡¨ç¤ºè¶Šå€¾å‘åœ¨é”™è¯¯æ—¶ç»™é«˜åˆ†ï¼‰
                bias[abbrev] = round(mean_wrong - mean_correct, 3)

        except (sqlite3.Error, OSError) as e:
            _log.warning("self_score åå·®åˆ†æå¤±è´¥: %s", e)
        finally:
            if conn:
                conn.close()

        _log.info("Agent self_score åå·®åˆ†æ: %s", {k: f"{v:+.3f}" for k, v in bias.items()})
        return bias

    def adapt_weights(self, min_samples: int = 10, period: str = "t7") -> Optional[Dict]:
        """
        æ ¹æ®å†å²æ–¹å‘å‡†ç¡®ç‡è‡ªåŠ¨è°ƒæ•´ 5 ç»´å…¬å¼æƒé‡

        ä¼˜å…ˆä½¿ç”¨ T+7ï¼ˆæ›´å¯é ï¼‰ï¼ŒT+7 æ ·æœ¬ä¸è¶³æ—¶è‡ªåŠ¨é™çº§åˆ° T+1ï¼š
        - T+7ï¼šå¹³æ»‘å› å­ 80% æ–°æƒé‡ï¼ˆå……åˆ†ä¿¡ä»»ï¼‰
        - T+1ï¼šå¹³æ»‘å› å­ 50% æ–°æƒé‡ï¼ˆT+1 å™ªå£°æ›´å¤§ï¼Œä¿å®ˆè°ƒæ•´ï¼‰

        è§„åˆ™ï¼š
        - æŒ‰ Agent æ–¹å‘ vs å®é™…æ”¶ç›Šè®¡ç®—å„ç»´åº¦å‡†ç¡®ç‡
        - å‡†ç¡®ç‡^2 å½’ä¸€åŒ–åä½œä¸ºæ–°æƒé‡ï¼ˆæ”¾å¤§é«˜å‡†ç¡®ç‡ç»´åº¦çš„ä¼˜åŠ¿ï¼‰
        - æœ€ä½æ ·æœ¬æ•°ï¼šmin_samplesï¼ˆT+7 é»˜è®¤ 10ï¼ŒT+1 å¯ç”¨ 5ï¼‰

        è¿”å›: {dimension: new_weight} æˆ– Noneï¼ˆæ ·æœ¬ä¸è¶³ï¼‰
        """
        # Agent â†’ ç»´åº¦æ˜ å°„ï¼ˆä¸ pheromone_board.AGENT_DIMENSIONS ä¿æŒä¸€è‡´ï¼‰
        agent_dim_map = {
            "ScoutBeeNova":      "signal",
            "OracleBeeEcho":     "odds",
            "BuzzBeeWhisper":    "sentiment",
            "ChronosBeeHorizon": "catalyst",
            "GuardBeeSentinel":  "risk_adj",
        }

        # é»˜è®¤æƒé‡ï¼ˆæ¥è‡ª configï¼Œæ­¤å¤„ä½œä¸ºå…œåº•ï¼‰
        _fallback_weights = {"signal": 0.30, "catalyst": 0.20, "sentiment": 0.20, "odds": 0.15, "risk_adj": 0.15}
        try:
            from config import EVALUATION_WEIGHTS
            base = {k: v for k, v in EVALUATION_WEIGHTS.items() if k in agent_dim_map.values()}
            # Bug 9: è¡¥å…¨ config ä¸­å¯èƒ½ç¼ºå¤±çš„ç»´åº¦ï¼Œé¿å…åç»­ KeyError
            default_weights = {dim: base.get(dim, _fallback_weights[dim]) for dim in _fallback_weights}
        except (ImportError, AttributeError):
            default_weights = _fallback_weights

        # T+1 å¹³æ»‘å› å­æ›´ä¿å®ˆï¼ˆT+1 å™ªå£°å¤§ï¼Œä¸èƒ½å¤§å¹…æ”¹å˜æƒé‡ï¼‰
        new_weight_ratio = 0.8 if period == "t7" else 0.5

        # è·å–æ¯ä¸ªç»´åº¦çš„å‡†ç¡®ç‡
        dim_accuracy = {}
        total_samples = 0

        conn = None
        try:
            conn = sqlite3.connect(self.store.db_path)
            conn.row_factory = sqlite3.Row

            for agent_name, dim in agent_dim_map.items():
                rows = conn.execute(f"""
                    SELECT agent_directions, return_{period}, direction
                    FROM {PredictionStore.TABLE}
                    WHERE checked_{period} = 1 AND agent_directions IS NOT NULL
                    AND date >= ?
                """, ((datetime.now() - timedelta(days=90)).strftime("%Y-%m-%d"),)).fetchall()

                correct = 0
                checked = 0
                for row in rows:
                    try:
                        dirs = json.loads(row["agent_directions"])
                        agent_dir = dirs.get(agent_name)
                        if not agent_dir:
                            continue
                        ret = row[f"return_{period}"]
                        if ret is None:
                            continue
                        checked += 1
                        if self._check_direction(agent_dir, ret):
                            correct += 1
                    except (json.JSONDecodeError, KeyError, TypeError, ValueError) as e:
                        _log.debug("Agent direction parse error: %s", e)
                        continue

                if checked >= min_samples:
                    dim_accuracy[dim] = correct / checked
                    total_samples += checked
                else:
                    dim_accuracy[dim] = 0.5  # æ ·æœ¬ä¸è¶³æ—¶ç”¨ä¸­æ€§ 50%

        except (sqlite3.Error, OSError, json.JSONDecodeError, KeyError, TypeError) as e:
            _log.warning("æƒé‡è‡ªé€‚åº”å¤±è´¥ (%s): %s", period, e)
            return None
        finally:
            if conn:
                conn.close()

        if total_samples < min_samples:
            _log.debug("æƒé‡è‡ªé€‚åº”ï¼š%s æ ·æœ¬ä¸è¶³ (%d < %d)", period, total_samples, min_samples)
            return None

        # è®¡ç®—æ–°æƒé‡ï¼šå‡†ç¡®ç‡^2 å½’ä¸€åŒ–ï¼ˆæ”¾å¤§é«˜å‡†ç¡®ç‡ç»´åº¦çš„ä¼˜åŠ¿ï¼‰
        raw = {dim: max(0.05, acc ** 2) for dim, acc in dim_accuracy.items()}
        total_raw = sum(raw.values())
        new_weights = {dim: round(v / total_raw, 3) for dim, v in raw.items()}

        # å¹³æ»‘è¿‡æ¸¡ï¼šnew_weight_ratio Ã— æ–°æƒé‡ + (1-ratio) Ã— é»˜è®¤æƒé‡
        smoothed = {}
        for dim in default_weights:
            old_w = default_weights[dim]
            new_w = new_weights.get(dim, old_w)
            smoothed[dim] = round(old_w * (1 - new_weight_ratio) + new_w * new_weight_ratio, 3)

        # å½’ä¸€åŒ–ç¡®ä¿æ€»å’Œ = 1.0
        s = sum(smoothed.values())
        smoothed = {dim: round(v / s, 3) for dim, v in smoothed.items()}

        # NA5ï¼šself_score åå·®æ ¡æ­£
        # è‹¥æŸ Agent ç³»ç»Ÿæ€§ä¹è§‚ï¼ˆé«˜åˆ†æ—¶ç»å¸¸é”™ï¼‰ï¼Œå°å¹…ä¸‹è°ƒå…¶ç»´åº¦æƒé‡
        # è§„åˆ™ï¼š|bias| > 0.5 æ‰ä¿®æ­£ï¼Œæœ€å¤§ä¿®æ­£å¹…åº¦ Â±10%ï¼Œé¿å…éœ‡è¡
        dim_to_abbrev = {
            "signal":    "ScoutBee",
            "odds":      "OracleBe",   # OracleBeeEcho[:8] = "OracleBe"
            "sentiment": "BuzzBeeW",
            "catalyst":  "ChronosB",
            "risk_adj":  "GuardBee",
        }
        try:
            bias_map = self.analyze_self_score_bias(period=period, min_samples=3)
            bias_applied = {}
            for dim, abbrev in dim_to_abbrev.items():
                bias = bias_map.get(abbrev, 0.0)
                if abs(bias) > 0.5:
                    # ä¹è§‚åå·®ï¼ˆbias>0ï¼‰â†’ é™æƒï¼›ä¿å®ˆåå·®ï¼ˆbias<0ï¼‰â†’ å°å¹…å‡æƒ
                    correction = -bias * 0.05   # æ¯1åˆ†åå·®è°ƒæ•´ 5%ï¼Œæœ€å¤§ Â±10%
                    correction = max(-0.10, min(0.05, correction))
                    smoothed[dim] = round(smoothed[dim] * (1.0 + correction), 3)
                    bias_applied[dim] = round(correction, 4)
            if bias_applied:
                # å†æ¬¡å½’ä¸€åŒ–
                s2 = sum(smoothed.values())
                smoothed = {dim: round(v / s2, 3) for dim, v in smoothed.items()}
                _log.info("NA5 self_score åå·®æ ¡æ­£: %s", bias_applied)
        except (sqlite3.Error, OSError, json.JSONDecodeError, KeyError, TypeError, ValueError, ZeroDivisionError) as e:
            _log.debug("self_score åå·®æ ¡æ­£è·³è¿‡ï¼ˆæ ·æœ¬ä¸è¶³æˆ–å¼‚å¸¸ï¼‰: %s", e)

        _log.info(
            "æƒé‡è‡ªé€‚åº”ï¼ˆ%sï¼Œ%d æ ·æœ¬ï¼‰: %s | å„ç»´åº¦å‡†ç¡®ç‡: %s",
            period, total_samples,
            {k: f"{v:.3f}" for k, v in smoothed.items()},
            {k: f"{v:.1%}" for k, v in dim_accuracy.items()},
        )

        self._save_adapted_weights(smoothed, dim_accuracy, total_samples, period)
        return smoothed

    def _save_adapted_weights(
        self, weights: Dict, accuracy: Dict, samples: int, period: str = "t7"
    ):
        """å°†è‡ªé€‚åº”æƒé‡æŒä¹…åŒ–åˆ° SQLite"""
        conn = None
        try:
            conn = sqlite3.connect(self.store.db_path)
            conn.execute("""
                CREATE TABLE IF NOT EXISTS adapted_weights (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    date TEXT NOT NULL,
                    weights TEXT NOT NULL,
                    accuracy TEXT NOT NULL,
                    sample_count INTEGER,
                    period TEXT DEFAULT 't7',
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)
            # è¿ç§»æ—§è¡¨ç¼ºå°‘ period åˆ—
            try:
                conn.execute("ALTER TABLE adapted_weights ADD COLUMN period TEXT DEFAULT 't7'")
            except sqlite3.OperationalError:
                pass
            conn.execute("""
                INSERT INTO adapted_weights (date, weights, accuracy, sample_count, period)
                VALUES (?, ?, ?, ?, ?)
            """, (
                datetime.now().strftime("%Y-%m-%d"),
                json.dumps(weights),
                json.dumps({k: round(v, 3) for k, v in accuracy.items()}),
                samples,
                period,
            ))
            conn.commit()
        except (sqlite3.Error, OSError, TypeError) as e:
            _log.warning("ä¿å­˜è‡ªé€‚åº”æƒé‡å¤±è´¥: %s", e)
        finally:
            if conn:
                conn.close()

    @staticmethod
    def load_adapted_weights(db_path: str = DB_PATH) -> Optional[Dict]:
        """
        åŠ è½½æœ€è¿‘çš„è‡ªé€‚åº”æƒé‡ï¼ˆä¾› QueenDistiller ä½¿ç”¨ï¼‰

        ä¼˜å…ˆåŠ è½½ T+7 æƒé‡ï¼ˆæ›´å¯é ï¼‰ï¼Œå…¶æ¬¡åŠ è½½ T+1 æƒé‡ï¼ˆæ—©æœŸé™çº§ï¼‰ã€‚
        è¿”å›çš„æƒé‡å·²é™„åŠ  _meta å­—æ®µï¼ŒQueenDistiller ä¼šè‡ªåŠ¨å¿½ç•¥æœªçŸ¥ keyã€‚

        Returns:
            {signal: 0.xx, ..., _meta: {period, samples}} æˆ– None
        """
        conn = None
        try:
            conn = sqlite3.connect(db_path)
            # ä¼˜å…ˆå– T+7ï¼Œå†å– T+1
            row = conn.execute("""
                SELECT weights, sample_count, period
                FROM adapted_weights
                WHERE sample_count >= 3
                ORDER BY
                    CASE period WHEN 't7' THEN 0 WHEN 't1' THEN 1 ELSE 2 END,
                    created_at DESC
                LIMIT 1
            """).fetchone()

            if row:
                weights = json.loads(row[0])
                period = row[2] or "t7"
                samples = row[1]
                _log.info("åŠ è½½è‡ªé€‚åº”æƒé‡ï¼ˆ%sï¼Œ%d æ ·æœ¬ï¼‰: %s", period, samples, weights)
                return weights
            return None
        except (sqlite3.Error, OSError, json.JSONDecodeError, KeyError) as e:
            _log.debug("Adapted weights load failed: %s", e)
            return None
        finally:
            if conn:
                conn.close()


# ==================== ä¾¿æ·å‡½æ•° ====================

def run_full_backtest(swarm_results: Dict = None) -> Dict:
    """
    æ‰§è¡Œå®Œæ•´å›æµ‹æµç¨‹

    1. ä¿å­˜æ–°é¢„æµ‹ï¼ˆå¦‚æœ‰ï¼‰
    2. æ£€æŸ¥åˆ°æœŸé¢„æµ‹
    3. è¾“å‡ºæŠ¥å‘Š
    4. å°è¯•æƒé‡è‡ªé€‚åº”

    è¿”å›: {backtest_results, accuracy_stats, adapted_weights}
    """
    bt = Backtester()

    # 1. ä¿å­˜æ–°é¢„æµ‹
    if swarm_results:
        bt.save_predictions(swarm_results)

    # 2. å›æµ‹åˆ°æœŸé¢„æµ‹
    backtest_results = bt.run_backtest()

    # 3. å‡†ç¡®ç‡æŠ¥å‘Š
    bt.print_report()

    # 4. æƒé‡è‡ªé€‚åº”
    adapted = bt.adapt_weights(min_samples=10)

    return {
        "backtest_results": backtest_results,
        "adapted_weights": adapted,
    }
