#!/usr/bin/env python3
"""
ğŸ Alpha Hive èœ‚ç¾¤ Agent ç³»ç»Ÿ - 6 ä¸ªè‡ªæ²»å·¥èœ‚ + QueenDistiller
å®ç°çœŸæ­£çš„å¤š Agent å¹¶è¡Œåä½œä¸ä¿¡æ¯ç´ é©±åŠ¨å†³ç­–

5 ç»´åŠ æƒè¯„åˆ†å…¬å¼ï¼ˆCLAUDE.mdï¼‰ï¼š
  Opportunity Score = 0.30Ã—Signal + 0.20Ã—Catalyst + 0.20Ã—Sentiment + 0.15Ã—Odds + 0.15Ã—RiskAdj

Agent â†’ ç»´åº¦æ˜ å°„ï¼š
  Signal   (0.30) = ScoutBeeNova     (SEC Form4/13F + æ‹¥æŒ¤åº¦)
  Catalyst (0.20) = ChronosBeeHorizon (è´¢æŠ¥/äº‹ä»¶å‚¬åŒ–å‰‚)
  Sentiment(0.20) = BuzzBeeWhisper   (yfinance åŠ¨é‡ + æˆäº¤é‡æƒ…ç»ª)
  Odds     (0.15) = OracleBeeEcho    (æœŸæƒ IV/P-C Ratio)
  RiskAdj  (0.15) = GuardBeeSentinel (äº¤å‰éªŒè¯ + æ‹¥æŒ¤åº¦æŠ˜æ‰£)
  ML è¾…åŠ©          = RivalBeeVanguard (ML é¢„æµ‹ï¼Œä¸ç›´æ¥å‚ä¸ 5 ç»´å…¬å¼ï¼Œä½œä¸ºé¢å¤–åŠ å‡åˆ†)
"""

from abc import ABC, abstractmethod
from typing import Dict, List, Optional
from pheromone_board import PheromoneBoard, PheromoneEntry
import json


# ==================== å·¥å…·å‡½æ•° ====================

# yfinance æ•°æ®ç¼“å­˜ï¼ˆåŒä¸€æ¬¡æ‰«æå†…å…±äº«ï¼Œé¿å…é‡å¤è¯·æ±‚ï¼‰
import time as _time
import threading as _threading

from resilience import yfinance_limiter, yfinance_breaker
from models import DataQualityChecker as _DQChecker

_yf_cache: Dict[str, Dict] = {}
_yf_cache_ts: Dict[str, float] = {}
_yf_lock = _threading.Lock()
_YF_CACHE_TTL = 120  # ç¼“å­˜ 2 åˆ†é’Ÿ
_YF_MAX_RETRIES = 2


def _fetch_stock_data(ticker: str) -> Dict:
    """
    ä» yfinance æ‹‰å–è‚¡ç¥¨å®æ—¶æ•°æ®ï¼ˆä»·æ ¼ã€åŠ¨é‡ã€æˆäº¤é‡ç­‰ï¼‰
    å†…ç½®ç¼“å­˜ï¼ˆ2 åˆ†é’Ÿ TTLï¼‰+ RateLimiter + CircuitBreaker + æŒ‡æ•°é€€é¿é‡è¯•
    å¤±è´¥æ—¶è¿”å›é»˜è®¤å€¼ï¼Œä¸ä¼šæŠ›å‡ºå¼‚å¸¸
    """
    # æ£€æŸ¥ç¼“å­˜
    cached = _yf_cache.get(ticker)
    if cached and (_time.time() - _yf_cache_ts.get(ticker, 0)) < _YF_CACHE_TTL:
        return cached

    data = {
        "price": 100.0,
        "momentum_5d": 0.0,
        "avg_volume": 0,
        "volume_ratio": 1.0,
        "volatility_20d": 0.0,
    }

    if not yfinance_breaker.allow_request():
        return data

    for attempt in range(_YF_MAX_RETRIES + 1):
        try:
            yfinance_limiter.acquire()
            import yfinance as yf
            t = yf.Ticker(ticker)
            hist = t.history(period="1mo")
            if hist.empty:
                if attempt < _YF_MAX_RETRIES:
                    _time.sleep(1.0 * (2 ** attempt))
                    continue
                return data

            data["price"] = float(hist["Close"].iloc[-1])

            if len(hist) >= 5:
                data["momentum_5d"] = (hist["Close"].iloc[-1] / hist["Close"].iloc[-5] - 1) * 100

            if len(hist) >= 2:
                recent_vol = float(hist["Volume"].iloc[-1])
                avg_vol = float(hist["Volume"].iloc[-20:].mean()) if len(hist) >= 20 else float(hist["Volume"].mean())
                data["avg_volume"] = int(avg_vol)
                data["volume_ratio"] = recent_vol / avg_vol if avg_vol > 0 else 1.0

            if len(hist) >= 20:
                returns = hist["Close"].pct_change().dropna()
                data["volatility_20d"] = float(returns.std() * (252 ** 0.5) * 100)

            # å†™å…¥ç¼“å­˜
            _yf_cache[ticker] = data
            _yf_cache_ts[ticker] = _time.time()
            yfinance_breaker.record_success()
            break

        except Exception as e:
            if attempt < _YF_MAX_RETRIES:
                _time.sleep(1.0 * (2 ** attempt))
            else:
                yfinance_breaker.record_failure()

    return data


# ==================== Agent åŸºç±» ====================

class BeeAgent(ABC):
    """Agent åŸºç±»ï¼šæ‰€æœ‰ Agent å¿…é¡»ç»§æ‰¿æ­¤ç±»"""

    def __init__(self, board: PheromoneBoard, retriever=None):
        self.board = board
        self.retriever = retriever
        # é¢„æ³¨å…¥çš„å…±äº«æ•°æ®ï¼ˆç”±å¤–éƒ¨æ‰¹é‡é¢„å–åæ³¨å…¥ï¼Œé¿å…é‡å¤ API è°ƒç”¨ï¼‰
        self._prefetched_stock: Dict[str, Dict] = {}
        self._prefetched_context: Dict[str, str] = {}

    @abstractmethod
    def analyze(self, ticker: str) -> Dict:
        """
        åˆ†æå•ä¸ªæ ‡çš„

        Returns:
            - score: 0-10 çš„è¯„åˆ†
            - direction: "bullish" / "bearish" / "neutral"
            - discovery: ä¸€å¥è¯æ‘˜è¦
            - source: æ•°æ®æ¥æº
            - dimension: å¯¹åº”çš„ 5 ç»´ç»´åº¦å ("signal"/"catalyst"/"sentiment"/"odds"/"risk_adj")
        """
        pass

    def _publish(self, ticker: str, discovery: str, source: str, score: float, direction: str):
        """å‘å¸ƒå‘ç°åˆ°ä¿¡æ¯ç´ æ¿"""
        entry = PheromoneEntry(
            agent_id=self.__class__.__name__,
            ticker=ticker,
            discovery=discovery,
            source=source,
            self_score=score,
            direction=direction
        )
        self.board.publish(entry)

    def _get_stock_data(self, ticker: str) -> Dict:
        """è·å–è‚¡ç¥¨æ•°æ®ï¼ˆä¼˜å…ˆä½¿ç”¨é¢„å–ç¼“å­˜ï¼Œå›é€€åˆ°ç›´æ¥è¯·æ±‚ï¼‰"""
        if ticker in self._prefetched_stock:
            return self._prefetched_stock[ticker]
        return _fetch_stock_data(ticker)

    def _get_history_context(self, ticker: str) -> str:
        """è·å–å†å²ä¸Šä¸‹æ–‡ï¼ˆä¼˜å…ˆé¢„å–ç¼“å­˜ï¼Œå›é€€åˆ°å®æ—¶æŸ¥è¯¢ï¼‰"""
        if ticker in self._prefetched_context:
            return self._prefetched_context[ticker]
        if not self.retriever:
            return ""
        try:
            if hasattr(self.retriever, 'get_context_for_agent'):
                return self.retriever.get_context_for_agent(
                    ticker, self.__class__.__name__
                )
            from datetime import datetime
            return self.retriever.get_context_summary(ticker, datetime.now().strftime("%Y-%m-%d"))
        except Exception:
            return ""


def prefetch_shared_data(tickers: list, retriever=None) -> Dict:
    """
    æ‰¹é‡é¢„å–æ‰€æœ‰ ticker çš„å…±äº«æ•°æ®ï¼ˆyfinance + VectorMemoryï¼‰ï¼Œ
    é¿å… 6 ä¸ª Agent å„è‡ªé‡å¤è¯·æ±‚ã€‚

    è¿”å›: {"stock_data": {ticker: data}, "contexts": {ticker: str}}
    """
    stock_data = {}
    contexts = {}

    # 1. æ‰¹é‡é¢„å– yfinanceï¼ˆä¸²è¡Œä½†æœ‰å…¨å±€ç¼“å­˜ï¼Œåªè¯·æ±‚ä¸€æ¬¡/tickerï¼‰
    for t in tickers:
        stock_data[t] = _fetch_stock_data(t)

    # 2. æ‰¹é‡é¢„å– VectorMemory ä¸Šä¸‹æ–‡ï¼ˆä¸€æ¬¡æŸ¥è¯¢/tickerï¼Œè€Œé 6 æ¬¡ï¼‰
    if retriever and hasattr(retriever, 'get_context_for_agent'):
        for t in tickers:
            try:
                contexts[t] = retriever.get_context_for_agent(t, "BeeAgent")
            except Exception:
                contexts[t] = ""

    return {"stock_data": stock_data, "contexts": contexts}


def inject_prefetched(agents: list, prefetched: Dict):
    """å°†é¢„å–æ•°æ®æ³¨å…¥æ‰€æœ‰ Agent"""
    for agent in agents:
        agent._prefetched_stock = prefetched.get("stock_data", {})
        agent._prefetched_context = prefetched.get("contexts", {})


# ==================== ScoutBeeNova (Signal ç»´åº¦) ====================

class ScoutBeeNova(BeeAgent):
    """èªæ˜é’±ä¾¦å¯Ÿèœ‚ - SEC Form4/13F å†…å¹•äº¤æ˜“ + æ‹¥æŒ¤åº¦åˆ†æ
    å¯¹åº”ç»´åº¦ï¼šSignal (æƒé‡ 0.30)

    æ•°æ®æºï¼š
    - SEC EDGAR Form 4ï¼ˆå†…å¹•ä¹°å–è®°å½•ï¼Œå…è´¹ APIï¼‰
    - CrowdingDetectorï¼ˆæ‹¥æŒ¤åº¦è¯„ä¼°ï¼‰
    - yfinanceï¼ˆåŠ¨é‡/æˆäº¤é‡ï¼‰

    è¯„åˆ†é€»è¾‘ï¼š
    - å†…å¹•ä¹°å…¥æƒé‡ 60% + æ‹¥æŒ¤åº¦æƒé‡ 40%
    - é«˜ç®¡ä¸»åŠ¨ä¹°å…¥ â†’ å¼ºçƒˆçœ‹å¤šä¿¡å·
    - å¤§è§„æ¨¡å†…å¹•å–å‡º â†’ çœ‹ç©ºä¿¡å·
    """

    def analyze(self, ticker: str) -> Dict:
        try:
            ctx = self._get_history_context(ticker)

            # ---- 1. SEC EDGAR å†…å¹•äº¤æ˜“æ•°æ® ----
            insider_data = None
            insider_score = 5.0
            insider_summary = ""
            try:
                from sec_edgar import get_insider_trades
                insider_data = get_insider_trades(ticker, days=90)
                insider_score = insider_data.get("sentiment_score", 5.0)
                insider_summary = insider_data.get("summary", "")
            except Exception as e:
                insider_summary = f"SEC æ•°æ®ä¸å¯ç”¨: {e}"

            # ---- 2. æ‹¥æŒ¤åº¦åˆ†æï¼ˆçœŸå®æ•°æ®æºï¼‰----
            stock = self._get_stock_data(ticker)

            from crowding_detector import CrowdingDetector
            detector = CrowdingDetector(ticker)

            from real_data_sources import get_real_crowding_metrics
            metrics = get_real_crowding_metrics(ticker, stock, self.board)

            crowding_score, component_scores = detector.calculate_crowding_score(metrics)
            crowding_signal = max(1.0, 10.0 - crowding_score / 10.0)

            # ---- 3. ç»¼åˆè¯„åˆ†ï¼šå†…å¹•äº¤æ˜“ 60% + æ‹¥æŒ¤åº¦ 40% ----
            score = insider_score * 0.6 + crowding_signal * 0.4
            score = max(1.0, min(10.0, score))

            # æ–¹å‘åˆ¤æ–­
            if insider_data and insider_data.get("insider_sentiment") == "bullish":
                direction = "bullish"
            elif insider_data and insider_data.get("insider_sentiment") == "bearish":
                if crowding_score > 50:
                    direction = "bearish"
                else:
                    direction = "neutral"  # å–å‡ºä½†ä¸æ‹¥æŒ¤ï¼Œå¯èƒ½åªæ˜¯è®¡åˆ’æ€§å‡æŒ
            elif crowding_score > 70:
                direction = "bearish"
            elif crowding_score < 30:
                direction = "bullish"
            else:
                direction = "neutral"

            category, _ = detector.get_crowding_category(crowding_score)
            adj_factor = detector.get_adjustment_factor(crowding_score)

            # æ„å»ºå‘ç°æ‘˜è¦
            parts = []
            if insider_data and insider_data.get("total_filings", 0) > 0:
                dollar_sold = insider_data.get("dollar_sold", 0)
                dollar_bought = insider_data.get("dollar_bought", 0)
                if dollar_bought > 0:
                    parts.append(f"å†…å¹•ä¹°å…¥ ${dollar_bought:,.0f}")
                if dollar_sold > 0:
                    parts.append(f"å†…å¹•å–å‡º ${dollar_sold:,.0f}")
                # æ ‡æ³¨é‡è¦äº¤æ˜“
                notable = insider_data.get("notable_trades", [])
                if notable:
                    top = notable[0]
                    parts.append(f"{top['insider']} {top['code_desc']} {top['shares']:,.0f}è‚¡")
            else:
                parts.append("æ— è¿‘æœŸå†…å¹•äº¤æ˜“")

            parts.append(f"æ‹¥æŒ¤åº¦ {crowding_score:.0f}/100ï¼ˆ{category}ï¼‰")
            parts.append(f"åŠ¨é‡ {stock['momentum_5d']:+.1f}%")

            discovery = " | ".join(parts)
            if ctx:
                discovery = f"{discovery} | {ctx}"

            self._publish(ticker, discovery, "sec_edgar+crowding", score, direction)

            # Phase 2: confidence = æ•°æ®å®Œæ•´åº¦ï¼ˆå†…å¹•æ•°æ®å¯ç”¨ + æ‹¥æŒ¤åº¦å¯ç”¨ï¼‰
            confidence = 0.5
            if insider_data and insider_data.get("total_filings", 0) > 0:
                confidence += 0.3
            dq = metrics.get("data_quality", {})
            real_fields = sum(1 for v in dq.values() if v == "real")
            confidence += min(0.2, real_fields * 0.04)
            confidence = min(1.0, confidence)

            return {
                "score": round(score, 2),
                "direction": direction,
                "confidence": round(confidence, 2),
                "discovery": discovery,
                "source": "ScoutBeeNova",
                "dimension": "signal",
                "data_quality": metrics.get("data_quality", {}),
                "details": {
                    "insider": {
                        "sentiment": insider_data.get("insider_sentiment", "neutral") if insider_data else "unknown",
                        "score": insider_score,
                        "filings": insider_data.get("total_filings", 0) if insider_data else 0,
                        "dollar_bought": insider_data.get("dollar_bought", 0) if insider_data else 0,
                        "dollar_sold": insider_data.get("dollar_sold", 0) if insider_data else 0,
                        "notable_trades": (insider_data.get("notable_trades", [])[:3]) if insider_data else [],
                    },
                    "crowding_score": crowding_score,
                    "crowding_signal": round(crowding_signal, 2),
                    "components": component_scores,
                    "adjustment_factor": adj_factor,
                    "momentum_5d": stock["momentum_5d"],
                    "price": stock["price"],
                }
            }

        except Exception as e:
            return {"error": str(e), "source": "ScoutBeeNova", "score": 5.0, "dimension": "signal"}


# ==================== OracleBeeEcho (Odds ç»´åº¦) ====================

class OracleBeeEcho(BeeAgent):
    """å¸‚åœºé¢„æœŸèœ‚ - æœŸæƒåˆ†æ + Polymarket é¢„æµ‹å¸‚åœºèµ”ç‡
    å¯¹åº”ç»´åº¦ï¼šOdds (æƒé‡ 0.15)
    èåˆï¼šæœŸæƒä¿¡å· 60% + Polymarket èµ”ç‡ 40%
    """

    def analyze(self, ticker: str) -> Dict:
        try:
            ctx = self._get_history_context(ticker)

            # è·å–çœŸå®è‚¡ä»·
            stock = self._get_stock_data(ticker)
            current_price = stock["price"]

            # ---- æœŸæƒåˆ†æï¼ˆ60%ï¼‰----
            options_score = 5.0
            signal_summary = "æœŸæƒæ•°æ®ä¸å¯ç”¨"
            try:
                from options_analyzer import OptionsAgent
                agent = OptionsAgent()
                result = agent.analyze(ticker, stock_price=current_price)
                options_score = result.get("options_score", 5.0)
                signal_summary = result.get("signal_summary", "å¹³è¡¡")
            except Exception:
                result = {}

            # ---- Polymarket èµ”ç‡ï¼ˆ40%ï¼‰----
            poly_score = 5.0
            poly_signal = ""
            try:
                from polymarket_client import get_polymarket_odds
                poly = get_polymarket_odds(ticker)
                poly_score = poly.get("odds_score", 5.0)
                poly_signal = poly.get("odds_signal", "")
                poly_markets = poly.get("markets_found", 0)
            except Exception:
                poly_markets = 0

            # ---- èåˆè¯„åˆ† ----
            if poly_markets > 0:
                score = options_score * 0.6 + poly_score * 0.4
            else:
                score = options_score  # æ—  Polymarket æ•°æ®æ—¶å®Œå…¨ä¾èµ–æœŸæƒ

            # ä» signal_summary æ¨æ–­æ–¹å‘
            if "å¤š" in signal_summary or "å¢å¼º" in signal_summary or "çœ‹æ¶¨" in signal_summary:
                direction = "bullish"
            elif "ç©º" in signal_summary or "çœ‹è·Œ" in signal_summary:
                direction = "bearish"
            else:
                direction = "neutral"

            discovery = f"{signal_summary} | ${current_price:.1f}"
            if poly_signal:
                discovery += f" | {poly_signal}"
            if ctx:
                discovery += f" | {ctx}"

            self._publish(ticker, discovery, "options+polymarket", score, direction)

            # Phase 2: confidence = æœŸæƒæ•°æ®å¯ç”¨ + Polymarket å¯ç”¨
            confidence = 0.4
            if result:
                confidence += 0.4
            if poly_markets > 0:
                confidence += 0.2
            confidence = min(1.0, confidence)

            return {
                "score": round(score, 2),
                "direction": direction,
                "confidence": round(confidence, 2),
                "discovery": discovery,
                "source": "OracleBeeEcho",
                "dimension": "odds",
                "data_quality": {
                    "options": "real" if result else "fallback",
                    "polymarket": "real" if poly_markets > 0 else "unavailable",
                },
                "details": result,
                "polymarket_score": poly_score,
                "polymarket_markets": poly_markets,
            }

        except Exception as e:
            return {"error": str(e), "source": "OracleBeeEcho", "score": 5.0, "dimension": "odds"}


# ==================== BuzzBeeWhisper (Sentiment ç»´åº¦) ====================

class BuzzBeeWhisper(BeeAgent):
    """æƒ…ç»ªåˆ†æèœ‚ - å¤šæºå¸‚åœºæƒ…ç»ªé‡åŒ–
    å¯¹åº”ç»´åº¦ï¼šSentiment (æƒé‡ 0.20)

    æƒ…ç»ªä¿¡å·æ¥æºï¼ˆ5 é€šé“åŠ æƒï¼‰ï¼š
    1. ä»·æ ¼åŠ¨é‡ï¼ˆ5æ—¥/20æ—¥ï¼‰â†’ å¸‚åœºå‚ä¸è€…å®é™…è¡Œä¸ºï¼ˆ20%ï¼‰
    2. æˆäº¤é‡å¼‚åŠ¨ï¼ˆä»Šæ—¥ vs 20æ—¥å‡é‡ï¼‰â†’ å…³æ³¨åº¦ï¼ˆ15%ï¼‰
    3. æ³¢åŠ¨ç‡æ°´å¹³ â†’ ææƒ§/è´ªå©ªæŒ‡æ ‡ï¼ˆ10%ï¼‰
    4. Reddit ç¤¾äº¤æƒ…ç»ªï¼ˆApeWisdomï¼‰â†’ æ•£æˆ·å…³æ³¨åº¦å’ŒåŠ¨é‡ï¼ˆ25%ï¼‰
    5. Finviz æ–°é—»æƒ…ç»ª â†’ åª’ä½“å™äº‹æ–¹å‘ï¼ˆ30%ï¼‰
    """

    def analyze(self, ticker: str) -> Dict:
        try:
            ctx = self._get_history_context(ticker)
            stock = self._get_stock_data(ticker)

            # 1. åŠ¨é‡ä¿¡å·ï¼ˆ-10% ~ +10% æ˜ å°„åˆ° 0~100ï¼‰
            momentum_pct = max(-10, min(10, stock["momentum_5d"]))
            momentum_sentiment = (momentum_pct + 10) / 20 * 100  # 0~100

            # 2. æˆäº¤é‡å¼‚åŠ¨ï¼ˆ>1.5 å€ = é«˜å…³æ³¨ï¼‰
            vol_ratio = stock["volume_ratio"]
            if vol_ratio > 2.0:
                volume_signal = 80
            elif vol_ratio > 1.5:
                volume_signal = 65
            elif vol_ratio > 1.0:
                volume_signal = 50
            elif vol_ratio > 0.5:
                volume_signal = 35
            else:
                volume_signal = 20

            # 3. æ³¢åŠ¨ç‡ä¿¡å·ï¼ˆé«˜æ³¢åŠ¨ = ææƒ§ï¼Œä½æ³¢åŠ¨ = è´ªå©ª/ç¨³å®šï¼‰
            vol20 = stock["volatility_20d"]
            if vol20 > 60:
                vol_sentiment = 25
            elif vol20 > 40:
                vol_sentiment = 40
            elif vol20 > 20:
                vol_sentiment = 60
            else:
                vol_sentiment = 75

            # 4. Reddit ç¤¾äº¤æƒ…ç»ª
            reddit_signal = 50  # é»˜è®¤ä¸­æ€§
            reddit_data = None
            reddit_desc = ""
            try:
                from reddit_sentiment import get_reddit_sentiment
                reddit_data = get_reddit_sentiment(ticker)
                # å°† sentiment_score (1-10) è½¬ä¸º 0-100
                reddit_signal = reddit_data["sentiment_score"] * 10
                buzz = reddit_data.get("reddit_buzz", "quiet")
                mentions = reddit_data.get("mentions", 0)
                rank = reddit_data.get("rank")
                if rank:
                    reddit_desc = f"Reddit #{rank}({buzz},{mentions}æåŠ)"
                else:
                    reddit_desc = f"Reddit æ— çƒ­åº¦"
            except Exception:
                reddit_desc = "Reddit ä¸å¯ç”¨"

            # 5. Finviz æ–°é—»æƒ…ç»ªï¼ˆå…³é”®è¯åŸºç¡€ + LLM è¯­ä¹‰å¢å¼ºï¼‰
            news_signal = 50  # é»˜è®¤ä¸­æ€§
            news_desc = ""
            news_reasoning = ""
            news_mode = "keyword"
            try:
                from finviz_sentiment import get_finviz_sentiment
                finviz = get_finviz_sentiment(ticker)
                news_signal = finviz["news_score"] * 10  # 0-10 â†’ 0-100
                news_desc = finviz.get("news_signal", "")

                # LLM è¯­ä¹‰åˆ†æï¼ˆæœ‰ API Key æ—¶è‡ªåŠ¨å¯ç”¨ï¼‰
                headlines = finviz.get("top_bullish", []) + finviz.get("top_bearish", [])
                if not headlines:
                    # å°è¯•è·å–åŸå§‹æ ‡é¢˜
                    try:
                        from finviz_sentiment import _client as fv_client
                        if fv_client:
                            headlines = fv_client.get_news_titles(ticker, max_titles=10)
                    except Exception:
                        pass

                if headlines:
                    try:
                        import llm_service
                        if llm_service.is_available():
                            llm_news = llm_service.analyze_news_sentiment(ticker, headlines)
                            if llm_news:
                                # LLM åˆ†ææˆåŠŸï¼šæ··åˆå…³é”®è¯ 50% + LLM 50%
                                llm_news_score = llm_news.get("sentiment_score", 5.0) * 10
                                news_signal = news_signal * 0.5 + llm_news_score * 0.5
                                news_desc = llm_news.get("key_theme", news_desc)
                                news_reasoning = llm_news.get("reasoning", "")
                                news_mode = "llm_enhanced"
                    except Exception:
                        pass
            except Exception:
                news_desc = "æ–°é—»ä¸å¯ç”¨"

            # 5 é€šé“åŠ æƒç»¼åˆï¼ˆæ–°é—»æƒ…ç»ªæƒé‡æœ€é«˜ï¼‰
            sentiment_composite = (
                momentum_sentiment * 0.20 +
                volume_signal * 0.15 +
                vol_sentiment * 0.10 +
                reddit_signal * 0.25 +
                news_signal * 0.30
            )

            # è½¬æ¢ä¸º 0-10 åˆ†
            score = sentiment_composite / 10.0
            score = max(1.0, min(10.0, score))

            # æ–¹å‘åˆ¤å®š
            bullish_pct = int(sentiment_composite)
            if sentiment_composite > 60:
                direction = "bullish"
            elif sentiment_composite < 40:
                direction = "bearish"
            else:
                direction = "neutral"

            discovery_parts = [
                f"æƒ…ç»ª {bullish_pct}%",
                f"åŠ¨é‡ {stock['momentum_5d']:+.1f}%",
                f"é‡æ¯” {vol_ratio:.1f}x",
                reddit_desc,
                news_desc,
            ]
            if news_reasoning:
                discovery_parts.append(news_reasoning)
            discovery = " | ".join(p for p in discovery_parts if p)

            if ctx:
                discovery = f"{discovery} | {ctx}"

            self._publish(ticker, discovery, "market_sentiment+reddit", round(score, 2), direction)

            # Phase 2: confidence = åŸºç¡€ 0.5ï¼ˆyfinanceï¼‰+ Reddit + Finviz + LLM
            confidence = 0.5  # yfinance momentum/volume always available
            if reddit_data and reddit_data.get("rank"):
                confidence += 0.2
            if news_desc and "ä¸å¯ç”¨" not in news_desc:
                confidence += 0.2
            if news_mode == "llm_enhanced":
                confidence += 0.1
            confidence = min(1.0, confidence)

            return {
                "score": round(score, 2),
                "direction": direction,
                "confidence": round(confidence, 2),
                "discovery": discovery,
                "source": "BuzzBeeWhisper",
                "dimension": "sentiment",
                "data_quality": {
                    "momentum": "real",
                    "volume": "real",
                    "volatility": "real",
                    "reddit": "real" if (reddit_data and reddit_data.get("rank")) else "fallback",
                    "finviz_news": news_mode if news_desc and "ä¸å¯ç”¨" not in news_desc else "fallback",
                },
                "details": {
                    "sentiment_pct": bullish_pct,
                    "momentum_5d": stock["momentum_5d"],
                    "volume_ratio": vol_ratio,
                    "volatility_20d": vol20,
                    "reddit": {
                        "rank": reddit_data.get("rank") if reddit_data else None,
                        "mentions": reddit_data.get("mentions", 0) if reddit_data else 0,
                        "mention_delta": reddit_data.get("mention_delta", 0) if reddit_data else 0,
                        "buzz": reddit_data.get("reddit_buzz", "quiet") if reddit_data else "unknown",
                        "score": reddit_data.get("sentiment_score", 5.0) if reddit_data else 5.0,
                    },
                    "components": {
                        "momentum_signal": round(momentum_sentiment, 1),
                        "volume_signal": volume_signal,
                        "volatility_signal": vol_sentiment,
                        "reddit_signal": round(reddit_signal, 1),
                    }
                }
            }

        except Exception as e:
            return {"error": str(e), "source": "BuzzBeeWhisper", "score": 5.0, "dimension": "sentiment"}


# ==================== ChronosBeeHorizon (Catalyst ç»´åº¦) ====================

class ChronosBeeHorizon(BeeAgent):
    """å‚¬åŒ–å‰‚è¿½è¸ªèœ‚ - è´¢æŠ¥ã€äº‹ä»¶ã€æ—¶é—´çº¿ï¼ˆyfinance çœŸå®æ—¥å†ï¼‰
    å¯¹åº”ç»´åº¦ï¼šCatalyst (æƒé‡ 0.20)
    """

    def analyze(self, ticker: str) -> Dict:
        try:
            ctx = self._get_history_context(ticker)

            catalysts_found = []
            score = 5.0
            direction = "neutral"

            # 1. ä» yfinance è·å–çœŸå®è´¢æŠ¥æ—¥æœŸ
            try:
                import yfinance as yf
                t = yf.Ticker(ticker)
                cal = t.calendar
                if cal is not None:
                    # cal å¯èƒ½æ˜¯ DataFrame æˆ– dict
                    if hasattr(cal, 'to_dict'):
                        cal_dict = cal.to_dict()
                    elif isinstance(cal, dict):
                        cal_dict = cal
                    else:
                        cal_dict = {}

                    # æå–è´¢æŠ¥æ—¥æœŸ
                    earnings_date = cal_dict.get("Earnings Date", [])
                    if isinstance(earnings_date, list) and earnings_date:
                        from datetime import datetime
                        for ed in earnings_date:
                            if hasattr(ed, 'strftime'):
                                date_str = ed.strftime("%Y-%m-%d")
                            else:
                                date_str = str(ed)[:10]
                            days_until = (datetime.strptime(date_str, "%Y-%m-%d") - datetime.now()).days
                            if days_until >= 0:
                                catalysts_found.append({
                                    "event": f"è´¢æŠ¥å‘å¸ƒ",
                                    "date": date_str,
                                    "days_until": days_until,
                                    "type": "earnings",
                                    "severity": "critical" if days_until <= 14 else "high",
                                })
                    elif isinstance(earnings_date, dict):
                        for key, val in earnings_date.items():
                            if hasattr(val, 'strftime'):
                                date_str = val.strftime("%Y-%m-%d")
                                from datetime import datetime
                                days_until = (datetime.strptime(date_str, "%Y-%m-%d") - datetime.now()).days
                                if days_until >= 0:
                                    catalysts_found.append({
                                        "event": f"è´¢æŠ¥å‘å¸ƒ",
                                        "date": date_str,
                                        "days_until": days_until,
                                        "type": "earnings",
                                        "severity": "critical" if days_until <= 14 else "high",
                                    })

                    # æå–å…¶ä»–äº‹ä»¶
                    for key in ["Ex-Dividend Date", "Dividend Date"]:
                        val = cal_dict.get(key)
                        if val:
                            if isinstance(val, dict):
                                for k, v in val.items():
                                    if hasattr(v, 'strftime'):
                                        catalysts_found.append({
                                            "event": key,
                                            "date": v.strftime("%Y-%m-%d"),
                                            "days_until": 0,
                                            "type": "dividend",
                                            "severity": "medium",
                                        })
                            elif hasattr(val, 'strftime'):
                                catalysts_found.append({
                                    "event": key,
                                    "date": val.strftime("%Y-%m-%d"),
                                    "days_until": 0,
                                    "type": "dividend",
                                    "severity": "medium",
                                })
            except Exception:
                pass

            # 2. è¡¥å…… CatalystTimelineï¼ˆå·²æœ‰çš„ç¡¬ç¼–ç å‚¬åŒ–å‰‚ï¼‰
            try:
                from catalyst_refinement import CatalystTimeline, create_nvda_catalysts, create_vktx_catalysts
                if ticker == "NVDA":
                    timeline = create_nvda_catalysts()
                elif ticker == "VKTX":
                    timeline = create_vktx_catalysts()
                else:
                    timeline = None

                if timeline:
                    for cat in timeline.get_upcoming_catalysts(days_ahead=30):
                        catalysts_found.append({
                            "event": cat.event_name,
                            "date": cat.scheduled_date or "TBD",
                            "days_until": cat.get_days_until_event(),
                            "type": cat.catalyst_type.value,
                            "severity": cat.severity.value,
                        })
            except Exception:
                pass

            # è¯„åˆ†é€»è¾‘
            if catalysts_found:
                # æŒ‰å¤©æ•°æ’åº
                catalysts_found.sort(key=lambda c: c.get("days_until", 999))

                # åŸºç¡€åˆ† + å‚¬åŒ–å‰‚æ•°é‡åŠ æˆ
                base = 6.0
                # è¿‘æœŸå‚¬åŒ–å‰‚ï¼ˆ7å¤©å†…ï¼‰é¢å¤–åŠ åˆ†
                imminent = [c for c in catalysts_found if c.get("days_until", 999) <= 7]
                medium = [c for c in catalysts_found if 7 < c.get("days_until", 999) <= 30]

                score = base + len(imminent) * 1.5 + len(medium) * 0.5
                score = min(10.0, score)

                nearest = catalysts_found[0]
                discovery = f"å‚¬åŒ–å‰‚ {len(catalysts_found)} ä¸ª | æœ€è¿‘ï¼š{nearest['event']}ï¼ˆ{nearest.get('days_until', '?')}å¤©åï¼‰"
                direction = "bullish"
            else:
                score = 4.0
                discovery = "æ— è¿‘æœŸå‚¬åŒ–å‰‚"
                direction = "neutral"

            if ctx:
                discovery = f"{discovery} | {ctx}"

            self._publish(ticker, discovery, "catalyst_timeline", score, direction)

            # Phase 2: confidence = å‚¬åŒ–å‰‚æ•°é‡å’Œæ¥æºå¤šæ ·æ€§
            confidence = 0.3  # baseline
            if catalysts_found:
                confidence += min(0.4, len(catalysts_found) * 0.1)
                # æœ‰ yfinance å®æ—¶æ—¥å†æ•°æ®åŠ åˆ†
                has_yf = any(c.get("type") == "earnings" for c in catalysts_found)
                if has_yf:
                    confidence += 0.2
            confidence = min(1.0, confidence)

            return {
                "score": round(score, 2),
                "direction": direction,
                "confidence": round(confidence, 2),
                "discovery": discovery,
                "source": "ChronosBeeHorizon",
                "dimension": "catalyst",
                "data_quality": {
                    "yfinance_calendar": "real" if catalysts_found else "empty",
                    "catalyst_refinement": "real",
                },
                "details": {"catalysts": catalysts_found[:5]}
            }

        except Exception as e:
            return {"error": str(e), "source": "ChronosBeeHorizon", "score": 5.0, "dimension": "catalyst"}


# ==================== RivalBeeVanguard (ML è¾…åŠ©) ====================

class RivalBeeVanguard(BeeAgent):
    """ç«äº‰åˆ†æä¸ ML é¢„æµ‹èœ‚ - æ¦‚ç‡é¢„æµ‹ + è¡Œä¸šåŠ¨é‡å¯¹æ ‡
    ä¸ç›´æ¥å‚ä¸ 5 ç»´å…¬å¼ï¼Œä½œä¸ºé¢å¤–è°ƒæ•´é¡¹
    """

    def analyze(self, ticker: str) -> Dict:
        try:
            ctx = self._get_history_context(ticker)

            # å°è¯• ML é¢„æµ‹
            prediction = {}
            try:
                from ml_predictor_extended import MLPredictionService, TrainingData
                from datetime import datetime
                service = MLPredictionService()

                stock = self._get_stock_data(ticker)
                opportunity = TrainingData(
                    ticker=ticker,
                    date=datetime.now().strftime("%Y-%m-%d"),
                    crowding_score=50.0,
                    catalyst_quality="B+",
                    momentum_5d=stock["momentum_5d"],
                    volatility=stock["volatility_20d"],
                    market_sentiment=stock["momentum_5d"] * 5,
                    iv_rank=50.0,
                    put_call_ratio=1.0,
                    actual_return_3d=0.0,
                    actual_return_7d=0.0,
                    actual_return_30d=0.0,
                    win_3d=False,
                    win_7d=False,
                    win_30d=False,
                )
                prediction = service.predict_for_opportunity(opportunity)
            except Exception:
                pass

            if prediction:
                prob = prediction.get("probability", 0.5)
                ret_7d = prediction.get("expected_7d", 0.0)
                ret_30d = prediction.get("expected_30d", 0.0)
                avg_ret = (ret_7d + ret_30d) / 2

                score = prob * 10  # èƒœç‡ â†’ 0-10
                score = max(1.0, min(10.0, score))

                direction = "bullish" if avg_ret > 0 else ("bearish" if avg_ret < 0 else "neutral")

                discovery = f"ML èƒœç‡ {prob*100:.0f}% | 7d {ret_7d:+.2f}% | 30d {ret_30d:+.2f}%"
            else:
                # ML ä¸å¯ç”¨ï¼Œç”¨ç®€å•åŠ¨é‡å¯¹æ ‡
                stock = self._get_stock_data(ticker)
                mom = stock["momentum_5d"]
                score = max(1.0, min(10.0, 5.0 + mom * 0.3))
                direction = "bullish" if mom > 2 else ("bearish" if mom < -2 else "neutral")
                discovery = f"åŠ¨é‡å¯¹æ ‡ {mom:+.1f}% | æ³¢åŠ¨ç‡ {stock['volatility_20d']:.0f}%"

            if ctx:
                discovery = f"{discovery} | {ctx}"

            self._publish(ticker, discovery, "ml_predictor", round(score, 2), direction)

            # Phase 2: confidence = ML æ¨¡å‹å¯ç”¨æ€§
            confidence = 0.3 if not prediction else 0.8
            confidence = min(1.0, confidence)

            return {
                "score": round(score, 2),
                "direction": direction,
                "confidence": round(confidence, 2),
                "discovery": discovery,
                "source": "RivalBeeVanguard",
                "dimension": "ml_auxiliary",
                "data_quality": {
                    "ml_prediction": "real" if prediction else "fallback_momentum",
                },
                "details": prediction if prediction else {"momentum_5d": stock["momentum_5d"]}
            }

        except Exception as e:
            return {"error": str(e), "source": "RivalBeeVanguard", "score": 5.0, "dimension": "ml_auxiliary"}


# ==================== GuardBeeSentinel (RiskAdj ç»´åº¦) ====================

class GuardBeeSentinel(BeeAgent):
    """äº¤å‰éªŒè¯ä¸é£é™©è¯„ä¼°èœ‚ - å…±æŒ¯æ£€æµ‹ + æ‹¥æŒ¤åº¦æŠ˜æ‰£ + é£é™©è°ƒæ•´
    å¯¹åº”ç»´åº¦ï¼šRiskAdj (æƒé‡ 0.15)
    """

    def analyze(self, ticker: str) -> Dict:
        try:
            ctx = self._get_history_context(ticker)

            # 1. æ£€æµ‹ä¿¡æ¯ç´ æ¿å…±æŒ¯
            resonance = self.board.detect_resonance(ticker)
            top_signals = self.board.get_top_signals(ticker, n=5)

            # 2. ä»ä¿¡æ¯ç´ æ¿è¯»å–å·²æœ‰ Agent åˆ†æ•°
            avg_score = sum(e.self_score for e in top_signals) / len(top_signals) if top_signals else 5.0

            # 3. è¯„ä¼°ä¿¡å·ä¸€è‡´æ€§
            if top_signals:
                directions = [e.direction for e in top_signals]
                bull = directions.count("bullish")
                bear = directions.count("bearish")
                total = len(directions)
                consistency = max(bull, bear) / total if total > 0 else 0
            else:
                consistency = 0
                bull = bear = 0

            # 4. æ‹¥æŒ¤åº¦é£é™©æŠ˜æ‰£ï¼ˆä½¿ç”¨çœŸå®æ•°æ®æºï¼‰
            adj_factor = 1.0
            try:
                from crowding_detector import CrowdingDetector
                from real_data_sources import get_real_crowding_metrics
                stock = self._get_stock_data(ticker)
                detector = CrowdingDetector(ticker)
                real_metrics = get_real_crowding_metrics(ticker, stock, self.board)
                # è¦†ç›– bullish_agents ä¸ºå®é™…ä¿¡æ¯ç´ æ¿æ•°æ®
                real_metrics["bullish_agents"] = bull
                crowd, _ = detector.calculate_crowding_score(real_metrics)
                adj_factor = detector.get_adjustment_factor(crowd)
            except Exception:
                pass

            # 5. ç»¼åˆè¯„åˆ†
            if resonance["resonance_detected"]:
                # å…±æŒ¯ + ä¸€è‡´æ€§é«˜ â†’ é«˜åˆ†ï¼Œä½†å—æ‹¥æŒ¤åº¦è°ƒæ•´
                raw_score = 7.0 + consistency * 2.0  # 7.0 ~ 9.0
                score = raw_score * adj_factor
                direction = resonance["direction"]
                discovery = (
                    f"å…±æŒ¯âœ… {resonance['supporting_agents']} Agent åŒå‘ | "
                    f"ä¸€è‡´æ€§ {consistency:.0%} | "
                    f"é£é™©è°ƒæ•´ {adj_factor:.2f}"
                )
            else:
                # æ— å…±æŒ¯ â†’ ä¿å®ˆï¼Œæ‰“æŠ˜
                score = avg_score * 0.8 * adj_factor
                direction = "neutral"
                discovery = (
                    f"ä¿¡å·åˆ†æ•£ | å‡åˆ† {avg_score:.1f} | "
                    f"ä¸€è‡´æ€§ {consistency:.0%} | "
                    f"é£é™©è°ƒæ•´ {adj_factor:.2f}"
                )

            score = max(1.0, min(10.0, score))

            if ctx:
                discovery = f"{discovery} | {ctx}"

            self._publish(ticker, discovery, "guard_bee_sentinel", round(score, 2), direction)

            # Phase 2: confidence = ä¿¡å·æ¿æœ‰æ•°æ® + ä¸€è‡´æ€§é«˜
            confidence = 0.4
            if top_signals:
                confidence += 0.3
            if consistency >= 0.7:
                confidence += 0.2
            if resonance["resonance_detected"]:
                confidence += 0.1
            confidence = min(1.0, confidence)

            return {
                "score": round(score, 2),
                "direction": direction,
                "confidence": round(confidence, 2),
                "discovery": discovery,
                "source": "GuardBeeSentinel",
                "dimension": "risk_adj",
                "data_quality": {
                    "pheromone_board": "real",
                    "crowding": "real",
                },
                "details": {
                    "resonance": resonance,
                    "top_signals_count": len(top_signals),
                    "consistency": consistency,
                    "adjustment_factor": adj_factor,
                }
            }

        except Exception as e:
            return {"error": str(e), "source": "GuardBeeSentinel", "score": 5.0, "dimension": "risk_adj"}


# ==================== QueenDistiller (5 ç»´åŠ æƒå…¬å¼ + LLM è’¸é¦) ====================

class QueenDistiller:
    """
    ç‹åè’¸é¦èœ‚ - 5 ç»´åŠ æƒè¯„åˆ† + å…±æŒ¯å¢å¼º + å¤šæ•°æŠ•ç¥¨ + LLM æ¨ç†

    åŒå¼•æ“æ¶æ„ï¼š
    1. è§„åˆ™å¼•æ“ï¼ˆå§‹ç»ˆè¿è¡Œï¼‰ï¼šåŠ æƒè¯„åˆ† + å…±æŒ¯ + æŠ•ç¥¨ â†’ base_score
    2. LLM å¼•æ“ï¼ˆæœ‰ API Key æ—¶å¯ç”¨ï¼‰ï¼šClaude åˆ†ææ¨ç† â†’ è°ƒæ•´è¯„åˆ† + ç”Ÿæˆæ¨ç†é“¾

    Opportunity Score = 0.30Ã—Signal + 0.20Ã—Catalyst + 0.20Ã—Sentiment + 0.15Ã—Odds + 0.15Ã—RiskAdj
    """

    DEFAULT_WEIGHTS = {
        "signal":    0.30,
        "catalyst":  0.20,
        "sentiment": 0.20,
        "odds":      0.15,
        "risk_adj":  0.15,
    }

    def __init__(self, board: PheromoneBoard, weight_manager=None, adapted_weights: Dict = None,
                 enable_llm: bool = True):
        self.board = board
        self.weight_manager = weight_manager
        self.enable_llm = enable_llm
        if adapted_weights:
            self.DIMENSION_WEIGHTS = adapted_weights
        else:
            self.DIMENSION_WEIGHTS = dict(self.DEFAULT_WEIGHTS)

    def distill(self, ticker: str, agent_results: List[Dict]) -> Dict:
        """
        5 ç»´åŠ æƒè¯„åˆ† + å…±æŒ¯å¢å¼º + å¤šæ•°æŠ•ç¥¨ + LLM æ¨ç†è’¸é¦

        åŒå¼•æ“ï¼šè§„åˆ™å¼•æ“å§‹ç»ˆè¿è¡Œä½œä¸ºåŸºç¡€ï¼ŒLLM å¼•æ“åœ¨å¯ç”¨æ—¶å åŠ æ¨ç†ã€‚
        """
        # ===== è§„åˆ™å¼•æ“ï¼ˆå§‹ç»ˆè¿è¡Œï¼‰=====

        # 1. è¿‡æ»¤æœ‰æ•ˆç»“æœï¼ˆå«æ•°æ®è´¨é‡æ¸…æ´—ï¼‰
        _dq = _DQChecker()
        cleaned_results = _dq.clean_results_batch(agent_results)
        valid_results = [r for r in cleaned_results if "error" not in r]
        all_results = cleaned_results

        # 2. æŒ‰ dimension åˆ†ç»„ï¼ˆå« confidenceï¼‰
        dim_scores = {}
        dim_confidence = {}
        for r in valid_results:
            dim = r.get("dimension", "")
            if dim in self.DIMENSION_WEIGHTS:
                dim_scores[dim] = r.get("score", 5.0)
                dim_confidence[dim] = r.get("confidence", 0.5)

        # 3. ML è¾…åŠ©åˆ†ï¼ˆæŒ‰ confidence ç¼©æ”¾å½±å“åŠ›ï¼‰
        ml_adjustment = 0.0
        for r in valid_results:
            if r.get("dimension") == "ml_auxiliary":
                ml_score = r.get("score", 5.0)
                ml_conf = r.get("confidence", 0.5)
                ml_adjustment = (ml_score - 5.0) * 0.1 * ml_conf

        # 4. 5 ç»´ confidence-weighted è¯„åˆ†
        # ä½ confidence Agent çš„è¯„åˆ†å‘ 5.0ï¼ˆä¸­æ€§ï¼‰æ”¶ç¼©
        weighted_sum = 0.0
        weight_total = 0.0
        for dim, weight in self.DIMENSION_WEIGHTS.items():
            if dim in dim_scores:
                conf = dim_confidence.get(dim, 0.5)
                # æŒ‰ confidence æ··åˆï¼šé«˜ confidence ç”¨åŸå§‹åˆ†ï¼Œä½ confidence æ‹‰å‘ 5.0
                effective_score = dim_scores[dim] * conf + 5.0 * (1.0 - conf)
                weighted_sum += effective_score * weight
                weight_total += weight
            else:
                weighted_sum += 5.0 * weight
                weight_total += weight

        base_score = weighted_sum / weight_total if weight_total > 0 else 5.0

        # 5. ML è°ƒæ•´
        adjusted_score = base_score + ml_adjustment

        # 6. å…±æŒ¯å¢å¼º
        resonance = self.board.detect_resonance(ticker)
        if resonance["resonance_detected"]:
            boost_pct = resonance["confidence_boost"]
            rule_score = adjusted_score * (1.0 + boost_pct / 100.0)
        else:
            rule_score = adjusted_score

        rule_score = round(max(0.0, min(10.0, rule_score)), 2)

        # 7. å¤šæ•°æŠ•ç¥¨
        directions = [r.get("direction", "neutral") for r in valid_results]
        bullish_count = directions.count("bullish")
        bearish_count = directions.count("bearish")
        neutral_count = directions.count("neutral")

        if bullish_count > bearish_count:
            rule_direction = "bullish"
        elif bearish_count > bullish_count:
            rule_direction = "bearish"
        else:
            rule_direction = "neutral"

        # 8. Agent æ–¹å‘
        per_agent_directions = {}
        for r in all_results:
            src = r.get("source", "")
            if src:
                per_agent_directions[src] = r.get("direction", "neutral")

        # 9. data_quality æ±‡æ€»
        data_quality_summary = {}
        real_count = 0
        total_fields = 0
        for r in valid_results:
            dq = r.get("data_quality", {})
            if isinstance(dq, dict):
                src = r.get("source", "unknown")
                data_quality_summary[src] = dq
                for v in dq.values():
                    total_fields += 1
                    if v == "real":
                        real_count += 1

        data_real_pct = round(real_count / total_fields * 100, 1) if total_fields > 0 else 0.0

        # ===== LLM å¼•æ“ï¼ˆå¯ç”¨æ—¶å åŠ ï¼‰=====
        llm_result = None
        reasoning = ""
        key_insight = ""
        risk_flag = ""
        llm_confidence = 0.0
        final_score = rule_score
        final_direction = rule_direction
        distill_mode = "rule_engine"

        if self.enable_llm:
            try:
                import llm_service
                if llm_service.is_available():
                    llm_result = llm_service.distill_with_reasoning(
                        ticker=ticker,
                        agent_results=valid_results,
                        dim_scores=dim_scores,
                        resonance=resonance,
                        rule_score=rule_score,
                        rule_direction=rule_direction,
                    )
            except Exception:
                pass

        if llm_result:
            distill_mode = "llm_enhanced"
            reasoning = llm_result.get("reasoning", "")
            key_insight = llm_result.get("key_insight", "")
            risk_flag = llm_result.get("risk_flag", "")
            llm_confidence = llm_result.get("confidence", 0.5)

            llm_score = llm_result.get("final_score")
            llm_direction = llm_result.get("direction")

            if llm_score is not None and isinstance(llm_score, (int, float)):
                # æ··åˆç­–ç•¥ï¼šè§„åˆ™å¼•æ“ 60% + LLM 40%ï¼ˆLLM ä¸å®Œå…¨æ›¿ä»£è§„åˆ™å¼•æ“ï¼‰
                final_score = round(rule_score * 0.6 + float(llm_score) * 0.4, 2)
                final_score = max(0.0, min(10.0, final_score))

            if llm_direction in ("bullish", "bearish", "neutral"):
                # LLM æ–¹å‘ä¸è§„åˆ™å¼•æ“ä¸€è‡´æ—¶é‡‡ç”¨ï¼Œä¸ä¸€è‡´æ—¶ä¿æŒè§„åˆ™å¼•æ“
                if llm_direction == rule_direction:
                    final_direction = llm_direction
                elif llm_confidence >= 0.7:
                    # LLM é«˜ç½®ä¿¡åº¦æ—¶è¦†ç›–è§„åˆ™å¼•æ“æ–¹å‘
                    final_direction = llm_direction

        # ä¿ç•™å„ Agent çš„åŸå§‹åˆ†æå†…å®¹ï¼ˆdiscovery + detailsï¼‰
        agent_details = {}
        for r in all_results:
            src = r.get("source", "unknown")
            agent_details[src] = {
                "discovery": r.get("discovery", ""),
                "score": r.get("score", 5.0),
                "direction": r.get("direction", "neutral"),
                "confidence": r.get("confidence", 0.5),
                "dimension": r.get("dimension", ""),
                "details": r.get("details") or {},
            }

        return {
            "ticker": ticker,
            "final_score": final_score,
            "direction": final_direction,
            "resonance": resonance,
            "supporting_agents": len(valid_results),
            "agent_breakdown": {
                "bullish": bullish_count,
                "bearish": bearish_count,
                "neutral": neutral_count,
            },
            "agent_directions": per_agent_directions,
            "agent_details": agent_details,
            "dimension_scores": dim_scores,
            "dimension_confidence": dim_confidence,
            "dimension_weights": dict(self.DIMENSION_WEIGHTS),
            "ml_adjustment": round(ml_adjustment, 3),
            "base_score_before_resonance": round(adjusted_score, 2),
            "pheromone_compact": self.board.compact_snapshot(ticker),
            "data_quality": data_quality_summary,
            "data_real_pct": data_real_pct,
            # Phase 1: LLM æ¨ç†å¢å¼º
            "distill_mode": distill_mode,
            "reasoning": reasoning,
            "key_insight": key_insight,
            "risk_flag": risk_flag,
            "llm_confidence": llm_confidence,
            "rule_score": rule_score,
            "rule_direction": rule_direction,
        }
