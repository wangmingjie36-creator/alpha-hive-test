#!/usr/bin/env python3
"""
ğŸ Alpha Hive æ—¥æŠ¥ç”Ÿæˆå™¨ - é›†æˆæœŸæƒåˆ†æçš„å®Œæ•´ç‰ˆæœ¬
æ¯æ—¥è‡ªåŠ¨æ‰«æ watchlist å¹¶ç”Ÿæˆç»“æ„åŒ–æŠ•èµ„ç®€æŠ¥ + X çº¿ç¨‹ç‰ˆæœ¬
"""

import json
import os
import argparse
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple
from dataclasses import dataclass
from concurrent.futures import ThreadPoolExecutor
from threading import Lock

# å¯¼å…¥ç°æœ‰æ¨¡å—
from config import WATCHLIST, EVALUATION_WEIGHTS
from hive_logger import get_logger, PATHS, set_correlation_id

_log = get_logger("daily_report")

# Week 4: æŒ‡æ ‡æ”¶é›†å™¨
try:
    from metrics_collector import MetricsCollector
except ImportError:
    MetricsCollector = None
from generate_ml_report import MLEnhancedReportGenerator
from pheromone_board import PheromoneBoard
from swarm_agents import (
    ScoutBeeNova, OracleBeeEcho, BuzzBeeWhisper,
    ChronosBeeHorizon, RivalBeeVanguard, GuardBeeSentinel,
    BearBeeContrarian,
    QueenDistiller, prefetch_shared_data, inject_prefetched
)
from concurrent.futures import as_completed
from agent_toolbox import AgentHelper

# Phase 2: Import memory store
try:
    from memory_store import MemoryStore
except ImportError:
    MemoryStore = None

# Phase 3 P2: Import Calendar integrator
try:
    from calendar_integrator import CalendarIntegrator
except ImportError:
    CalendarIntegrator = None

# Phase 3 P4: Import Code Execution Agent
try:
    from code_executor_agent import CodeExecutorAgent
    from config import CODE_EXECUTION_CONFIG
except ImportError:
    CodeExecutorAgent = None
    CODE_EXECUTION_CONFIG = {"enabled": False}

# Phase 3 P5: Import CrewAI å¤š Agent æ¡†æ¶
try:
    from crewai_adapter import AlphaHiveCrew
    from config import CREWAI_CONFIG
except (ImportError, TypeError) as e:
    AlphaHiveCrew = None
    CREWAI_CONFIG = {"enabled": False}
    _log.info("CrewAI æ¨¡å—å¯¼å…¥å¤±è´¥: %s (é™çº§åˆ°åŸå§‹èœ‚ç¾¤)", type(e).__name__)

# Phase 3 P6: Import Slack æŠ¥å‘Šé€šçŸ¥å™¨ï¼ˆæ›¿ä»£ Gmailï¼‰
try:
    from slack_report_notifier import SlackReportNotifier
except ImportError:
    SlackReportNotifier = None

# è´¢æŠ¥è‡ªåŠ¨ç›‘æ§å™¨
try:
    from earnings_watcher import EarningsWatcher
except ImportError:
    EarningsWatcher = None

# Phase 3 å†…å­˜ä¼˜åŒ–: å‘é‡è®°å¿†å±‚ï¼ˆChroma é•¿æœŸè®°å¿†ï¼‰
try:
    from vector_memory import VectorMemory
    from config import VECTOR_MEMORY_CONFIG
except ImportError:
    VectorMemory = None
    VECTOR_MEMORY_CONFIG = {"enabled": False}

# Phase 6: å›æµ‹åé¦ˆå¾ªç¯
try:
    from backtester import Backtester, run_full_backtest
except ImportError:
    Backtester = None
    run_full_backtest = None


# å…è´£å£°æ˜å¸¸é‡ï¼ˆå»é‡ï¼Œå…¨å±€å¼•ç”¨ï¼‰
DISCLAIMER_FULL = (
    "æœ¬æŠ¥å‘Šä¸ºèœ‚ç¾¤ AI åˆ†æï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ï¼Œä¸æ›¿ä»£æŒç‰ŒæŠ•é¡¾ã€‚"
    "é¢„æµ‹å­˜åœ¨è¯¯å·®ï¼Œæ‰€æœ‰äº¤æ˜“å†³ç­–éœ€è‡ªè¡Œåˆ¤æ–­å’Œé£æ§ã€‚"
)
DISCLAIMER_SHORT = "éæŠ•èµ„å»ºè®®ï¼Œä»…æ•°æ®åˆ†æä¸æƒ…æ™¯æ¨æ¼”ã€‚"


@dataclass
class OpportunityItem:
    """æœºä¼šé¡¹ç›®ç»“æ„"""
    ticker: str
    direction: str  # "çœ‹å¤š" / "çœ‹ç©º" / "ä¸­æ€§"
    signal_score: float  # 0-10
    catalyst_score: float  # 0-10
    sentiment_score: float  # 0-10
    odds_score: float  # 0-10
    risk_score: float  # 0-10
    options_score: float  # 0-10 (æ–°å¢)
    opportunity_score: float  # 0-10 (ç»¼åˆ)
    confidence: float  # 0-100%
    key_catalysts: List[str]
    options_signal: str  # æœŸæƒä¿¡å·æ‘˜è¦
    risks: List[str]
    thesis_break: str  # å¤±æ•ˆæ¡ä»¶


class AlphaHiveDailyReporter:
    """Alpha Hive æ—¥æŠ¥ç”Ÿæˆå¼•æ“"""

    def __init__(self):
        self.report_dir = PATHS.home
        self.timestamp = datetime.now()
        self.date_str = self.timestamp.strftime("%Y-%m-%d")

        # åˆå§‹åŒ–æŠ¥å‘Šç”Ÿæˆå™¨
        self.ml_generator = MLEnhancedReportGenerator()

        # åˆå§‹åŒ– Agent å·¥å…·é›†ï¼ˆæ–°å¢ï¼‰
        self.agent_helper = AgentHelper()

        # Phase 2: åˆå§‹åŒ–æŒä¹…åŒ–è®°å¿†å­˜å‚¨
        self.memory_store = None
        self._session_id = None
        if MemoryStore:
            try:
                self.memory_store = MemoryStore()
                self._session_id = self.memory_store.generate_session_id(run_mode="daily_scan")
            except (OSError, ValueError, RuntimeError) as e:
                _log.warning("MemoryStore åˆå§‹åŒ–å¤±è´¥ï¼Œç»§ç»­è¿è¡Œ: %s", e)

        # ç»“æœå­˜å‚¨
        self.opportunities: List[OpportunityItem] = []
        self.observations: List[Dict] = []
        self.risks: List[Dict] = []

        # çº¿ç¨‹å®‰å…¨é”ï¼ˆç”¨äºå¹¶è¡Œæ‰§è¡Œæ—¶ä¿æŠ¤å…±äº«æ•°æ®ï¼‰
        self._results_lock = Lock()

        # Phase 3 P2: åˆå§‹åŒ– Google Calendar é›†æˆï¼ˆå¤±è´¥æ—¶é™çº§ï¼‰
        self.calendar = None
        if CalendarIntegrator:
            try:
                self.calendar = CalendarIntegrator()
            except (OSError, ValueError, RuntimeError) as e:
                _log.warning("Calendar åˆå§‹åŒ–å¤±è´¥: %s", e)

        # Phase 3 P4: åˆå§‹åŒ–ä»£ç æ‰§è¡Œ Agentï¼ˆå¤±è´¥æ—¶é™çº§ï¼‰
        self.code_executor_agent = None
        if CodeExecutorAgent and CODE_EXECUTION_CONFIG.get("enabled"):
            try:
                self.code_executor_agent = CodeExecutorAgent(board=None)
                # board åœ¨ run_swarm_scan æ—¶æ³¨å…¥
            except (OSError, ValueError, RuntimeError, TypeError) as e:
                _log.warning("CodeExecutorAgent åˆå§‹åŒ–å¤±è´¥: %s", e)

        # Phase 3 å†…å­˜ä¼˜åŒ–: åˆå§‹åŒ–å‘é‡è®°å¿†å±‚ï¼ˆChroma é•¿æœŸè®°å¿†ï¼‰
        self.vector_memory = None
        if VectorMemory and VECTOR_MEMORY_CONFIG.get("enabled"):
            try:
                self.vector_memory = VectorMemory(
                    db_path=VECTOR_MEMORY_CONFIG.get("db_path"),
                    retention_days=VECTOR_MEMORY_CONFIG.get("retention_days", 90)
                )
                if self.vector_memory.enabled:
                    if VECTOR_MEMORY_CONFIG.get("cleanup_on_startup"):
                        self.vector_memory.cleanup()
            except (ImportError, OSError, ValueError, RuntimeError) as e:
                _log.warning("å‘é‡è®°å¿†åˆå§‹åŒ–å¤±è´¥: %s", e)

        # Week 4: æŒ‡æ ‡æ”¶é›†å™¨
        self.metrics = None
        if MetricsCollector:
            try:
                self.metrics = MetricsCollector()
            except (OSError, ValueError, RuntimeError) as e:
                _log.warning("MetricsCollector åˆå§‹åŒ–å¤±è´¥: %s", e)

        # Phase 2: å…±äº«çº¿ç¨‹æ± ï¼ˆæ›¿ä»£æ‰€æœ‰ daemon çº¿ç¨‹ï¼Œé€€å‡ºæ—¶ç­‰å¾…å®Œæˆï¼‰
        import atexit
        self._bg_executor = ThreadPoolExecutor(max_workers=3, thread_name_prefix="hive_bg")
        self._bg_futures = []
        atexit.register(self._shutdown_bg)

        # è´¢æŠ¥è‡ªåŠ¨ç›‘æ§å™¨
        self.earnings_watcher = None
        if EarningsWatcher:
            try:
                self.earnings_watcher = EarningsWatcher()
            except (OSError, ValueError, RuntimeError) as e:
                _log.warning("EarningsWatcher åˆå§‹åŒ–å¤±è´¥: %s", e)

        # Phase 3 P6: åˆå§‹åŒ– Slack æŠ¥å‘Šé€šçŸ¥å™¨ï¼ˆæ›¿ä»£ Gmailï¼‰
        self.slack_notifier = None
        if SlackReportNotifier:
            try:
                self.slack_notifier = SlackReportNotifier()
            except (OSError, ValueError, RuntimeError, ConnectionError) as e:
                _log.warning("Slack é€šçŸ¥å™¨åˆå§‹åŒ–å¤±è´¥: %s", e)

    def _shutdown_bg(self) -> None:
        """atexit å¤„ç†å™¨ï¼šç­‰å¾…åå°ä»»åŠ¡å®Œæˆ"""
        from concurrent.futures import TimeoutError as FuturesTimeout, CancelledError
        for f in self._bg_futures:
            try:
                f.result(timeout=10)
            except (FuturesTimeout, CancelledError, OSError, RuntimeError) as e:
                _log.debug("Background task cleanup: %s", e)
        self._bg_executor.shutdown(wait=True)

    def _submit_bg(self, fn, *args) -> None:
        """æäº¤åå°ä»»åŠ¡åˆ°å…±äº«çº¿ç¨‹æ± ï¼ˆæ›¿ä»£ daemon çº¿ç¨‹ï¼‰"""
        future = self._bg_executor.submit(fn, *args)
        self._bg_futures.append(future)
        # æ¸…ç†å·²å®Œæˆçš„ futuresï¼ˆé˜²æ­¢å†…å­˜æ³„æ¼ï¼‰
        self._bg_futures = [f for f in self._bg_futures if not f.done()]

    def _analyze_ticker_safe(self, ticker: str, index: int, total: int) -> Tuple[str, OpportunityItem, str]:
        """
        åˆ†æå•ä¸ªæ ‡çš„ï¼ˆçº¿ç¨‹å®‰å…¨ï¼Œå¯åœ¨å¹¶è¡Œä¸Šä¸‹æ–‡ä¸­è°ƒç”¨ï¼‰

        Args:
            ticker: è‚¡ç¥¨ä»£ç 
            index: å½“å‰ç´¢å¼•ï¼ˆç”¨äºæ˜¾ç¤ºè¿›åº¦ï¼‰
            total: æ€»æ•°ï¼ˆç”¨äºæ˜¾ç¤ºè¿›åº¦ï¼‰

        Returns:
            (ticker, opportunity_item_or_none, error_message_or_none)
        """
        try:
            # æ„å»ºæœ€å°åŒ–çš„å®æ—¶æ•°æ®ç»“æ„
            realtime_metrics = {
                "ticker": ticker,
                "sources": {
                    "yahoo_finance": {
                        "current_price": 100.0,
                        "change_pct": 2.5
                    }
                }
            }

            # ç”Ÿæˆ ML å¢å¼ºæŠ¥å‘Š
            ml_report = self.ml_generator.generate_ml_enhanced_report(
                ticker, realtime_metrics
            )

            # è§£æä¸º OpportunityItem
            opportunity = self._parse_ml_report_to_opportunity(ticker, ml_report)

            # çº¿ç¨‹å®‰å…¨åœ°æ·»åŠ åˆ°ç»“æœåˆ—è¡¨
            with self._results_lock:
                self.opportunities.append(opportunity)

            return ticker, opportunity, None

        except (ValueError, KeyError, TypeError, AttributeError, OSError) as e:
            _log.error("Ticker analysis failed for %s: %s", ticker, e, exc_info=True)
            error_msg = str(e)
            # çº¿ç¨‹å®‰å…¨åœ°æ·»åŠ è§‚å¯Ÿé¡¹
            with self._results_lock:
                self.observations.append({
                    "ticker": ticker,
                    "status": "error",
                    "error": error_msg
                })
            return ticker, None, error_msg

    def run_daily_scan(self, focus_tickers: List[str] = None) -> Dict:
        """
        æ‰§è¡Œæ¯æ—¥æ‰«æï¼ˆå¹¶è¡Œç‰ˆæœ¬ï¼‰

        Args:
            focus_tickers: é‡ç‚¹å…³æ³¨æ ‡çš„ï¼ˆå¦‚ä¸ºNoneåˆ™æ‰«æå…¨éƒ¨watchlistï¼‰

        Returns:
            å®Œæ•´çš„æ—¥æŠ¥æ•°æ®ç»“æ„
        """
        _log.info("Alpha Hive æ—¥æŠ¥ %s", self.date_str)

        targets = focus_tickers or list(WATCHLIST.keys())[:10]
        _log.info("æ ‡çš„ï¼š%s", " ".join(targets))

        start_parallel = time.time()

        with ThreadPoolExecutor(max_workers=len(targets)) as executor:
            futures = [
                executor.submit(self._analyze_ticker_safe, ticker, i + 1, len(targets))
                for i, ticker in enumerate(targets)
            ]

            for i, future in enumerate(futures, 1):
                ticker, opportunity, error = future.result()
                if error:
                    _log.warning("[%d/%d] %s åˆ†æå¤±è´¥: %s", i, len(targets), ticker, error[:60])
                else:
                    _log.info("[%d/%d] %s: %.1f/10", i, len(targets), ticker, opportunity.opportunity_score)

        elapsed_parallel = time.time() - start_parallel
        _log.info("åˆ†æè€—æ—¶ï¼š%.1fs", elapsed_parallel)

        # æ’åºæœºä¼š
        self.opportunities.sort(key=lambda x: x.opportunity_score, reverse=True)

        # æ„å»ºæŠ¥å‘Š
        report = self._build_report()

        # Phase 2: å¼‚æ­¥ä¿å­˜ä¼šè¯ï¼ˆä½¿ç”¨å…±äº«çº¿ç¨‹æ± ï¼Œé€€å‡ºæ—¶ç­‰å¾…å®Œæˆï¼‰
        if self.memory_store and self._session_id:
            self._submit_bg(
                self.memory_store.save_session,
                self._session_id, self.date_str, "daily_scan",
                targets, {}, [], elapsed_parallel
            )

        return report

    def run_swarm_scan(self, focus_tickers: List[str] = None, progress_callback=None) -> Dict:
        """
        çœŸæ­£çš„èœ‚ç¾¤åä½œæ‰«æ - 7 ä¸ªè‡ªæ²»å·¥èœ‚å¹¶è¡Œè¿è¡Œï¼ˆ6 æ ¸å¿ƒ + BearBeeContrarianï¼‰ï¼Œå®æ—¶é€šè¿‡ä¿¡æ¯ç´ æ¿äº¤æ¢å‘ç°

        Args:
            focus_tickers: é‡ç‚¹å…³æ³¨æ ‡çš„ï¼ˆå¦‚ä¸ºNoneåˆ™æ‰«æå…¨éƒ¨watchlistï¼‰

        Returns:
            å®Œæ•´çš„èœ‚ç¾¤åˆ†ææŠ¥å‘Š
        """
        # Week 4: è®¾ç½® correlation_id è¿½è¸ªæœ¬æ¬¡æ‰«æ
        set_correlation_id(self._session_id or f"swarm_{self.date_str}")
        _log.info("èœ‚ç¾¤åä½œå¯åŠ¨ %s", self.date_str)

        targets = focus_tickers or list(WATCHLIST.keys())[:10]
        _log.info("æ ‡çš„ï¼š%s", " ".join(targets))

        start_time = time.time()

        # åˆ›å»ºå…±äº«çš„ä¿¡æ¯ç´ æ¿
        board = PheromoneBoard(memory_store=self.memory_store, session_id=self._session_id)

        # å®ä¾‹åŒ– Agentï¼šç¬¬ä¸€é˜¶æ®µ 6 ä¸ªæ ¸å¿ƒ Agentï¼ˆå¯é€‰+CodeExecutorï¼‰ï¼Œç¬¬äºŒé˜¶æ®µ BearBeeContrarianï¼ˆè¯»å–ä¿¡æ¯ç´ æ¿ååˆ†æï¼‰
        retriever = self.vector_memory if (self.vector_memory and self.vector_memory.enabled) else None
        phase1_agents = [
            ScoutBeeNova(board, retriever=retriever),
            OracleBeeEcho(board, retriever=retriever),
            BuzzBeeWhisper(board, retriever=retriever),
            ChronosBeeHorizon(board, retriever=retriever),
            RivalBeeVanguard(board, retriever=retriever),
            GuardBeeSentinel(board, retriever=retriever),
        ]
        # çœ‹ç©ºå¯¹å†²èœ‚ï¼šäºŒé˜¶æ®µæ‰§è¡Œï¼ˆç­‰å…¶ä»– Agent å†™å…¥ä¿¡æ¯ç´ æ¿åå†åˆ†æï¼‰
        bear_agent = BearBeeContrarian(board, retriever=retriever)

        # Phase 3 P4: åŠ¨æ€æ³¨å…¥ CodeExecutorAgent
        if self.code_executor_agent and CODE_EXECUTION_CONFIG.get("add_to_swarm"):
            self.code_executor_agent.board = board
            phase1_agents.append(self.code_executor_agent)

        # Phase 6: è‡ªé€‚åº”æƒé‡
        adapted_w = Backtester.load_adapted_weights() if Backtester else None
        queen = QueenDistiller(board, adapted_weights=adapted_w)

        all_agents = phase1_agents + [bear_agent]
        _log.info("%d Agentï¼ˆå«äºŒé˜¶æ®µçœ‹ç©ºèœ‚ï¼‰| é¢„å–æ•°æ®ä¸­...", len(all_agents))

        # âš¡ ä¼˜åŒ– #1+#2: æ‰¹é‡é¢„å– yfinance + VectorMemoryï¼ˆæ¯ ticker ä»… 1 æ¬¡ï¼‰
        prefetched = prefetch_shared_data(targets, retriever)
        inject_prefetched(all_agents, prefetched)
        prefetch_elapsed = time.time() - start_time
        _log.info("é¢„å–å®Œæˆ (%.1fs) | å¼€å§‹å¹¶è¡Œåˆ†æ", prefetch_elapsed)

        # âš¡ ä¼˜åŒ– #3: å•å±‚çº¿ç¨‹æ± ï¼ŒæŒ‰ ticker ä¸²è¡Œã€Agent å¹¶è¡Œ
        swarm_results = {}

        # Phase 2: å´©æºƒæ¢å¤ checkpoint
        checkpoint_file = self.report_dir / f".checkpoint_{self._session_id or 'default'}.json"
        completed_tickers = set()
        if checkpoint_file.exists():
            try:
                with open(checkpoint_file, "r") as f:
                    ckpt = json.load(f)
                    swarm_results = ckpt.get("results", {})
                    completed_tickers = set(swarm_results.keys())
                    if completed_tickers:
                        _log.info("æ¢å¤ checkpointï¼š%d æ ‡çš„å·²å®Œæˆ", len(completed_tickers))
            except (json.JSONDecodeError, KeyError, OSError) as e:
                _log.warning("Checkpoint æ¢å¤å¤±è´¥ï¼Œé‡æ–°å¼€å§‹: %s", e)

        for idx, ticker in enumerate(targets, 1):
            if ticker in completed_tickers:
                res = "âœ…" if swarm_results[ticker]["resonance"]["resonance_detected"] else "â€”"
                _log.info("[%d/%d] %s: %.1f/10 (å·²ç¼“å­˜) %s", idx, len(targets), ticker, swarm_results[ticker]['final_score'], res)
                continue

            # ç¬¬ä¸€é˜¶æ®µï¼š6 ä¸ªæ ¸å¿ƒ Agent å¹¶è¡Œåˆ†æï¼ˆå«å¯é€‰ CodeExecutorAgentï¼‰
            with ThreadPoolExecutor(max_workers=len(phase1_agents)) as executor:
                futures = {executor.submit(agent.analyze, ticker): agent for agent in phase1_agents}
                agent_results = []
                for future in as_completed(futures):
                    try:
                        agent_results.append(future.result(timeout=60))
                    except (TimeoutError, ValueError, KeyError, TypeError, RuntimeError) as e:
                        _log.warning("Agent future failed: %s", e)
                        agent_results.append(None)

            # ç¬¬äºŒé˜¶æ®µï¼šBearBeeContrarian è¯»å–ä¿¡æ¯ç´ æ¿ååˆ†æï¼ˆæ­¤æ—¶å…¶ä»– Agent æ•°æ®å·²å¯ç”¨ï¼‰
            try:
                bear_result = bear_agent.analyze(ticker)
                agent_results.append(bear_result)
                _log.info("  ğŸ» çœ‹ç©ºèœ‚: %s %s (%.1fåˆ†, %dä¿¡å·)",
                          ticker, bear_result.get("direction", "?"),
                          bear_result.get("details", {}).get("bear_score", 0),
                          len(bear_result.get("details", {}).get("bearish_signals", [])))
            except (ValueError, KeyError, TypeError, AttributeError) as e:
                _log.warning("BearBeeContrarian failed for %s: %s", ticker, e)
                agent_results.append(None)

            distilled = queen.distill(ticker, agent_results)
            swarm_results[ticker] = distilled

            res = "âœ…" if distilled["resonance"]["resonance_detected"] else "â€”"
            _log.info("[%d/%d] %s: %.1f/10 %s %s", idx, len(targets), ticker, distilled['final_score'], distilled['direction'], res)

            # è¿›åº¦å›è°ƒï¼ˆä¾›æ¡Œé¢ App å®æ—¶åŠ¨ç”»ä½¿ç”¨ï¼‰
            if progress_callback:
                try:
                    progress_callback(idx, len(targets), ticker, distilled)
                except Exception as _cb_err:
                    _log.debug("Progress callback error: %s", _cb_err)

            # å†™å…¥ checkpointï¼ˆæ¯ä¸ª ticker å®Œæˆåï¼‰
            try:
                with open(checkpoint_file, "w") as f:
                    json.dump({"results": swarm_results, "targets": targets}, f, default=str)
            except (OSError, TypeError) as e:
                _log.warning("Checkpoint å†™å…¥å¤±è´¥: %s", e)

        # æ‰«æå®Œæˆï¼Œä¿å­˜èœ‚ç¾¤ç»“æœä¾› ML æŠ¥å‘ŠåŒæ­¥ä½¿ç”¨
        try:
            swarm_json = self.report_dir / f".swarm_results_{self.date_str}.json"
            with open(swarm_json, "w") as f:
                json.dump(swarm_results, f, default=str, ensure_ascii=False)
        except (OSError, TypeError) as e:
            _log.warning("Swarm results ä¿å­˜å¤±è´¥: %s", e)
        # æ¸…ç† checkpoint
        try:
            checkpoint_file.unlink(missing_ok=True)
        except OSError as e:
            _log.debug("Checkpoint æ¸…ç†å¤±è´¥: %s", e)

        elapsed = time.time() - start_time

        # LLM Token ä½¿ç”¨ç»Ÿè®¡
        try:
            import llm_service
            usage = llm_service.get_usage()
            if usage["call_count"] > 0:
                _log.info("èœ‚ç¾¤è€—æ—¶ï¼š%.1fs | LLM: %dè°ƒç”¨ $%.4f", elapsed, usage['call_count'], usage['total_cost_usd'])
            else:
                _log.info("èœ‚ç¾¤è€—æ—¶ï¼š%.1fs | è§„åˆ™å¼•æ“æ¨¡å¼", elapsed)
        except (ImportError, AttributeError, KeyError) as e:
            _log.info("èœ‚ç¾¤è€—æ—¶ï¼š%.1fs (LLM stats unavailable: %s)", elapsed, e)

        # Week 4: è®°å½•æ‰«ææŒ‡æ ‡ + SLO æ£€æŸ¥
        if self.metrics:
            try:
                scores = [d.get("final_score", 5.0) for d in swarm_results.values()]
                agent_errors = sum(
                    1 for d in swarm_results.values()
                    if d.get("supporting_agents", 0) == 0
                )
                resonance_n = sum(
                    1 for d in swarm_results.values()
                    if d.get("resonance", {}).get("resonance_detected")
                )
                avg_real = (
                    sum(d.get("data_real_pct", 0) for d in swarm_results.values()) / len(swarm_results)
                    if swarm_results else 0
                )
                llm_c, llm_cost = 0, 0.0
                try:
                    import llm_service as _ls
                    _u = _ls.get_usage()
                    llm_c, llm_cost = _u.get("call_count", 0), _u.get("total_cost_usd", 0.0)
                except (ImportError, AttributeError, KeyError):
                    pass

                self.metrics.record_scan(
                    ticker_count=len(swarm_results),
                    duration_seconds=elapsed,
                    agent_count=len(all_agents),
                    prefetch_seconds=prefetch_elapsed,
                    avg_score=sum(scores) / len(scores) if scores else 5.0,
                    max_score=max(scores) if scores else 5.0,
                    min_score=min(scores) if scores else 5.0,
                    agent_errors=agent_errors,
                    agent_total=len(swarm_results) * len(all_agents),
                    data_real_pct=avg_real,
                    resonance_count=resonance_n,
                    llm_calls=llm_c,
                    llm_cost_usd=llm_cost,
                    session_id=self._session_id or "",
                    scan_mode="swarm",
                )
                for ticker, data in swarm_results.items():
                    self.metrics.record_ticker(
                        ticker=ticker,
                        final_score=data.get("final_score", 5.0),
                        direction=data.get("direction", "neutral"),
                        supporting_agents=data.get("supporting_agents", 0),
                        data_real_pct=data.get("data_real_pct", 0),
                        resonance_detected=data.get("resonance", {}).get("resonance_detected", False),
                        session_id=self._session_id or "",
                    )

                # SLO æ£€æŸ¥
                violations = self.metrics.check_slo(days=1)
                if violations:
                    _log.warning("SLO è¿è§„ %d æ¡: %s",
                                 len(violations),
                                 "; ".join(v["details"] for v in violations))
            except (OSError, ValueError, KeyError, TypeError) as e:
                _log.warning("æŒ‡æ ‡æ”¶é›†å¼‚å¸¸: %s", e)

        # Phase 6: å›æµ‹åé¦ˆå¾ªç¯
        if Backtester:
            try:
                bt = Backtester()
                bt.save_predictions(swarm_results)
                bt.run_backtest()
                bt.adapt_weights(min_samples=5)
            except (OSError, ValueError, KeyError, TypeError) as e:
                _log.warning("å›æµ‹å¼‚å¸¸: %s", e)

        # Phase 6: Slack æ¨é€é«˜åˆ†æœºä¼š + å¼‚å¸¸ä¿¡å·
        if self.slack_notifier and self.slack_notifier.enabled:
            for ticker, data in swarm_results.items():
                score = data.get("final_score", 0)
                direction = data.get("direction", "neutral")
                dir_cn = {"bullish": "çœ‹å¤š", "bearish": "çœ‹ç©º", "neutral": "ä¸­æ€§"}.get(direction, direction)

                # é«˜åˆ†æœºä¼šæ¨é€ï¼ˆ>= 7.5ï¼‰
                if score >= 7.5:
                    self._submit_bg(
                        self.slack_notifier.send_opportunity_alert,
                        ticker, score, dir_cn,
                        data.get("discovery", "é«˜åˆ†æœºä¼š"),
                        [f"è¯„åˆ† {score:.1f}/10"]
                    )

                # å¼‚å¸¸ä¿¡å·æ¨é€ï¼šå¼ºçœ‹ç©º æˆ– å†…å¹•å¤§é¢äº¤æ˜“
                elif score <= 3.0:
                    self._submit_bg(
                        self.slack_notifier.send_risk_alert,
                        f"{ticker} ä½åˆ†é¢„è­¦",
                        f"èœ‚ç¾¤è¯„åˆ†ä»… {score:.1f}/10ï¼Œæ–¹å‘ {dir_cn}",
                        "HIGH"
                    )

        # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        report = self._build_swarm_report(swarm_results, board, agent_count=len(all_agents))

        # Phase 3 P2: ä¸ºé«˜åˆ†æœºä¼šæ·»åŠ æ—¥å†æé†’ï¼ˆåå°çº¿ç¨‹æ± ï¼Œé€€å‡ºæ—¶ç­‰å¾…å®Œæˆï¼‰
        if self.calendar and report.get('opportunities'):
            for opp in report['opportunities']:
                if opp.opportunity_score >= 7.5:
                    self._submit_bg(
                        self.calendar.add_opportunity_reminder,
                        opp.ticker, opp.opportunity_score, opp.direction,
                        f"{opp.key_catalysts[0] if opp.key_catalysts else 'é«˜åˆ†æœºä¼š'}"
                    )

        # Phase 2: å¼‚æ­¥ä¿å­˜ä¼šè¯ï¼ˆä½¿ç”¨å…±äº«çº¿ç¨‹æ± ï¼Œé€€å‡ºæ—¶ç­‰å¾…å®Œæˆï¼‰
        if self.memory_store and self._session_id:
            snapshot = board.compact_snapshot()  # åœ¨ä¸»çº¿ç¨‹å–å¿«ç…§ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
            self._submit_bg(
                self.memory_store.save_session,
                self._session_id, self.date_str, "swarm",
                targets, swarm_results, snapshot, elapsed
            )

        # Phase 3 å†…å­˜ä¼˜åŒ–: å°†é«˜ä»·å€¼å‘ç°å­˜å…¥å‘é‡è®°å¿†ï¼ˆé•¿æœŸè®°å¿†ï¼‰
        if self.vector_memory and self.vector_memory.enabled:
            stored = 0
            # 1. å­˜å‚¨ Queen çš„æœ€ç»ˆè¯„åˆ†
            for ticker, data in swarm_results.items():
                if data.get("final_score", 0) >= 5.0:
                    self.vector_memory.store(
                        ticker=ticker,
                        agent_id="QueenDistiller",
                        discovery=f"è¯„åˆ†{data['final_score']:.1f} {data['direction']} "
                                  f"æ”¯æŒ{data.get('supporting_agents', 0)}Agent",
                        direction=data["direction"],
                        score=data["final_score"],
                        source="swarm_scan",
                        session_id=self._session_id or ""
                    )
                    stored += 1
            # 2. å­˜å‚¨ä¿¡æ¯ç´ æ¿ä¸Šæ¯ä¸ª Agent çš„é«˜ä»·å€¼å‘ç°
            for entry in board.snapshot():
                if entry.get("self_score", 0) >= 6.0:
                    self.vector_memory.store(
                        ticker=entry.get("ticker", ""),
                        agent_id=entry.get("agent_id", ""),
                        discovery=entry.get("discovery", "")[:300],
                        direction=entry.get("direction", "neutral"),
                        score=entry.get("self_score", 5.0),
                        source=entry.get("source", ""),
                        session_id=self._session_id or ""
                    )
                    stored += 1
            if stored > 0:
                _log.info("å·²å­˜å…¥ %d æ¡é•¿æœŸè®°å¿† (Chroma)", stored)

        return report

    def run_crew_scan(self, focus_tickers: List[str] = None) -> Dict:
        """
        CrewAI æ¨¡å¼èœ‚ç¾¤æ‰«æ - ä½¿ç”¨ Process.hierarchical ä¸»-å­ Agent é€’å½’è°ƒåº¦
        è‹¥ crewai æœªå®‰è£…ï¼Œè‡ªåŠ¨é™çº§åˆ° run_swarm_scan()

        Args:
            focus_tickers: é‡ç‚¹å…³æ³¨æ ‡çš„ï¼ˆå¦‚ä¸ºNoneåˆ™æ‰«æå…¨éƒ¨watchlistï¼‰

        Returns:
            å®Œæ•´çš„èœ‚ç¾¤åˆ†ææŠ¥å‘Š
        """
        # æ£€æŸ¥ CrewAI æ˜¯å¦å¯ç”¨
        if not AlphaHiveCrew or not CREWAI_CONFIG.get("enabled"):
            _log.info("CrewAI æœªå®‰è£…æˆ–æœªå¯ç”¨ï¼Œé™çº§åˆ°æ ‡å‡†èœ‚ç¾¤æ¨¡å¼")
            return self.run_swarm_scan(focus_tickers)

        _log.info("CrewAI æ¨¡å¼ %s", self.date_str)

        targets = focus_tickers or list(WATCHLIST.keys())[:10]
        _log.info("æ ‡çš„ï¼š%s", " ".join(targets))

        # åˆ›å»ºå…±äº«çš„ä¿¡æ¯ç´ æ¿
        board = PheromoneBoard(memory_store=self.memory_store, session_id=self._session_id)

        # æ„å»º CrewAI Crew
        crew = AlphaHiveCrew(board=board, memory_store=self.memory_store)
        crew.build(targets)

        _log.info("CrewAI %d Agent", crew.get_agents_count())

        swarm_results = {}
        start_time = time.time()

        # ä½¿ç”¨ CrewAI åˆ†ææ¯ä¸ªæ ‡çš„
        for i, ticker in enumerate(targets, 1):
            _log.info("[%d/%d] CrewAI åˆ†æ %s", i, len(targets), ticker)

            try:
                result = crew.analyze(ticker)
                swarm_results[ticker] = result

                _log.info("  %s: %.1f/10 %s", ticker, result.get('final_score', 0), result.get('direction', 'neutral'))

            except (ValueError, KeyError, TypeError, RuntimeError, ConnectionError) as e:
                _log.warning("  %s CrewAI åˆ†æå¤±è´¥: %s", ticker, str(e)[:80])
                swarm_results[ticker] = {
                    "ticker": ticker,
                    "final_score": 0.0,
                    "direction": "neutral",
                    "discovery": f"CrewAI åˆ†æå¤±è´¥: {str(e)}",
                    "error": str(e)
                }

        elapsed = time.time() - start_time
        _log.info("CrewAI è€—æ—¶ï¼š%.1fs", elapsed)

        # è½¬æ¢ä¸ºæ ‡å‡†æŠ¥å‘Šæ ¼å¼ï¼ˆå…¼å®¹ run_swarm_scan è¾“å‡ºï¼‰
        # CrewAI æ¨¡å¼ï¼š6 æ ¸å¿ƒ BeeAgent + BearBeeContrarian = 7
        report = self._build_swarm_report(swarm_results, board, agent_count=7)

        # å¼‚æ­¥ä¿å­˜ä¼šè¯ï¼ˆä½¿ç”¨å…±äº«çº¿ç¨‹æ± ï¼Œé€€å‡ºæ—¶ç­‰å¾…å®Œæˆï¼‰
        if self.memory_store and self._session_id:
            snapshot = board.compact_snapshot()
            self._submit_bg(
                self.memory_store.save_session,
                self._session_id, self.date_str, "crew_scan",
                targets, swarm_results, snapshot, elapsed
            )

        return report

    def _build_swarm_report(self, swarm_results: Dict, board: PheromoneBoard,
                            agent_count: int = 7) -> Dict:
        """
        å°†èœ‚ç¾¤åˆ†æç»“æœè½¬æ¢ä¸ºæ ‡å‡†æŠ¥å‘Šæ ¼å¼

        Args:
            swarm_results: QueenDistiller çš„æ‰€æœ‰æ±‡æ€»ç»“æœ
            board: ä¿¡æ¯ç´ æ¿ï¼ˆç”¨äºæå–å…¨å±€ä¿¡æ¯ï¼‰
            agent_count: å®é™…è¿è¡Œçš„ Agent æ€»æ•°ï¼ˆPhase-1 + BearBeeContrarian + å¯é€‰ CodeExecutorï¼‰

        Returns:
            æ ‡å‡†æŠ¥å‘Šæ ¼å¼
        """
        # æ’åºç»“æœ
        sorted_results = sorted(
            swarm_results.items(),
            key=lambda x: x[1]["final_score"],
            reverse=True
        )

        # æ„å»º OpportunityItem åˆ—è¡¨ï¼ˆå…¼å®¹ç°æœ‰æŠ¥å‘Šæ ¼å¼ï¼‰
        opportunities = []
        for ticker, swarm_data in sorted_results:
            opp = OpportunityItem(
                ticker=ticker,
                direction="çœ‹å¤š" if swarm_data["direction"] == "bullish" else (
                    "çœ‹ç©º" if swarm_data["direction"] == "bearish" else "ä¸­æ€§"
                ),
                signal_score=swarm_data["final_score"],
                catalyst_score=swarm_data["final_score"] * 0.9,
                sentiment_score=swarm_data["final_score"] * 0.85,
                odds_score=swarm_data["final_score"] * 0.8,
                risk_score=swarm_data["final_score"] * 0.95,
                options_score=swarm_data["final_score"] * 0.88,
                opportunity_score=swarm_data["final_score"],
                confidence=min(95, swarm_data["final_score"] * 10) if swarm_data["final_score"] >= 7.5 else 60,
                key_catalysts=["å¤š Agent å…±æŒ¯ä¿¡å·"] if swarm_data["resonance"]["resonance_detected"] else ["å¾…éªŒè¯"],
                options_signal=f"å…±æŒ¯ä¿¡å· ({swarm_data['resonance']['supporting_agents']} Agent)",
                risks=["å¤šå¤´æ‹¥æŒ¤"] if swarm_data["resonance"]["resonance_detected"] else [],
                thesis_break="ä¿¡å·åˆ†æ•£"
            )
            opportunities.append(opp)

        self.opportunities = opportunities

        # â”€â”€ P4: æŠ•èµ„ç»„åˆé›†ä¸­åº¦åˆ†æï¼ˆæ¿å—é‡å  + ç›¸å…³æ€§çŸ©é˜µï¼‰â”€â”€
        concentration = {}
        try:
            from portfolio_concentration import analyze_concentration
            from config import WATCHLIST
            concentration = analyze_concentration(swarm_results, WATCHLIST)
            _log.info("P4 é›†ä¸­åº¦åˆ†æï¼š%sï¼ˆé£é™©=%sï¼‰",
                      concentration.get("summary", ""), concentration.get("concentration_risk", ""))
        except (ImportError, ValueError, KeyError, TypeError, AttributeError) as e:
            _log.debug("P4 portfolio_concentration ä¸å¯ç”¨: %s", e)

        # â”€â”€ P5: å®è§‚ç¯å¢ƒå¿«ç…§ï¼ˆé™„åŠ åˆ°æŠ¥å‘Šå…ƒæ•°æ®ï¼‰â”€â”€
        macro_snapshot = {}
        try:
            from fred_macro import get_macro_context
            macro_snapshot = get_macro_context()
            _log.info("P5 å®è§‚ç¯å¢ƒï¼š%s", macro_snapshot.get("summary", ""))
        except (ImportError, ConnectionError, TimeoutError, ValueError, KeyError) as e:
            _log.debug("P5 fred_macro ä¸å¯ç”¨: %s", e)

        # â”€â”€ P3: è·å–å›æµ‹å‡†ç¡®ç‡ç»Ÿè®¡ï¼ˆé™„åŠ åˆ°æŠ¥å‘Šï¼‰â”€â”€
        backtest_stats = {}
        try:
            if Backtester:
                _bt = Backtester()
                backtest_stats = _bt.store.get_accuracy_stats("t7", days=30)
        except (OSError, ValueError, KeyError, TypeError) as e:
            _log.debug("Backtest stats unavailable: %s", e)

        # æ„å»ºæ ‡å‡†æŠ¥å‘Š
        report = {
            "date": self.date_str,
            "timestamp": self.timestamp.isoformat(),
            "system_status": "âœ… èœ‚ç¾¤åä½œå®Œæˆ",
            "phase_completed": "å®Œæ•´èœ‚ç¾¤æµç¨‹ (Swarm Mode)",
            "swarm_metadata": {
                "total_agents": agent_count,
                "tickers_analyzed": len(swarm_results),
                "resonances_detected": sum(1 for r in swarm_results.values() if r["resonance"]["resonance_detected"]),
                "pheromone_board_entries": board.get_entry_count()
            },
            "concentration_analysis": concentration,
            "macro_context": macro_snapshot,
            "backtest_stats": backtest_stats,
            "markdown_report": self._generate_swarm_markdown_report(swarm_results, concentration, macro_snapshot, backtest_stats, agent_count=agent_count),
            "twitter_threads": self._generate_swarm_twitter_threads(swarm_results),
            "opportunities": [
                {
                    "rank": i + 1,
                    "ticker": opp.ticker,
                    "direction": opp.direction,
                    "opp_score": round(opp.opportunity_score, 1),
                    "confidence": f"{opp.confidence:.0f}%",
                    "resonance": swarm_results[opp.ticker]["resonance"]["resonance_detected"],
                    "supporting_agents": swarm_results[opp.ticker]["supporting_agents"],
                    "thesis_break": opp.thesis_break
                }
                for i, opp in enumerate(self.opportunities[:5])
            ]
        }

        return report

    def _generate_swarm_markdown_report(self, swarm_results: Dict,
                                         concentration: Dict = None,
                                         macro_context: Dict = None,
                                         backtest_stats: Dict = None,
                                         agent_count: int = 7) -> str:
        """ç”Ÿæˆèœ‚ç¾¤æ¨¡å¼çš„ Markdown æŠ¥å‘Šï¼ˆ8 ç‰ˆå— + P4é›†ä¸­åº¦ + P5å®è§‚ + P3å›æµ‹ï¼‰"""

        md = []
        md.append(f"# ã€{self.date_str}ã€‘Alpha Hive èœ‚ç¾¤åä½œæ—¥æŠ¥")
        md.append("")
        md.append(f"**è‡ªåŠ¨ç”Ÿæˆäº**ï¼š{self.timestamp.strftime('%Y-%m-%d %H:%M:%S')}")
        md.append(f"**ç³»ç»Ÿæ¨¡å¼**ï¼šå®Œå…¨å»ä¸­å¿ƒåŒ–èœ‚ç¾¤åä½œ | {agent_count} ä¸ªè‡ªæ²»å·¥èœ‚ï¼ˆ6 æ ¸å¿ƒ + BearBeeContrarianï¼‰")
        md.append("")

        sorted_results = sorted(
            swarm_results.items(),
            key=lambda x: x[1]["final_score"],
            reverse=True
        )

        # ====== ç‰ˆå— 1ï¼šä»Šæ—¥æ‘˜è¦ ======
        resonances = sum(1 for r in swarm_results.values() if r["resonance"]["resonance_detected"])
        md.append("## 1) ä»Šæ—¥æ‘˜è¦")
        md.append("")
        md.append(f"- æ‰«ææ ‡çš„ï¼š{len(swarm_results)} ä¸ª | å…±æŒ¯ä¿¡å·ï¼š{resonances}/{len(swarm_results)}")
        for i, (ticker, data) in enumerate(sorted_results[:3], 1):
            res = "å…±æŒ¯" if data["resonance"]["resonance_detected"] else ""
            md.append(f"- **{ticker}** {data['direction'].upper()} {data['final_score']:.1f}/10 {res}")
        md.append("")

        # ====== ç‰ˆå— 2ï¼šä»Šæ—¥èªæ˜é’±åŠ¨å‘ï¼ˆScoutBeeNovaï¼‰ ======
        md.append("## 2) ä»Šæ—¥èªæ˜é’±åŠ¨å‘")
        md.append("")
        for ticker, data in sorted_results:
            agent = data.get("agent_details", {}).get("ScoutBeeNova", {})
            discovery = agent.get("discovery", "")
            details = agent.get("details", {})
            insider = details.get("insider", {})
            md.append(f"### {ticker}")
            if discovery:
                md.append(f"- {discovery}")
            if insider:
                sentiment = insider.get("sentiment", "unknown")
                bought = insider.get("dollar_bought", 0)
                sold = insider.get("dollar_sold", 0)
                filings = insider.get("filings", 0)
                md.append(f"- å†…å¹•äº¤æ˜“æƒ…ç»ªï¼š**{sentiment}** | ç”³æŠ¥æ•°ï¼š{filings}")
                if bought > 0:
                    md.append(f"- å†…å¹•ä¹°å…¥é‡‘é¢ï¼š${bought:,.0f}")
                if sold > 0:
                    md.append(f"- å†…å¹•å–å‡ºé‡‘é¢ï¼š${sold:,.0f}")
                notable = insider.get("notable_trades", [])
                for t in notable[:2]:
                    if isinstance(t, dict):
                        md.append(f"  - {t.get('insider', '?')}ï¼š{t.get('code_desc', '?')} {t.get('shares', 0):,.0f} è‚¡")
            crowding = details.get("crowding_score", "")
            if crowding:
                md.append(f"- æ‹¥æŒ¤åº¦ï¼š{crowding:.0f}/100")
            md.append("")

        # ====== ç‰ˆå— 3ï¼šå¸‚åœºéšå«é¢„æœŸï¼ˆOracleBeeEchoï¼‰ ======
        md.append("## 3) å¸‚åœºéšå«é¢„æœŸ")
        md.append("")
        for ticker, data in sorted_results:
            agent = data.get("agent_details", {}).get("OracleBeeEcho", {})
            discovery = agent.get("discovery", "")
            details = agent.get("details", {})
            md.append(f"### {ticker}")
            if discovery:
                md.append(f"- {discovery}")
            if isinstance(details, dict) and details:
                iv = details.get("iv_rank")
                pc = details.get("put_call_ratio")
                gamma = details.get("gamma_exposure")
                if iv is not None:
                    md.append(f"- IV Rankï¼š{iv}")
                if pc is not None:
                    pc_val = pc if isinstance(pc, (int, float)) else pc
                    md.append(f"- Put/Call Ratioï¼š{pc_val}")
                if gamma is not None:
                    md.append(f"- Gamma Exposureï¼š{gamma}")
                # å¼‚å¸¸æ´»åŠ¨
                unusual = details.get("unusual_activity", [])
                if unusual:
                    md.append(f"- å¼‚å¸¸æ´»åŠ¨ï¼š{len(unusual)} ä¸ªä¿¡å·")
                    for u in unusual[:3]:
                        if isinstance(u, dict):
                            utype = u.get("type", "unknown").replace("_", " ")
                            strike = u.get("strike", "")
                            vol = u.get("volume", 0)
                            bull = "çœ‹æ¶¨" if u.get("bullish") else "çœ‹è·Œ"
                            md.append(f"  - {bull} {utype} ${strike} ({vol:,.0f}æ‰‹)")
                        elif isinstance(u, str):
                            md.append(f"  - {u}")
            md.append("")

        # ====== ç‰ˆå— 4ï¼šX æƒ…ç»ªæ±‡æ€»ï¼ˆBuzzBeeWhisperï¼‰ ======
        md.append("## 4) X æƒ…ç»ªæ±‡æ€»")
        md.append("")
        for ticker, data in sorted_results:
            agent = data.get("agent_details", {}).get("BuzzBeeWhisper", {})
            discovery = agent.get("discovery", "")
            details = agent.get("details", {})
            md.append(f"### {ticker}")
            if discovery:
                md.append(f"- {discovery}")
            if isinstance(details, dict) and details:
                sent_pct = details.get("sentiment_pct")
                mom = details.get("momentum_5d")
                vol = details.get("volume_ratio")
                if sent_pct is not None:
                    md.append(f"- çœ‹å¤šæƒ…ç»ªï¼š{sent_pct}%")
                if mom is not None:
                    md.append(f"- 5 æ—¥åŠ¨é‡ï¼š{mom:+.1f}%")
                if vol is not None:
                    md.append(f"- é‡æ¯”ï¼š{vol:.1f}x")
                reddit = details.get("reddit_mentions") or details.get("reddit_rank")
                if reddit:
                    md.append(f"- Reddit çƒ­åº¦ï¼š{reddit}")
            md.append("")

        # ====== ç‰ˆå— 5ï¼šè´¢æŠ¥/äº‹ä»¶å‚¬åŒ–å‰‚ï¼ˆChronosBeeHorizonï¼‰ ======
        md.append("## 5) è´¢æŠ¥/äº‹ä»¶å‚¬åŒ–å‰‚")
        md.append("")
        for ticker, data in sorted_results:
            agent = data.get("agent_details", {}).get("ChronosBeeHorizon", {})
            discovery = agent.get("discovery", "")
            details = agent.get("details", {})
            md.append(f"### {ticker}")
            if discovery:
                md.append(f"- {discovery}")
            if isinstance(details, dict) and details:
                earnings = details.get("next_earnings") or details.get("earnings_date")
                if earnings:
                    md.append(f"- ä¸‹æ¬¡è´¢æŠ¥ï¼š{earnings}")
                events = details.get("upcoming_events") or details.get("catalysts", [])
                if isinstance(events, list):
                    for ev in events[:3]:
                        if isinstance(ev, dict):
                            md.append(f"  - {ev.get('date', '?')}ï¼š{ev.get('event', ev.get('description', '?'))}")
                        elif isinstance(ev, str):
                            md.append(f"  - {ev}")
                past = details.get("recent_events", [])
                if isinstance(past, list):
                    for ev in past[:2]:
                        if isinstance(ev, dict):
                            md.append(f"  - [å·²å‘ç”Ÿ] {ev.get('description', ev)}")
            md.append("")

        # ====== ç‰ˆå— 6ï¼šç«äº‰æ ¼å±€åˆ†æï¼ˆRivalBeeVanguardï¼‰ ======
        md.append("## 6) ç«äº‰æ ¼å±€åˆ†æ")
        md.append("")
        for ticker, data in sorted_results:
            agent = data.get("agent_details", {}).get("RivalBeeVanguard", {})
            discovery = agent.get("discovery", "")
            details = agent.get("details", {})
            md.append(f"### {ticker}")
            if discovery:
                md.append(f"- {discovery}")
            if isinstance(details, dict) and details:
                ml_pred = details.get("ml_prediction") or details.get("prediction")
                if isinstance(ml_pred, dict):
                    md.append(f"- ML é¢„æµ‹æ–¹å‘ï¼š{ml_pred.get('direction', '?')}")
                    md.append(f"- ML ç½®ä¿¡åº¦ï¼š{ml_pred.get('confidence', '?')}")
                peers = details.get("peer_comparison") or details.get("peers", [])
                if isinstance(peers, list) and peers:
                    md.append(f"- åŒä¸šå¯¹æ ‡ï¼š{', '.join(str(p) for p in peers[:5])}")
            md.append("")

        # ====== ç‰ˆå— 6.5ï¼šçœ‹ç©ºå¯¹å†²è§‚ç‚¹ï¼ˆBearBeeContrarianï¼‰ ======
        md.append("## 6.5) çœ‹ç©ºå¯¹å†²è§‚ç‚¹")
        md.append("")
        md.append("> BearBeeContrarian ä¸“é—¨å¯»æ‰¾çœ‹ç©ºä¿¡å·ï¼Œå¹³è¡¡èœ‚ç¾¤ç³»ç»Ÿæ€§çœ‹å¤šåå·®")
        md.append("")
        for ticker, data in sorted_results:
            agent = data.get("agent_details", {}).get("BearBeeContrarian", {})
            discovery = agent.get("discovery", "")
            details = agent.get("details", {})
            bear_score = details.get("bear_score", 0)
            signals = details.get("bearish_signals", [])
            direction = agent.get("direction", "neutral")

            if direction == "bearish":
                severity = "**çœ‹ç©ºè­¦å‘Š**"
            elif direction == "neutral":
                severity = "éœ€å…³æ³¨é£é™©ç‚¹"
            elif signals:
                severity = "é£é™©æç¤º"
            else:
                severity = "æš‚æ— çœ‹ç©ºä¿¡å·"

            md.append(f"### {ticker} ({severity} | çœ‹ç©ºå¼ºåº¦ {bear_score:.1f}/10)")
            if signals:
                for sig in signals:
                    md.append(f"- {sig}")
            elif discovery:
                md.append(f"- {discovery}")
            else:
                md.append("- æœªå‘ç°æ˜¾è‘—çœ‹ç©ºä¿¡å·")
            # æ•°æ®æ¥æºæ ‡æ³¨
            sources = details.get("data_sources", {})
            if sources:
                src_labels = {"pheromone_board": "èœ‚ç¾¤å…±äº«", "sec_api": "SECç›´æŸ¥",
                              "options_api": "æœŸæƒç›´æŸ¥", "finviz_api": "Finviz",
                              "yfinance": "yfinance", "unavailable": "ä¸å¯ç”¨"}
                src_parts = [f"{k}={src_labels.get(v, v)}" for k, v in sources.items()]
                md.append(f"- *æ•°æ®æ¥æº*ï¼š{' | '.join(src_parts)}")
            md.append("")

        # ====== ç‰ˆå— 7ï¼šç»¼åˆåˆ¤æ–­ & ä¿¡å·å¼ºåº¦ï¼ˆGuardBeeSentinel + å…¨ä½“æŠ•ç¥¨ï¼‰ ======
        md.append("## 7) ç»¼åˆåˆ¤æ–­ & ä¿¡å·å¼ºåº¦")
        md.append("")
        md.append("| æ ‡çš„ | æ–¹å‘ | ç»¼åˆåˆ† | å…±æŒ¯ | æŠ•ç¥¨(å¤š/ç©º/ä¸­) | æ•°æ®% | å¤±æ•ˆæ¡ä»¶ |")
        md.append("|------|------|--------|------|---------------|-------|---------|")
        for ticker, data in sorted_results:
            res = "Y" if data["resonance"]["resonance_detected"] else "N"
            ab = data["agent_breakdown"]
            data_pct = data.get("data_real_pct", 0)
            # ä» GuardBeeSentinel è·å–äº¤å‰éªŒè¯ä¿¡æ¯
            guard = data.get("agent_details", {}).get("GuardBeeSentinel", {})
            guard_discovery = guard.get("discovery", "")
            thesis_break = "ä¿¡å·åˆ†æ•£" if not guard_discovery else guard_discovery[:30]
            md.append(
                f"| **{ticker}** | {data['direction'].upper()} | "
                f"{data['final_score']:.1f} | {res} | "
                f"{ab['bullish']}/{ab['bearish']}/{ab['neutral']} | "
                f"{data_pct:.0f}% | {thesis_break} |"
            )
        md.append("")

        # GuardBeeSentinel è¯¦ç»†äº¤å‰éªŒè¯
        md.append("### äº¤å‰éªŒè¯è¯¦æƒ…")
        md.append("")
        for ticker, data in sorted_results:
            guard = data.get("agent_details", {}).get("GuardBeeSentinel", {})
            discovery = guard.get("discovery", "")
            if discovery:
                md.append(f"- **{ticker}**ï¼š{discovery}")
        md.append("")

        # ====== ç‰ˆå— P4ï¼šæŠ•èµ„ç»„åˆé›†ä¸­åº¦é£é™© ======
        if concentration and concentration.get("sector_breakdown"):
            risk_level = concentration.get("concentration_risk", "low")
            risk_emoji = {"low": "âœ…", "medium": "âš ï¸", "high": "ğŸš¨"}.get(risk_level, "")
            md.append(f"## ğŸ“Š æŠ•èµ„ç»„åˆé›†ä¸­åº¦åˆ†æ {risk_emoji}")
            md.append("")
            md.append(f"**é›†ä¸­åº¦é£é™©**ï¼š{risk_level.upper()} | **ç»¼åˆè¯„åˆ†**ï¼š{concentration.get('risk_score', 0):.1f}/10")
            md.append("")

            # æ¿å—åˆ†å¸ƒ
            md.append("**æ¿å—åˆ†å¸ƒ**ï¼š")
            for sector, info in concentration.get("sector_breakdown", {}).items():
                tickers_str = " / ".join(info.get("tickers", []))
                md.append(f"- {sector}ï¼š{info.get('pct', 0):.0f}%ï¼ˆ{tickers_str}ï¼‰")
            md.append("")

            # ç›¸å…³æ€§è­¦å‘Š
            corr_warns = concentration.get("correlation_warnings", [])
            if corr_warns:
                md.append("**é«˜ç›¸å…³å¯¹ï¼ˆâ‰¥0.70ï¼‰**ï¼š")
                for w in corr_warns[:4]:
                    md.append(f"- {w['pair']}ï¼šç›¸å…³ç³»æ•° {w['correlation']:.2f} [{w['risk'].upper()}]")
                md.append("")

            # å»ºè®®
            md.append("**åˆ†æ•£åŒ–å»ºè®®**ï¼š")
            for rec in concentration.get("recommendations", []):
                md.append(f"- {rec}")
            md.append("")

        # ====== ç‰ˆå— P5ï¼šå®è§‚ç¯å¢ƒ ======
        if macro_context and macro_context.get("data_source") != "fallback":
            regime = macro_context.get("macro_regime", "neutral")
            regime_emoji = {"risk_on": "ğŸŸ¢", "risk_off": "ğŸ”´", "neutral": "ğŸŸ¡"}.get(regime, "")
            md.append(f"## ğŸŒ å®è§‚ç¯å¢ƒ {regime_emoji}")
            md.append("")
            md.append(f"**å®è§‚æ”¿ä½“**ï¼š{regime.upper()} | **è¯„åˆ†**ï¼š{macro_context.get('macro_score', 5):.1f}/10")
            md.append("")
            md.append(f"| æŒ‡æ ‡ | æ•°å€¼ | çŠ¶æ€ |")
            md.append(f"|------|------|------|")
            md.append(f"| VIX | {macro_context.get('vix', 0):.1f} | {macro_context.get('vix_regime', '')} |")
            md.append(f"| 10Yåˆ©ç‡ | {macro_context.get('treasury_10y', 0):.2f}% | {macro_context.get('rate_environment', '')} |")
            md.append(f"| å¤§ç›˜(5æ—¥) | {macro_context.get('spx_change_pct', 0):+.2f}% | {macro_context.get('market_trend', '')} |")
            md.append(f"| ç¾å…ƒ | â€” | {macro_context.get('dollar_trend', '')} |")
            md.append("")
            headwinds = macro_context.get("macro_headwinds", [])
            tailwinds = macro_context.get("macro_tailwinds", [])
            if headwinds:
                md.append("**é€†é£**ï¼š" + " | ".join(headwinds[:3]))
                md.append("")
            if tailwinds:
                md.append("**é¡ºé£**ï¼š" + " | ".join(tailwinds[:3]))
                md.append("")

        # ====== ç‰ˆå— P3ï¼šå†å²é¢„æµ‹å‡†ç¡®ç‡ï¼ˆT+7 å›æµ‹åé¦ˆï¼‰======
        if backtest_stats and backtest_stats.get("total_checked", 0) > 0:
            acc = backtest_stats["overall_accuracy"]
            total = backtest_stats["total_checked"]
            correct = backtest_stats["correct_count"]
            avg_ret = backtest_stats["avg_return"]
            md.append("## ğŸ“ˆ å†å²é¢„æµ‹å‡†ç¡®ç‡ï¼ˆT+7ï¼Œè¿‘30å¤©ï¼‰")
            md.append("")
            md.append(
                f"**æ ·æœ¬**ï¼š{total} æ¡ | "
                f"**å‡†ç¡®ç‡**ï¼š{acc * 100:.1f}% ({correct}/{total}) | "
                f"**å¹³å‡æ”¶ç›Š**ï¼š{avg_ret:+.2f}%"
            )
            md.append("")
            by_ticker = backtest_stats.get("by_ticker", {})
            if by_ticker:
                md.append("| æ ‡çš„ | æ–¹å‘å‡†ç¡®ç‡ | é¢„æµ‹æ¬¡æ•° | å¹³å‡æ”¶ç›Š |")
                md.append("|------|-----------|---------|---------|")
                for t, info in sorted(
                    by_ticker.items(), key=lambda x: x[1]["total"], reverse=True
                )[:6]:
                    md.append(
                        f"| {t} | {info['accuracy'] * 100:.0f}% "
                        f"| {info['total']} | {info['avg_return']:+.2f}% |"
                    )
                md.append("")
            by_dir = backtest_stats.get("by_direction", {})
            if by_dir:
                parts = []
                for d, label in [("bullish", "çœ‹å¤š"), ("bearish", "çœ‹ç©º"), ("neutral", "ä¸­æ€§")]:
                    info = by_dir.get(d, {})
                    if info.get("total", 0) > 0:
                        parts.append(
                            f"{label}:{info['accuracy']*100:.0f}%({info['total']}æ¬¡)"
                        )
                if parts:
                    md.append("**æŒ‰æ–¹å‘**ï¼š" + " | ".join(parts))
                    md.append("")

        # ====== ç‰ˆå— 8ï¼šæ•°æ®æ¥æº & å…è´£å£°æ˜ ======
        md.append("## 8) æ•°æ®æ¥æº & å…è´£å£°æ˜")
        md.append("")
        md.append("**èœ‚ç¾¤åˆ†å·¥**ï¼š")
        md.append("- ScoutBeeNovaï¼šèªæ˜é’±ä¾¦å¯Ÿï¼ˆSEC Form 4/13F + æ‹¥æŒ¤åº¦ï¼‰")
        md.append("- OracleBeeEchoï¼šå¸‚åœºé¢„æœŸï¼ˆæœŸæƒ IV/P-C Ratio/Gammaï¼‰")
        md.append("- BuzzBeeWhisperï¼šç¤¾äº¤æƒ…ç»ªï¼ˆX/Reddit/Finvizï¼‰")
        md.append("- ChronosBeeHorizonï¼šå‚¬åŒ–å‰‚è¿½è¸ªï¼ˆè´¢æŠ¥/äº‹ä»¶æ—¥å†ï¼‰")
        md.append("- RivalBeeVanguardï¼šç«äº‰æ ¼å±€ï¼ˆML é¢„æµ‹ + è¡Œä¸šå¯¹æ ‡ï¼‰")
        md.append("- GuardBeeSentinelï¼šäº¤å‰éªŒè¯ï¼ˆå…±æŒ¯æ£€æµ‹ + é£é™©è°ƒæ•´ï¼‰")
        md.append("")
        md.append("**å…è´£å£°æ˜**ï¼š")
        md.append(DISCLAIMER_FULL)
        md.append("")

        return "\n".join(md)

    def _generate_swarm_twitter_threads(self, swarm_results: Dict) -> List[str]:
        """ç”Ÿæˆèœ‚ç¾¤æ¨¡å¼çš„ X çº¿ç¨‹ç‰ˆæœ¬"""

        threads = []
        sorted_results = sorted(
            swarm_results.items(),
            key=lambda x: x[1]["final_score"],
            reverse=True
        )

        # ä¸»çº¿ç¨‹
        main_thread = []
        main_thread.append(
            f"ã€Alpha Hive èœ‚ç¾¤æ—¥æŠ¥ {self.date_str}ã€‘"
            f"7 ä¸ªè‡ªæ²»å·¥èœ‚åä½œåˆ†æï¼Œå¤šæ•°æŠ•ç¥¨å…±æŒ¯ä¿¡å·ã€‚"
            f"{DISCLAIMER_SHORT}ğŸ‘‡"
        )

        for i, (ticker, data) in enumerate(sorted_results[:3], 1):
            resonance_emoji = "âœ…" if data["resonance"]["resonance_detected"] else "âŒ"
            insight = data.get("key_insight", "")
            tweet = (
                f"{i}. **{ticker}** {data['direction'].upper()}\n"
                f"èœ‚ç¾¤è¯„åˆ†ï¼š{data['final_score']:.1f}/10 | å…±æŒ¯ï¼š{resonance_emoji}\n"
                f"Agent æŠ•ç¥¨ï¼šçœ‹å¤š{data['agent_breakdown']['bullish']} vs çœ‹ç©º{data['agent_breakdown']['bearish']}"
            )
            if insight:
                tweet += f"\nAIæ´å¯Ÿï¼š{insight}"
            main_thread.append(tweet)

        main_thread.append(
            f"ğŸ 7 ä¸ªå·¥èœ‚ç‹¬ç«‹åˆ†æï¼ˆ6 æ ¸å¿ƒ + çœ‹ç©ºå¯¹å†²èœ‚ï¼‰â†’ ä¿¡æ¯ç´ æ¿å®æ—¶äº¤æ¢ â†’ å¤šæ•°æŠ•ç¥¨æ±‡æ€»\n"
            f"é«˜å…±æŒ¯ä¿¡å·ä¼˜å…ˆçº§æœ€é«˜ã€‚é£é™©æç¤ºï¼šæ§åˆ¶ä»“ä½ã€‚\n"
            f"ä¸‹ä¸€æ­¥ï¼šT+1 éªŒè¯ï¼ŒT+7 å›çœ‹å‡†ç¡®ç‡ã€‚@igg_wang748"
        )

        threads.append("\n\n".join(main_thread))

        return threads

    def _parse_ml_report_to_opportunity(self, ticker: str, ml_report: Dict) -> OpportunityItem:
        """å°† ML æŠ¥å‘Šè§£æä¸º OpportunityItem"""

        adv = ml_report.get("advanced_analysis", {})
        opts = adv.get("options_analysis")
        ml_pred = ml_report.get("ml_prediction", {})

        # æå–å„ç»´åº¦è¯„åˆ†ï¼ˆå‡è®¾å·²æ ‡å‡†åŒ–ä¸º 0-10ï¼‰
        signal_score = adv.get("signal_strength", 5.0)
        catalyst_score = adv.get("catalyst_score", 5.0)
        sentiment_score = adv.get("sentiment_score", 5.0)
        odds_score = adv.get("odds_score", 5.0)
        risk_score = adv.get("risk_adjusted_score", 5.0)

        # å®‰å…¨æå–æœŸæƒåˆ†æ•°
        if opts and isinstance(opts, dict):
            options_score = float(opts.get("options_score", 5.0))
            options_signal = opts.get("signal_summary", "ä¿¡å·å¹³è¡¡")
        else:
            options_score = 5.0
            options_signal = "æœŸæƒæ•°æ®ä¸å¯ç”¨"

        # è®¡ç®—ç»¼åˆ Opportunity Scoreï¼ˆä¸ CLAUDE.md 5 ç»´å…¬å¼ä¸€è‡´ï¼‰
        # options_score åˆå¹¶å…¥ odds ç»´åº¦ï¼ˆå–å¹³å‡ï¼‰
        odds_combined = (odds_score + options_score) / 2.0
        opp_score = (
            0.30 * signal_score +
            0.20 * catalyst_score +
            0.20 * sentiment_score +
            0.15 * odds_combined +
            0.15 * risk_score
        )

        # åˆ¤æ–­æ–¹å‘
        if opp_score >= 7.5:
            direction = "çœ‹å¤š" if signal_score > 5.0 else "çœ‹ç©º"
            confidence = min(95, opp_score * 10)
        elif opp_score >= 6.0:
            direction = "ä¸­æ€§"
            confidence = 60
        else:
            direction = "ä¸­æ€§"
            confidence = 30

        return OpportunityItem(
            ticker=ticker,
            direction=direction,
            signal_score=signal_score,
            catalyst_score=catalyst_score,
            sentiment_score=sentiment_score,
            odds_score=odds_score,
            risk_score=risk_score,
            options_score=options_score,
            opportunity_score=opp_score,
            confidence=confidence,
            key_catalysts=adv.get("upcoming_catalysts", [])[:3] if adv.get("upcoming_catalysts") else [],
            options_signal=options_signal,
            risks=adv.get("key_risks", [])[:2] if adv.get("key_risks") else [],
            thesis_break=adv.get("thesis_break_conditions", "æœªå®šä¹‰")
        )

    def _build_report(self) -> Dict:
        """æ„å»ºå®Œæ•´æŠ¥å‘Š"""

        report = {
            "date": self.date_str,
            "timestamp": self.timestamp.isoformat(),
            "system_status": "âœ… å®Œæˆ",
            "phase_completed": "1-6 (å®Œæ•´èœ‚ç¾¤æµç¨‹)",
            "markdown_report": self._generate_markdown_report(),
            "twitter_threads": self._generate_twitter_threads(),
            "opportunities": [
                {
                    "rank": i + 1,
                    "ticker": opp.ticker,
                    "direction": opp.direction,
                    "opp_score": round(opp.opportunity_score, 1),
                    "confidence": f"{opp.confidence:.0f}%",
                    "options_signal": opp.options_signal,
                    "key_catalyst": opp.key_catalysts[0] if opp.key_catalysts else "N/A",
                    "thesis_break": opp.thesis_break
                }
                for i, opp in enumerate(self.opportunities[:5])
            ],
            "observation_list": self.observations
        }

        return report

    def _generate_markdown_report(self) -> str:
        """ç”Ÿæˆä¸­æ–‡ Markdown æŠ¥å‘Š"""

        md = []
        md.append(f"# ã€{self.date_str}ã€‘Alpha Hive æ¯æ—¥æŠ•èµ„ç®€æŠ¥")
        md.append("")
        md.append(f"**è‡ªåŠ¨ç”Ÿæˆäº**ï¼š{self.timestamp.strftime('%Y-%m-%d %H:%M:%S')}")
        md.append(f"**ç³»ç»ŸçŠ¶æ€**ï¼šâœ… å®Œå…¨æ¿€æ´» | Phase 1-6 å®Œæˆ")
        md.append("")

        # 1. ä»Šæ—¥æ‘˜è¦
        md.append("## ğŸ“Š ä»Šæ—¥æ‘˜è¦ï¼ˆTop 3ï¼‰")
        md.append("")

        for i, opp in enumerate(self.opportunities[:3], 1):
            md.append(f"### {i}. **{opp.ticker}** - {opp.direction}")
            md.append(f"- **æœºä¼šåˆ†æ•°**ï¼š{opp.opportunity_score:.1f}/10 | **ç½®ä¿¡åº¦**ï¼š{opp.confidence:.0f}%")
            md.append(f"- **æœŸæƒä¿¡å·**ï¼š{opp.options_signal}")
            if opp.key_catalysts:
                md.append(f"- **å…³é”®å‚¬åŒ–å‰‚**ï¼š{', '.join(opp.key_catalysts[:2])}")
            md.append("")

        # 2. æœºä¼šæ¸…å•
        md.append("## ğŸ¯ å®Œæ•´æœºä¼šæ¸…å•")
        md.append("")
        md.append("| æ’åº | æ ‡çš„ | æ–¹å‘ | ç»¼åˆåˆ† | æœŸæƒä¿¡å· | ç½®ä¿¡åº¦ |")
        md.append("|------|------|------|--------|---------|--------|")

        for i, opp in enumerate(self.opportunities[:5], 1):
            md.append(
                f"| {i} | **{opp.ticker}** | {opp.direction} | "
                f"{opp.opportunity_score:.1f} | {opp.options_signal[:12]}... | {opp.confidence:.0f}% |"
            )

        md.append("")

        # 3. é£é™©é›·è¾¾
        md.append("## âš ï¸ é£é™©é›·è¾¾")
        md.append("")
        for opp in self.opportunities[:3]:
            if opp.risks:
                md.append(f"**{opp.ticker}**ï¼š{', '.join(opp.risks)}")

        md.append("")

        # 4. æ•°æ®æ¥æºä¸å…è´£
        md.append("## ğŸ“ æ•°æ®æ¥æº & å…è´£å£°æ˜")
        md.append("")
        md.append("**æ•°æ®æº**ï¼š")
        md.append("- StockTwits æƒ…ç»ªï¼ˆå®æ—¶ï¼‰")
        md.append("- Polymarket èµ”ç‡ï¼ˆæ¯5åˆ†é’Ÿï¼‰")
        md.append("- Yahoo Finance / yFinanceï¼ˆå®æ—¶ï¼‰")
        md.append("- SEC æŠ«éœ²ï¼ˆæ¯æ—¥æ›´æ–°ï¼‰")
        md.append("- **æœŸæƒé“¾æ•°æ®**ï¼ˆyFinanceï¼Œæ¯5åˆ†é’Ÿç¼“å­˜ï¼‰")
        md.append("")
        md.append("**å…è´£å£°æ˜**ï¼š")
        md.append(DISCLAIMER_FULL)
        md.append("")

        return "\n".join(md)

    def _generate_twitter_threads(self) -> List[str]:
        """ç”Ÿæˆ X çº¿ç¨‹ç‰ˆæœ¬"""

        threads = []

        # ä¸»çº¿ç¨‹
        main_thread = []
        main_thread.append(
            f"ã€Alpha Hive æ—¥æŠ¥ {self.date_str}ã€‘"
            f"{DISCLAIMER_SHORT}"
            f"ä»Šå¤©æœ€å€¼å¾—è·Ÿè¸ªçš„ 3 ä¸ªæœºä¼š ğŸ‘‡"
        )

        for i, opp in enumerate(self.opportunities[:3], 1):
            main_thread.append(
                f"{i}. **{opp.ticker}** {opp.direction}\n"
                f"ç»¼åˆåˆ†ï¼š{opp.opportunity_score:.1f}/10 | æœŸæƒä¿¡å·ï¼š{opp.options_signal}\n"
                f"ä¸»å‚¬åŒ–å‰‚ï¼š{opp.key_catalysts[0] if opp.key_catalysts else 'TBD'}"
            )

        main_thread.append(
            f"æ›´å¤šè¯¦æƒ…è§å®Œæ•´æ—¥æŠ¥ã€‚é£é™©æç¤ºï¼šé«˜æ³¢åŠ¨æ ‡çš„éœ€æ§åˆ¶ä»“ä½ã€‚"
            f"ä¸‹ä¸€æ­¥è·Ÿè¸ªï¼šT+1 éªŒè¯ä¿¡å·å¼ºåº¦ï¼ŒT+7 å›çœ‹é¢„æµ‹åå·®ã€‚@igg_wang748"
        )

        threads.append("\n\n".join(main_thread))

        return threads

    def auto_commit_and_notify(self, report: Dict) -> Dict:
        """
        è‡ªåŠ¨æäº¤æŠ¥å‘Šåˆ° Git + Slack é€šçŸ¥ï¼ˆAgent Toolbox æ¼”ç¤ºï¼‰

        æ–°åŠŸèƒ½ï¼šä½¿ç”¨ AgentHelper è‡ªåŠ¨æ‰§è¡Œ Git æäº¤å’Œé€šçŸ¥
        """
        _log.info("Auto-commit & Notify å¯åŠ¨")

        results = {}

        # 1. Git æäº¤æŠ¥å‘Šï¼ˆå§‹ç»ˆæ–° commitï¼Œä¸ amendï¼Œé¿å… GitHub Pages éƒ¨ç½²å†²çªï¼‰
        from datetime import datetime as _dt2
        timestamp = _dt2.now().strftime("%H:%M")
        today_commit_msg = f"Alpha Hive èœ‚ç¾¤æ—¥æŠ¥ {self.date_str} {timestamp}"
        _log.info("Git commit... (mode: new)")
        status = self.agent_helper.git.status()
        if status.get("modified_files"):
            commit_result = self.agent_helper.git.commit(today_commit_msg)
            results["git_commit"] = commit_result
            if commit_result["success"]:
                _log.info("Git commit æˆåŠŸï¼ˆnewï¼‰")
            else:
                _log.warning("Git commit å¤±è´¥ï¼š%s", commit_result.get('message'))
        else:
            _log.info("æ— éœ€æäº¤ï¼ˆå·¥ä½œç›®å½•å¹²å‡€ï¼‰")

        # 2. Git æ¨é€ï¼šLLM æ¨¡å¼ â†’ ç”Ÿäº§ï¼ˆorigin mainï¼‰ï¼Œè§„åˆ™æ¨¡å¼ â†’ æµ‹è¯•ï¼ˆtest remoteï¼‰
        #    è§„åˆ™æ¨¡å¼ä½¿ç”¨ä¸´æ—¶åˆ†æ”¯ï¼Œä¸æ±¡æŸ“æœ¬åœ° mainï¼Œæ¨å®Œå³åˆ é™¤
        import llm_service as _llm_check
        _using_llm = _llm_check.is_available()
        env_label = "ğŸ§  ç”Ÿäº§ï¼ˆLLMï¼‰" if _using_llm else "ğŸ”§ æµ‹è¯•ï¼ˆè§„åˆ™å¼•æ“ï¼‰"
        _log.info("Git push â†’ [%s]", env_label)

        if _using_llm:
            # ç”Ÿäº§æ¨¡å¼ï¼šæ­£å¸¸æ¨é€ origin main
            r = self.agent_helper.git.run_git_cmd("git push origin main")
            push_result = {"success": r["success"], "remote": "origin",
                           "output": r.get("stdout", "") or r.get("stderr", "")}
        else:
            # æµ‹è¯•æ¨¡å¼ï¼šä¸´æ—¶åˆ†æ”¯ â†’ test remote â†’ åˆ é™¤ä¸´æ—¶åˆ†æ”¯ â†’ æœ¬åœ° main å›æ»šåˆ° origin/main
            _remote_check = self.agent_helper.git.run_git_cmd("git remote")
            if "test" not in _remote_check.get("stdout", ""):
                _log.warning("test remote ä¸å­˜åœ¨ï¼Œè·³è¿‡æ¨é€")
                push_result = {"success": False, "error": "test remote not configured"}
            else:
                _tmp = "_test_snapshot"
                # ä»å½“å‰ HEAD åˆ›å»ºä¸´æ—¶åˆ†æ”¯å¹¶æ¨é€åˆ° test:main
                self.agent_helper.git.run_git_cmd(f"git branch -D {_tmp}", check=False)
                self.agent_helper.git.run_git_cmd(f"git checkout -b {_tmp}")
                r = self.agent_helper.git.run_git_cmd(f"git push test {_tmp}:main --force")
                push_result = {"success": r["success"], "remote": "test",
                               "output": r.get("stdout", "") or r.get("stderr", "")}
                # å›åˆ° main å¹¶åˆ é™¤ä¸´æ—¶åˆ†æ”¯ï¼Œæœ¬åœ° main æ¢å¤å¹²å‡€çŠ¶æ€
                self.agent_helper.git.run_git_cmd("git checkout main")
                self.agent_helper.git.run_git_cmd(f"git branch -D {_tmp}")
                # é‡ç½®æœ¬åœ° main åˆ° origin/mainï¼Œæ’¤é”€æµ‹è¯•æ•°æ®å¯¹æœ¬åœ° main çš„æ±¡æŸ“
                self.agent_helper.git.run_git_cmd("git fetch origin")
                self.agent_helper.git.run_git_cmd("git reset --hard origin/main")
                _log.info("æœ¬åœ° main å·²æ¢å¤è‡³ origin/mainï¼ˆæµ‹è¯•æ•°æ®ä¸æ±¡æŸ“ç”Ÿäº§ï¼‰")

        results["git_push"] = push_result
        results["deploy_env"] = "production" if _using_llm else "test"
        if push_result["success"]:
            _log.info("Git push æˆåŠŸ â†’ %s", push_result.get("remote"))
        else:
            _log.warning("Git push å¤±è´¥ï¼š%s", push_result.get("error") or push_result.get("output", ""))

        # 3. Slack é€šçŸ¥ï¼ˆç”± Claude Code MCP å·¥å…·æ¨é€ï¼Œä¸ç”¨ webhook botï¼‰
        _log.info("Slack æ¨é€ç”± Claude Code è´Ÿè´£ï¼ˆç”¨æˆ·è´¦å·ï¼‰")
        results["slack_notification"] = {"skipped": "handled_by_claude_mcp"}

        _log.info("Auto-commit & Notify å®Œæˆ")
        return results

    def check_earnings_updates(self, report_path: str = None, tickers: List[str] = None) -> Dict:
        """
        æ£€æŸ¥ watchlist ä¸­ä»Šæ—¥æ˜¯å¦æœ‰æ ‡çš„å‘å¸ƒäº†è´¢æŠ¥ï¼Œè‹¥æœ‰åˆ™è‡ªåŠ¨æŠ“å–ç»“æœå¹¶æ›´æ–°ç®€æŠ¥

        Args:
            report_path: ç®€æŠ¥æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ä»Šæ—¥ç®€æŠ¥ï¼‰
            tickers: è¦æ£€æŸ¥çš„æ ‡çš„ï¼ˆé»˜è®¤ WATCHLIST å…¨éƒ¨ï¼‰

        Returns:
            {reporting_today: [], updated: [], earnings_data: {}, errors: []}
        """
        if not self.earnings_watcher:
            _log.info("EarningsWatcher ä¸å¯ç”¨ï¼Œè·³è¿‡è´¢æŠ¥æ£€æŸ¥")
            return {"reporting_today": [], "updated": [], "earnings_data": {}, "errors": ["EarningsWatcher not available"]}

        if tickers is None:
            tickers = list(WATCHLIST.keys())

        if report_path is None:
            # æŸ¥æ‰¾ä»Šæ—¥ç®€æŠ¥
            candidates = [
                self.report_dir / "reports" / f"alpha_hive_daily_{self.date_str}.md",
                self.report_dir / f"alpha-hive-daily-{self.date_str}.md",
            ]
            for c in candidates:
                if c.exists():
                    report_path = str(c)
                    break

        if report_path is None:
            _log.warning("æœªæ‰¾åˆ°ä»Šæ—¥ç®€æŠ¥æ–‡ä»¶ï¼Œè·³è¿‡è´¢æŠ¥æ›´æ–°")
            return {"reporting_today": [], "updated": [], "earnings_data": {}, "errors": ["no report file found"]}

        result = self.earnings_watcher.check_and_update(tickers, report_path)

        # å¦‚æœæœ‰æ›´æ–°ï¼Œé€šè¿‡ Slack å‘é€é€šçŸ¥
        if result.get("updated") and self.slack_notifier and self.slack_notifier.enabled:
            for ticker in result["updated"]:
                ed = result["earnings_data"].get(ticker, {})
                rev = ed.get("revenue_actual")
                eps = ed.get("eps_actual")
                yoy = ed.get("yoy_revenue_growth")

                msg_parts = [f"{ticker} è´¢æŠ¥æ•°æ®å·²è‡ªåŠ¨æ›´æ–°"]
                if rev:
                    rev_str = f"${rev / 1e9:.1f}B" if abs(rev) >= 1e9 else f"${rev / 1e6:.0f}M"
                    msg_parts.append(f"è¥æ”¶ {rev_str}")
                if yoy is not None:
                    msg_parts.append(f"YoY {'+' if yoy > 0 else ''}{yoy * 100:.1f}%")
                if eps is not None:
                    msg_parts.append(f"EPS ${eps:.2f}")

                try:
                    self.slack_notifier.send_opportunity_alert(
                        ticker,
                        0,  # score placeholder
                        "è´¢æŠ¥æ›´æ–°",
                        " | ".join(msg_parts),
                        ["è‡ªåŠ¨æŠ“å–", f"å®Œæ•´åº¦: {ed.get('data_completeness', 'N/A')}"]
                    )
                except (OSError, ValueError, RuntimeError) as e:
                    _log.warning("Slack è´¢æŠ¥é€šçŸ¥å‘é€å¤±è´¥: %s", e)

        # D1: è‡ªåŠ¨åŒæ­¥è´¢æŠ¥æ—¥æœŸåˆ°å‚¬åŒ–å‰‚æ—¥å†
        try:
            auto_catalysts = self.earnings_watcher.get_catalysts_for_calendar(tickers)
            if auto_catalysts and hasattr(self, 'calendar') and self.calendar:
                # åˆå¹¶è‡ªåŠ¨è·å–çš„è´¢æŠ¥æ—¥æœŸä¸ config.CATALYSTS
                from config import CATALYSTS
                merged = dict(CATALYSTS)
                for t, events in auto_catalysts.items():
                    if t in merged:
                        # å»é‡ï¼šåªæ·»åŠ å°šæœªå­˜åœ¨çš„ earnings äº‹ä»¶
                        existing_dates = {e.get("scheduled_date") for e in merged[t]}
                        for ev in events:
                            if ev.get("scheduled_date") not in existing_dates:
                                merged[t].append(ev)
                    else:
                        merged[t] = events
                self.calendar.sync_catalysts(catalysts=merged, tickers=tickers)
                _log.info("å·²è‡ªåŠ¨åŒæ­¥ %d ä¸ªæ ‡çš„çš„è´¢æŠ¥æ—¥æœŸåˆ°å‚¬åŒ–å‰‚æ—¥å†", len(auto_catalysts))
        except (ImportError, OSError, ValueError, TypeError, AttributeError) as e:
            _log.debug("å‚¬åŒ–å‰‚æ—¥å†è‡ªåŠ¨åŒæ­¥è·³è¿‡: %s", e)

        return result

    def _generate_ml_reports(self, report: Dict) -> List[str]:
        """ä¸ºæ‰«ææ ‡çš„æ‰¹é‡ç”Ÿæˆ ML å¢å¼º HTML æŠ¥å‘Šï¼ˆåŒæ­¥å†™å…¥ï¼Œä¾› _generate_index_html æ£€æµ‹åˆ°æ–‡ä»¶åæ·»åŠ é“¾æ¥ï¼‰"""
        # åŠ è½½èœ‚ç¾¤è¯¦ç»†æ•°æ®ï¼ˆsave_report å·²å†™å…¥ .swarm_results_*.jsonï¼‰
        swarm_data: Dict = {}
        sr_path = self.report_dir / f".swarm_results_{self.date_str}.json"
        if sr_path.exists():
            try:
                with open(sr_path) as f:
                    swarm_data = json.load(f)
            except (OSError, json.JSONDecodeError):
                pass

        # ç”¨ swarm_data æ‰€æœ‰æ ‡çš„ï¼ˆè€Œéä»… opportunities å‰å‡ åï¼‰ï¼Œç¡®ä¿æ¯ä¸ªæ‰«ææ ‡çš„éƒ½æœ‰ ML æŠ¥å‘Š
        opps = report.get("opportunities", [])
        opp_tickers = [o.get("ticker") for o in opps if o.get("ticker")]
        extra = [t for t in swarm_data if t not in opp_tickers]
        tickers = opp_tickers + extra
        if not tickers:
            return []

        generated = []
        for ticker in tickers:
            try:
                # ä» yfinance è·å–å½“å‰ä»·æ ¼
                real_price, real_change = 100.0, 0.0
                try:
                    import yfinance as _yf
                    _hist = _yf.Ticker(ticker).history(period="5d")
                    if not _hist.empty:
                        real_price = float(_hist["Close"].iloc[-1])
                        if len(_hist) >= 2:
                            real_change = (_hist["Close"].iloc[-1] / _hist["Close"].iloc[-2] - 1) * 100
                except Exception:
                    pass

                ticker_data = {
                    "ticker": ticker,
                    "sources": {
                        "yahoo_finance": {
                            "current_price": real_price,
                            "price_change_5d": real_change,
                            "change_pct": real_change,
                        }
                    },
                }

                # ç”Ÿæˆ ML å¢å¼ºåˆ†æ
                enhanced = self.ml_generator.generate_ml_enhanced_report(ticker, ticker_data)

                # æ³¨å…¥èœ‚ç¾¤æ•°æ®
                if ticker in swarm_data:
                    enhanced["swarm_results"] = swarm_data[ticker]

                # åŒæ­¥å†™å…¥ HTMLï¼ˆå¿…é¡»åœ¨ _generate_index_html å‰å®Œæˆï¼Œä»¥ä¾¿æ–‡ä»¶å­˜åœ¨æ€§æ£€æµ‹é€šè¿‡ï¼‰
                html = self.ml_generator.generate_html_report(ticker, enhanced)
                html_path = self.report_dir / f"alpha-hive-{ticker}-ml-enhanced-{self.date_str}.html"
                with open(html_path, "w", encoding="utf-8") as f:
                    f.write(html)

                generated.append(ticker)
                _log.info("ML å¢å¼ºæŠ¥å‘Šå·²ç”Ÿæˆï¼š%s", html_path.name)

            except Exception as e:
                _log.warning("ML æŠ¥å‘Šç”Ÿæˆå¤±è´¥ %s: %s", ticker, e)

        return generated

    def save_report(self, report: Dict) -> str:
        """ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶ï¼ˆMD / JSON / Xçº¿ç¨‹ / index.html GitHub Pagesï¼‰"""

        # ä¿å­˜ JSON ç‰ˆæœ¬
        json_file = self.report_dir / f"alpha-hive-daily-{self.date_str}.json"
        with open(json_file, "w", encoding="utf-8") as f:
            json.dump(report, f, ensure_ascii=False, indent=2)

        # ä¿å­˜ Markdown ç‰ˆæœ¬
        md_file = self.report_dir / f"alpha-hive-daily-{self.date_str}.md"
        with open(md_file, "w", encoding="utf-8") as f:
            f.write(report["markdown_report"])

        # æ¸…ç†å½“å¤©æ—§çš„ X çº¿ç¨‹æ–‡ä»¶ï¼ˆé˜²æ­¢å¤šæ¬¡è¿è¡Œæ—¶æ•°é‡ä¸åŒå¯¼è‡´æ®‹ç•™å åŠ ï¼‰
        for old in self.report_dir.glob(f"alpha-hive-thread-{self.date_str}-*.txt"):
            old.unlink()

        # ä¿å­˜ X çº¿ç¨‹ç‰ˆæœ¬
        for i, thread in enumerate(report["twitter_threads"], 1):
            thread_file = self.report_dir / f"alpha-hive-thread-{self.date_str}-{i}.txt"
            with open(thread_file, "w", encoding="utf-8") as f:
                f.write(thread)

        # ç”Ÿæˆ ML å¢å¼º HTML æŠ¥å‘Šï¼ˆå¿…é¡»åœ¨ _generate_index_html å‰å®Œæˆï¼Œä»¥ä¾¿ ML é“¾æ¥è‡ªåŠ¨å‡ºç°ï¼‰
        try:
            ml_tickers = self._generate_ml_reports(report)
            if ml_tickers:
                _log.info("ML å¢å¼ºæŠ¥å‘Šå®Œæˆï¼š%s", ml_tickers)
                print(f"   ML æŠ¥å‘Š     : âœ… {', '.join(ml_tickers)}")
        except Exception as e:
            _log.warning("ML æŠ¥å‘Šæ‰¹é‡ç”Ÿæˆå‡ºé”™: %s", e)

        # æ›´æ–° GitHub Pages ä»ªè¡¨æ¿
        try:
            html = self._generate_index_html(report)
            index_file = self.report_dir / "index.html"
            with open(index_file, "w", encoding="utf-8") as f:
                f.write(html)
            _log.info("index.html å·²æ›´æ–°ï¼ˆGitHub Pagesï¼‰")
        except Exception as e:
            _log.warning("index.html ç”Ÿæˆå¤±è´¥: %s", e)

        _log.info("æŠ¥å‘Šå·²ä¿å­˜ï¼š%s", md_file.name)

        return str(md_file)

    def _generate_index_html(self, report: Dict) -> str:
        """ä» swarm report + .swarm_results_*.json ç”Ÿæˆå®Œæ•´ GitHub Pages ä»ªè¡¨æ¿"""
        from datetime import datetime as _dt
        import html as _html
        from pathlib import Path as _Path

        now_str = _dt.now().strftime("%Y-%m-%d %H:%M PST")
        date_str = self.date_str
        opps = report.get("opportunities", [])
        meta = report.get("swarm_metadata", {})
        n_tickers = meta.get("tickers_analyzed", len(opps))
        n_agents = meta.get("total_agents", 7)
        n_resonance = meta.get("resonances_detected", 0)

        # è¯»å–è¯¦ç»† swarm_resultsï¼ˆå« IV Rankã€P/C Ratioã€å†…å¹•ä¿¡å·ç­‰ï¼‰
        swarm_detail: Dict = {}
        try:
            sr_path = self.report_dir / f".swarm_results_{date_str}.json"
            if sr_path.exists():
                with open(sr_path) as _f:
                    swarm_detail = json.load(_f)
        except (OSError, json.JSONDecodeError):
            pass

        # å°† opportunities æŒ‰ ticker å»ºç«‹ç´¢å¼•ï¼Œå¹¶è¡¥å…… swarm è¯¦ç»†æ•°æ®
        opp_by_ticker = {o.get("ticker"): o for o in opps}
        # è‹¥ swarm_detail æœ‰æ›´å¤š tickerï¼ˆè¶…è¿‡ opportunities çš„ 5 ä¸ªï¼‰ï¼Œå…¨éƒ¨çº³å…¥
        all_tickers_sorted = [o.get("ticker") for o in opps]
        for t in swarm_detail:
            if t not in all_tickers_sorted:
                all_tickers_sorted.append(t)

        dir_map = {"bullish": ("çœ‹å¤š", "bullish", "#28a745"),
                   "bearish": ("çœ‹ç©º", "bearish", "#dc3545"),
                   "neutral": ("ä¸­æ€§", "neutral", "#ffc107")}

        def sc_cls(score):
            return "sc-h" if score >= 7.0 else ("sc-m" if score >= 5.5 else "sc-l")

        def _detail(ticker):
            """æå–å•ä¸ª ticker çš„è¯¦ç»†æŒ‡æ ‡"""
            sd = swarm_detail.get(ticker, {})
            ad = sd.get("agent_details", {})
            oracle = ad.get("OracleBeeEcho", {}).get("details", {})
            scout_disc = ad.get("ScoutBeeNova", {}).get("discovery", "")
            bear_score = ad.get("BearBeeContrarian", {}).get("score", 0.0)
            ab = sd.get("agent_breakdown", {})
            iv_rank = oracle.get("iv_rank", None)
            pc = oracle.get("put_call_ratio", None)
            real_pct = sd.get("data_real_pct", None)
            # å†…å¹•ä¿¡å·ï¼šå– ScoutBeeNova discovery ç¬¬ä¸€ä¸ª | æ®µ
            insider_hint = scout_disc.split("|")[0].strip() if scout_disc else ""
            # æ˜¯å¦æœ‰å†…å¹•ä¹°å…¥/å–å‡º
            insider_color = "#28a745" if "ä¹°å…¥" in insider_hint else ("#dc3545" if "å–å‡º" in insider_hint else "#666")
            return {
                "iv_rank": f"{iv_rank:.1f}" if iv_rank is not None else "-",
                "pc": f"{pc:.2f}" if pc is not None else "-",
                "bear_score": float(bear_score),
                "bullish": ab.get("bullish", 0),
                "bearish_v": ab.get("bearish", 0),
                "neutral_v": ab.get("neutral", 0),
                "insider_hint": _html.escape(insider_hint[:35]) if insider_hint else "",
                "insider_color": insider_color,
                "real_pct": f"{real_pct:.0f}%" if real_pct is not None else "-",
            }

        # è®¡ç®— avg real_pct
        real_pcts = [swarm_detail[t].get("data_real_pct", 0) for t in swarm_detail if swarm_detail[t].get("data_real_pct")]
        avg_real = f"{sum(real_pcts)/len(real_pcts):.0f}%" if real_pcts else "-"

        # â”€â”€ æœºä¼šå¡ç‰‡ï¼ˆTop 6ï¼‰â”€â”€
        cards_html = ""
        for i, ticker in enumerate(all_tickers_sorted[:6], 1):
            opp = opp_by_ticker.get(ticker, {})
            score = float(opp.get("opp_score") or swarm_detail.get(ticker, {}).get("final_score", 0))
            direction = str(opp.get("direction") or swarm_detail.get(ticker, {}).get("direction", "neutral")).lower()
            if direction not in dir_map:
                direction = "bullish" if "å¤š" in direction else ("bearish" if "ç©º" in direction else "neutral")
            resonance = opp.get("resonance", swarm_detail.get(ticker, {}).get("resonance", {}).get("resonance_detected", False))
            supporting = int(opp.get("supporting_agents") or swarm_detail.get(ticker, {}).get("supporting_agents", 0))
            dir_label, dir_cls, dir_color = dir_map[direction]
            border = " style=\"border-color:#28a745;border-width:2px;\"" if i == 1 else ""
            rank_style = " style=\"background:#28a745;color:white;\"" if i == 1 else ""
            sc = sc_cls(score)
            res_badge = (f'<span class="res-badge res-y">{supporting} Agent å…±æŒ¯</span>'
                         if resonance else '<span class="res-badge res-n">æ— å…±æŒ¯</span>')
            d = _detail(ticker)
            pc_color = ' style="color:#28a745;font-weight:bold;"' if d["pc"] != "-" and float(d["pc"]) < 0.7 else (
                       ' style="color:#dc3545;font-weight:bold;"' if d["pc"] != "-" and float(d["pc"]) > 1.5 else "")
            bear_pct = min(100, int(d["bear_score"] * 10))
            insider_row = (f'<div class="mr"><span class="lbl">å†…å¹•ä¿¡å·</span>'
                           f'<span class="val" style="color:{d["insider_color"]};">{d["insider_hint"]}</span></div>'
                           if d["insider_hint"] else "")
            ml_link = _Path(self.report_dir / f"alpha-hive-{ticker}-ml-enhanced-{date_str}.html")
            ml_row = (f'<div class="mr"><span class="lbl">ML æŠ¥å‘Š</span>'
                      f'<span class="val"><a href="alpha-hive-{ticker}-ml-enhanced-{date_str}.html" style="color:#667eea;">æŸ¥çœ‹è¯¦æƒ…</a></span></div>'
                      if ml_link.exists() else "")
            cards_html += f"""
                <div class="opp-card"{border}>
                    <div class="card-rank"{rank_style}>#{i}</div>
                    <div class="card-hd">
                        <h3>{_html.escape(ticker)}</h3>
                        <div class="dir-badge dir-{dir_cls}">{dir_label}</div>
                    </div>
                    <div class="card-body">
                        <div class="mr"><span class="lbl">ç»¼åˆåˆ†</span><span class="val {sc}">{score:.1f}/10</span></div>
                        <div class="mr"><span class="lbl">å…±æŒ¯ä¿¡å·</span>{res_badge}</div>
                        <div class="mr"><span class="lbl">æŠ•ç¥¨</span><span class="val">{d['bullish']}å¤š / {d['bearish_v']}ç©º / {d['neutral_v']}ä¸­</span></div>
                        <div class="mr"><span class="lbl">IV Rank</span><span class="val">{d['iv_rank']}</span></div>
                        <div class="mr"><span class="lbl">P/C Ratio</span><span class="val"{pc_color}>{d['pc']}</span></div>
                        {insider_row}
                        <div class="mr"><span class="lbl">çœ‹ç©ºå¼ºåº¦</span><span class="val">{d['bear_score']:.1f}/10</span></div>
                        <div class="bear-bar"><div class="bear-fill" style="width:{bear_pct}%"></div></div>
                        {ml_row}
                    </div>
                </div>"""

        # â”€â”€ å®Œæ•´è¡¨æ ¼ï¼ˆå…¨éƒ¨ tickerï¼‰â”€â”€
        rows_html = ""
        for i, ticker in enumerate(all_tickers_sorted, 1):
            opp = opp_by_ticker.get(ticker, {})
            score = float(opp.get("opp_score") or swarm_detail.get(ticker, {}).get("final_score", 0))
            direction = str(opp.get("direction") or swarm_detail.get(ticker, {}).get("direction", "neutral")).lower()
            if direction not in dir_map:
                direction = "bullish" if "å¤š" in direction else ("bearish" if "ç©º" in direction else "neutral")
            resonance = opp.get("resonance", swarm_detail.get(ticker, {}).get("resonance", {}).get("resonance_detected", False))
            supporting = int(opp.get("supporting_agents") or swarm_detail.get(ticker, {}).get("supporting_agents", 0))
            dir_label, _, dir_color = dir_map[direction]
            sc = sc_cls(score)
            d = _detail(ticker)
            res_html = (f'<span class="res-badge res-y">{supporting} Agent</span>'
                        if resonance else '<span class="res-badge res-n">æ— </span>')
            row_style = " style=\"background:#f0fff0;\"" if i == 1 else ""
            ml_link = _Path(self.report_dir / f"alpha-hive-{ticker}-ml-enhanced-{date_str}.html")
            ml_td = (f'<a href="alpha-hive-{ticker}-ml-enhanced-{date_str}.html" style="color:#667eea;">æŸ¥çœ‹</a>'
                     if ml_link.exists() else "-")
            pc_style = (' style="color:#28a745;font-weight:bold;"' if d["pc"] != "-" and float(d["pc"]) < 0.7
                        else (' style="color:#dc3545;font-weight:bold;"' if d["pc"] != "-" and float(d["pc"]) > 1.5 else ""))
            rows_html += f"""
                <tr{row_style}>
                    <td>{i}</td>
                    <td><strong>{_html.escape(ticker)}</strong></td>
                    <td style="color:{dir_color};font-weight:bold;">{dir_label}</td>
                    <td class="{sc}"><strong>{score:.1f}</strong>/10</td>
                    <td>{res_html}</td>
                    <td>{d['bullish']} / {d['bearish_v']} / {d['neutral_v']}</td>
                    <td>{d['iv_rank']}</td>
                    <td{pc_style}>{d['pc']}</td>
                    <td style="color:#fd7e14;">{d['bear_score']:.1f}/10</td>
                    <td>{ml_td}</td>
                </tr>"""

        # â”€â”€ Phase 3 å¢å¼ºï¼šå®è§‚é¢æ¿ + æ·±åº¦å¡ç‰‡ + Markdown æ¸²æŸ“ â”€â”€
        import re as _re

        # extra_cssï¼šç”¨æ™®é€šå­—ç¬¦ä¸²ï¼ˆä¸ç”¨ f-stringï¼‰ï¼Œé¿å… CSS å¤§æ‹¬å·è½¬ä¹‰é—®é¢˜
        extra_css = """
        .reports-list { display: flex; flex-direction: column; gap: 12px; }
        .report-item { border: 1px solid #eee; border-radius: 8px; padding: 12px; }
        .report-date { font-size: 0.85em; color: #666; margin-bottom: 8px; }
        .report-links { display: flex; flex-wrap: wrap; gap: 8px; }
        .rl { display: inline-block; padding: 5px 12px; border-radius: 15px; font-size: 0.82em;
              font-weight: bold; text-decoration: none; transition: opacity 0.2s; }
        .rl:hover { opacity: 0.85; }
        .rl.md { background: #667eea; color: white; }
        .rl.json { background: #764ba2; color: white; }
        .rl.ml-rl { background: #17a2b8; color: white; font-size: 0.78em; padding: 4px 10px; }
        .company-grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(360px, 1fr)); gap: 20px; }
        .company-card { border-radius: 12px; overflow: hidden; box-shadow: 0 4px 18px rgba(0,0,0,0.09); }
        .cc-header { display: flex; justify-content: space-between; align-items: center; padding: 14px 20px; color: white; }
        .cc-ticker { font-size: 1.4em; font-weight: bold; }
        .cc-dir { font-size: 0.88em; background: rgba(255,255,255,0.22); padding: 3px 12px; border-radius: 12px; }
        .cc-score { font-size: 1.1em; font-weight: bold; }
        .cc-score.sc-h { color: #90EE90; } .cc-score.sc-m { color: #FFD700; } .cc-score.sc-l { color: #FFB6C1; }
        .cc-body { padding: 16px 20px; background: white; }
        .cc-metrics { display: flex; gap: 12px; margin-bottom: 12px; padding-bottom: 12px; border-bottom: 1px solid #f0f0f0; }
        .cc-metric { flex: 1; text-align: center; background: #f8f9fa; border-radius: 8px; padding: 8px 4px; }
        .cm-l { display: block; font-size: 0.75em; color: #888; }
        .cm-v { display: block; font-size: 1em; font-weight: bold; color: #333; margin-top: 3px; }
        .cc-signals { list-style: none; padding: 0; margin: 0 0 14px 0; }
        .cc-signals li { padding: 5px 0; border-bottom: 1px dashed #f5f5f5; font-size: 0.87em; color: #444; line-height: 1.5; }
        .cc-signals li:last-child { border-bottom: none; }
        .cc-footer { text-align: right; margin-top: 4px; }
        .ml-btn { display: inline-block; padding: 6px 16px; background: linear-gradient(135deg,#667eea,#764ba2);
                  color: white; border-radius: 15px; font-size: 0.82em; font-weight: bold; text-decoration: none; }
        .ml-btn:hover { opacity: 0.88; }
        .ml-btn-na { font-size: 0.82em; color: #bbb; font-style: italic; }
        .report-body { font-size: 0.92em; line-height: 1.8; color: #333; max-height: 900px; overflow-y: auto; padding-right: 8px; }
        .report-body h1 { font-size: 1.5em; color: #667eea; border-bottom: 2px solid #667eea; padding-bottom: 8px; margin: 20px 0 12px; }
        .report-body h2 { font-size: 1.2em; color: #667eea; border-left: 4px solid #667eea; padding-left: 10px; margin: 16px 0 8px; }
        .report-body h3 { font-size: 1.05em; color: #764ba2; font-weight: bold; margin: 12px 0 5px; }
        .report-body h4 { font-size: 0.97em; color: #555; margin: 8px 0 4px; }
        .report-body ul { margin: 4px 0 8px 18px; }
        .report-body .sub-ul { margin-top: 4px; padding-left: 16px; }
        .report-body li { margin: 2px 0; }
        .report-body p { margin: 2px 0; }
        .report-body hr { border: none; border-top: 1px solid #eee; margin: 14px 0; }
        """

        # F&G æŒ‡æ•° + å¹³å‡æƒ…ç»ª
        _fg_val = None
        _avg_sent, _sent_cnt = 0.0, 0
        for _t3 in all_tickers_sorted:
            _b3 = swarm_detail.get(_t3, {}).get("agent_details", {}).get("BuzzBeeWhisper", {}).get("discovery", "")
            if _fg_val is None:
                _m3 = _re.search(r'F&G\s*(\d+)', _b3)
                if _m3:
                    _fg_val = int(_m3.group(1))
            _s3 = _re.search(r'æƒ…ç»ª\s*([\d.]+)%', _b3)
            if _s3:
                _avg_sent += float(_s3.group(1))
                _sent_cnt += 1
        _fv3 = _fg_val if _fg_val is not None else 50
        _fg_color = "#dc3545" if _fv3 <= 45 else ("#ffc107" if _fv3 <= 55 else "#28a745")
        _fg_label = (("æåº¦ææƒ§" if _fv3 <= 25 else "ææƒ§") if _fv3 <= 45
                     else (("ä¸­æ€§" if _fv3 <= 55 else "è´ªå©ª") if _fv3 <= 75 else "æåº¦è´ªå©ª"))
        _fg_str = str(_fg_val) if _fg_val is not None else "?"
        _avg_sent_str = f"{_avg_sent/_sent_cnt:.0f}%" if _sent_cnt else "-"

        # ML å¿«æ·é“¾æ¥
        _ml_ql = ""
        for _t3 in all_tickers_sorted:
            if _Path(self.report_dir / f"alpha-hive-{_t3}-ml-enhanced-{date_str}.html").exists():
                _ml_ql += (f'<a href="alpha-hive-{_t3}-ml-enhanced-{date_str}.html"'
                           f' class="rl ml-rl">{_html.escape(_t3)}</a> ')

        # ä¸ªè‚¡æ·±åº¦åˆ†æå¡ç‰‡
        _dir_hdr = {"bullish": "#28a745", "bearish": "#dc3545", "neutral": "#e67e22"}
        company_cards_html = ""
        for _tkr3 in all_tickers_sorted:
            _sd3 = swarm_detail.get(_tkr3, {})
            _ad3 = _sd3.get("agent_details", {})
            _sc3 = float(opp_by_ticker.get(_tkr3, {}).get("opp_score") or _sd3.get("final_score", 0))
            _dr3 = str(opp_by_ticker.get(_tkr3, {}).get("direction") or _sd3.get("direction", "neutral")).lower()
            if _dr3 not in dir_map:
                _dr3 = "bullish" if "å¤š" in _dr3 else ("bearish" if "ç©º" in _dr3 else "neutral")
            _dlbl3, _, _ = dir_map[_dr3]
            _hc3 = _dir_hdr.get(_dr3, "#667eea")
            _scls3 = sc_cls(_sc3)
            _det3 = _detail(_tkr3)
            _blist = []
            for _disc3, _ico3, _lb3 in [
                (_ad3.get("ScoutBeeNova", {}).get("discovery", ""), "ğŸ“‹", "å†…å¹•"),
                (_ad3.get("OracleBeeEcho", {}).get("discovery", ""), "ğŸ“Š", "æœŸæƒ"),
                (_ad3.get("BuzzBeeWhisper", {}).get("discovery", ""), "ğŸ’¬", "æƒ…ç»ª"),
                (_ad3.get("ChronosBeeHorizon", {}).get("discovery", ""), "ğŸ“…", "å‚¬åŒ–å‰‚"),
                (_ad3.get("BearBeeContrarian", {}).get("discovery", ""), "ğŸ»", "é£é™©"),
            ]:
                _f3 = _disc3.split("|")[0].strip()[:90] if _disc3 else ""
                if _f3:
                    _blist.append(f'<li>{_ico3} <strong>{_lb3}ï¼š</strong>{_html.escape(_f3)}</li>')
            _bhtml3 = "\n                        ".join(_blist) if _blist else "<li>æ•°æ®é‡‡é›†ä¸­...</li>"
            _ml3ex = _Path(self.report_dir / f"alpha-hive-{_tkr3}-ml-enhanced-{date_str}.html").exists()
            _mlbtn3 = (f'<a href="alpha-hive-{_tkr3}-ml-enhanced-{date_str}.html" class="ml-btn">ML å¢å¼ºåˆ†æ â†’</a>'
                       if _ml3ex else '<span class="ml-btn-na">ML æŠ¥å‘Šç”Ÿæˆä¸­</span>')
            company_cards_html += f"""
            <div class="company-card">
                <div class="cc-header" style="background:{_hc3};">
                    <span class="cc-ticker">{_html.escape(_tkr3)}</span>
                    <span class="cc-dir">{_dlbl3}</span>
                    <span class="cc-score {_scls3}">{_sc3:.1f}/10</span>
                </div>
                <div class="cc-body">
                    <div class="cc-metrics">
                        <div class="cc-metric"><span class="cm-l">IV Rank</span><span class="cm-v">{_det3['iv_rank']}</span></div>
                        <div class="cc-metric"><span class="cm-l">P/C Ratio</span><span class="cm-v">{_det3['pc']}</span></div>
                        <div class="cc-metric"><span class="cm-l">çœ‹ç©ºå¼ºåº¦</span><span class="cm-v">{_det3['bear_score']:.1f}/10</span></div>
                    </div>
                    <ul class="cc-signals">
                        {_bhtml3}
                    </ul>
                    <div class="cc-footer">{_mlbtn3}</div>
                </div>
            </div>"""

        # Markdown â†’ HTML è½»é‡æ¸²æŸ“
        def _md2html(md_text: str) -> str:
            lines = md_text.split('\n')
            out, in_ul, in_sub = [], False, False
            for ln in lines:
                if ln.startswith('  - ') or ln.startswith('    - '):
                    if not in_sub:
                        out.append('<ul class="sub-ul">')
                        in_sub = True
                    out.append('<li>' + _re.sub(r'\*\*(.+?)\*\*', r'<strong>\1</strong>', ln.lstrip('- ').strip()) + '</li>')
                    continue
                if in_sub:
                    out.append('</ul>')
                    in_sub = False
                if ln.startswith('- '):
                    if not in_ul:
                        out.append('<ul>')
                        in_ul = True
                    out.append('<li>' + _re.sub(r'\*\*(.+?)\*\*', r'<strong>\1</strong>', ln[2:]) + '</li>')
                    continue
                if in_ul and not ln.startswith(' '):
                    out.append('</ul>')
                    in_ul = False
                if ln.startswith('#### '):
                    out.append('<h4>' + _html.escape(ln[5:]) + '</h4>')
                elif ln.startswith('### '):
                    out.append('<h3>' + _html.escape(ln[4:]) + '</h3>')
                elif ln.startswith('## '):
                    out.append('<h2>' + _html.escape(ln[3:]) + '</h2>')
                elif ln.startswith('# '):
                    out.append('<h1>' + _html.escape(ln[2:]) + '</h1>')
                elif ln.startswith('---'):
                    out.append('<hr>')
                elif not ln.strip():
                    if not (in_ul or in_sub):
                        out.append('<br>')
                else:
                    out.append('<p>' + _re.sub(r'\*\*(.+?)\*\*', r'<strong>\1</strong>', _html.escape(ln)) + '</p>')
            if in_sub:
                out.append('</ul>')
            if in_ul:
                out.append('</ul>')
            return '\n'.join(out)

        _rpt_body = ""
        _md_path3 = _Path(self.report_dir) / f"alpha-hive-daily-{date_str}.md"
        if _md_path3.exists():
            try:
                _rpt_body = _md2html(_md_path3.read_text(encoding='utf-8'))
            except Exception:
                _rpt_body = "<p>æŠ¥å‘ŠåŠ è½½å¤±è´¥</p>"


        # â”€â”€ Chart & Radar Data â”€â”€
        import json as _json

        _dir_counts = {"bullish": 0, "bearish": 0, "neutral": 0}
        for _td in all_tickers_sorted:
            _drd = str(opp_by_ticker.get(_td, {}).get("direction") or
                       swarm_detail.get(_td, {}).get("direction", "neutral")).lower()
            if "å¤š" in _drd:   _drd = "bullish"
            elif "ç©º" in _drd: _drd = "bearish"
            elif _drd not in ("bullish","bearish","neutral"): _drd = "neutral"
            _dir_counts[_drd] += 1

        _all_scores = [
            (_td2, float(opp_by_ticker.get(_td2, {}).get("opp_score") or
                         swarm_detail.get(_td2, {}).get("final_score", 0)))
            for _td2 in all_tickers_sorted
        ]
        _avg_score = (sum(s for _, s in _all_scores) / len(_all_scores)) if _all_scores else 0

        def _radar_data(ticker):
            sd = swarm_detail.get(ticker, {})
            ad = sd.get("agent_details", {})
            oracle_det = ad.get("OracleBeeEcho", {}).get("details", {})
            iv_r  = oracle_det.get("iv_rank", 50) or 50
            pc_r  = oracle_det.get("put_call_ratio", 1.0) or 1.0
            buzz_d = ad.get("BuzzBeeWhisper", {}).get("discovery", "")
            sm3 = _re.search(r'æƒ…ç»ª\s*([\d.]+)%', buzz_d)
            sent_v = float(sm3.group(1)) if sm3 else 50.0
            scout_s  = float(ad.get("ScoutBeeNova", {}).get("self_score", 5.0)) * 10
            chron_s  = float(ad.get("ChronosBeeHorizon", {}).get("self_score", 5.0)) * 10
            bear_s   = float(ad.get("BearBeeContrarian", {}).get("score", 5.0))
            risk_v   = max(0.0, (10.0 - bear_s) * 10)
            iv_n     = min(100.0, float(iv_r))
            pc_v     = float(pc_r)
            pc_n     = max(0.0, min(100.0, (2.0 - pc_v) / 1.5 * 100))
            return [round(iv_n,1), round(pc_n,1), round(min(100,sent_v),1),
                    round(min(100,scout_s),1), round(min(100,chron_s),1), round(risk_v,1)]

        _scores_js  = _json.dumps([[t, round(s, 1)] for t, s in _all_scores])
        _dir_js     = _json.dumps([_dir_counts["bullish"], _dir_counts["bearish"], _dir_counts["neutral"]])
        _radar_js   = _json.dumps({t: _radar_data(t) for t in all_tickers_sorted})

        _DOMAINS = {
            "MSFT": "microsoft.com", "NVDA": "nvidia.com",  "TSLA": "tesla.com",
            "META": "meta.com",       "AMZN": "amazon.com",  "RKLB": "rocketlabusa.com",
            "BILI": "bilibili.com",   "VKTX": "vikingtherapeutics.com", "CRCL": "circle.com",
            "GOOGL": "google.com",    "AAPL": "apple.com",   "NFLX": "netflix.com",
        }

        # â”€â”€ New CSS (plain string â€“ no f-string brace escaping) â”€â”€
        new_css = """
:root{--bg:#f0f4ff;--surface:#fff;--surface2:#f8f9fc;--border:#e8ecf3;
      --tp:#1a1f2e;--ts:#64748b;--acc:#F4A532;--acc2:#667eea;--acc3:#764ba2;
      --bull:#22c55e;--bear:#ef4444;--neut:#f59e0b;--nav-h:60px}
html.dark{--bg:#0A0F1C;--surface:#141928;--surface2:#1a2035;--border:#2a3050;--tp:#e2e8f0;--ts:#94a3b8}
*{margin:0;padding:0;box-sizing:border-box}
html{scroll-behavior:smooth}
body{font-family:-apple-system,BlinkMacSystemFont,'Segoe UI',Roboto,sans-serif;
     background:var(--bg);color:var(--tp);min-height:100vh;transition:background .3s,color .3s}
/* NAV */
.nav{position:fixed;top:0;left:0;right:0;z-index:1000;height:var(--nav-h);
     background:rgba(10,15,28,.96);backdrop-filter:blur(10px);
     border-bottom:1px solid rgba(244,165,50,.2);
     display:flex;align-items:center;justify-content:space-between;padding:0 28px}
.nav-logo{display:flex;align-items:center;gap:8px;font-weight:900;font-size:1.1em;color:var(--acc);text-decoration:none}
.nav-links{display:flex;gap:2px}
.nav-link{padding:7px 12px;border-radius:6px;font-size:.85em;font-weight:500;
          color:rgba(255,255,255,.7);text-decoration:none;transition:all .2s}
.nav-link:hover{background:rgba(244,165,50,.15);color:var(--acc)}
.dark-btn{background:rgba(255,255,255,.08);border:1px solid rgba(255,255,255,.15);
          color:#fff;padding:6px 14px;border-radius:8px;cursor:pointer;font-size:.82em;transition:all .2s}
.dark-btn:hover{background:rgba(244,165,50,.2);border-color:var(--acc)}
@media(max-width:768px){.nav-links{display:none}}
/* HERO */
.hero{background:linear-gradient(135deg,#0A0F1C 0%,#141928 55%,#1a1040 100%);
      padding:calc(var(--nav-h) + 36px) 32px 0;position:relative;overflow:hidden}
.hero-inner{max-width:1280px;margin:0 auto;display:flex;align-items:center;
            justify-content:space-between;padding-bottom:36px;gap:40px}
.hero-left{flex:1}
.hero-badge{display:inline-flex;align-items:center;gap:6px;
            background:rgba(244,165,50,.12);border:1px solid rgba(244,165,50,.3);
            color:var(--acc);padding:5px 14px;border-radius:20px;
            font-size:.82em;font-weight:700;margin-bottom:18px}
.hero-title{font-size:clamp(1.8em,3.5vw,2.8em);font-weight:900;color:#fff;
            line-height:1.15;margin-bottom:12px}
.hero-title span{background:linear-gradient(135deg,#F4A532,#f7c55a);
                 -webkit-background-clip:text;-webkit-text-fill-color:transparent}
.hero-sub{color:rgba(255,255,255,.55);font-size:1em;margin-bottom:18px}
.hero-meta{display:flex;flex-wrap:wrap;gap:10px;align-items:center}
.hero-time{color:rgba(255,255,255,.45);font-size:.85em}
.hero-dbadge{background:rgba(34,197,94,.12);border:1px solid rgba(34,197,94,.3);
             color:#4ade80;padding:3px 12px;border-radius:12px;font-size:.8em;font-weight:700}
.hero-right{flex-shrink:0;width:260px}
.hero-svg{width:100%;height:auto}
@keyframes hive-float{0%,100%{transform:translateY(0) rotate(0deg)}50%{transform:translateY(-8px) rotate(2deg)}}
@keyframes hex-pulse{0%,100%{opacity:.6}50%{opacity:1}}
.hive-anim{animation:hive-float 4s ease-in-out infinite}
.hex-p{animation:hex-pulse 2s ease-in-out infinite}
/* HERO STATS ROW */
.hero-stats{max-width:1280px;margin:0 auto;
            display:grid;grid-template-columns:repeat(4,1fr);
            border-top:1px solid rgba(244,165,50,.12)}
.hstat{padding:22px;text-align:center;border-right:1px solid rgba(244,165,50,.08);transition:background .2s}
.hstat:last-child{border-right:none}
.hstat:hover{background:rgba(244,165,50,.04)}
.hstat-val{font-size:2.1em;font-weight:900;color:var(--acc);line-height:1}
.hstat-lbl{font-size:.78em;color:rgba(255,255,255,.45);margin-top:5px;text-transform:uppercase;letter-spacing:.05em}
/* MAIN */
.main{max-width:1280px;margin:0 auto;padding:36px 28px}
.section{background:var(--surface);border-radius:14px;padding:28px;margin-bottom:24px;border:1px solid var(--border)}
.sec-title{font-size:1.2em;font-weight:800;color:var(--tp);margin-bottom:20px;
           display:flex;align-items:center;gap:10px}
.sec-title::before{content:'';display:inline-block;width:4px;height:20px;
                   background:linear-gradient(135deg,var(--acc),var(--acc2));border-radius:2px}
/* TOP 6 CARDS */
.top6-grid{display:grid;grid-template-columns:repeat(3,1fr);gap:18px}
@media(max-width:1024px){.top6-grid{grid-template-columns:repeat(2,1fr)}}
@media(max-width:600px){.top6-grid{grid-template-columns:1fr}}
.scard{border:1px solid var(--border);border-radius:13px;overflow:hidden;
       background:var(--surface2);transition:transform .2s,box-shadow .2s,border-color .2s;position:relative}
.scard:hover{transform:translateY(-4px);box-shadow:0 12px 36px rgba(244,165,50,.14);border-color:var(--acc)}
.scard-head{padding:16px 16px 12px;display:flex;align-items:flex-start;justify-content:space-between}
.slogo-wrap{position:relative}
.slogo{width:42px;height:42px;border-radius:9px;object-fit:contain;
       background:#fff;padding:4px;border:1px solid var(--border)}
.slogo-fb{width:42px;height:42px;border-radius:9px;display:flex;align-items:center;
          justify-content:center;font-weight:900;font-size:.82em;color:#fff;
          background:linear-gradient(135deg,var(--acc2),var(--acc3))}
.srank{font-size:.7em;font-weight:800;background:var(--acc);color:#0A0F1C;
       padding:2px 7px;border-radius:5px;position:absolute;top:-5px;right:-5px}
.sdir{padding:4px 11px;border-radius:18px;font-size:.78em;font-weight:700}
.sdir-bull{background:rgba(34,197,94,.13);color:var(--bull)}
.sdir-bear{background:rgba(239,68,68,.13);color:var(--bear)}
.sdir-neut{background:rgba(245,158,11,.13);color:var(--neut)}
.scard-body{padding:0 16px 16px}
.sticker{font-size:1.4em;font-weight:900;color:var(--tp)}
.sname{font-size:.75em;color:var(--ts);margin-top:1px}
.score-row{display:flex;align-items:center;gap:10px;margin:12px 0 7px}
.score-big{font-size:1.9em;font-weight:900;line-height:1}
.score-big.sc-h{color:var(--bull)}.score-big.sc-m{color:var(--neut)}.score-big.sc-l{color:var(--bear)}
.sbar-wrap{flex:1}
.sbar-lbl{font-size:.7em;color:var(--ts);margin-bottom:3px;display:flex;justify-content:space-between}
.sbar{height:5px;background:var(--border);border-radius:3px;overflow:hidden}
.sbar-fill{height:100%;border-radius:3px}
.fill-h{background:linear-gradient(90deg,#22c55e,#4ade80)}
.fill-m{background:linear-gradient(90deg,#f59e0b,#fbbf24)}
.fill-l{background:linear-gradient(90deg,#ef4444,#f87171)}
.sinsight{font-size:.78em;color:var(--ts);line-height:1.5;border-top:1px solid var(--border);
          padding-top:9px;margin-top:4px;
          display:-webkit-box;-webkit-line-clamp:2;-webkit-box-orient:vertical;overflow:hidden}
.ml-btn{display:inline-flex;align-items:center;gap:4px;margin-top:11px;padding:5px 13px;
        background:linear-gradient(135deg,#667eea,#764ba2);color:#fff;
        border-radius:7px;font-size:.76em;font-weight:700;text-decoration:none;transition:opacity .2s}
.ml-btn:hover{opacity:.85}
/* CHARTS */
.charts-grid{display:grid;grid-template-columns:1fr 2fr 1fr;gap:20px}
@media(max-width:900px){.charts-grid{grid-template-columns:1fr}}
.chart-box{background:var(--surface2);border-radius:12px;padding:22px;border:1px solid var(--border)}
.chart-ttl{font-size:.82em;font-weight:700;color:var(--ts);text-transform:uppercase;
           letter-spacing:.06em;margin-bottom:14px;text-align:center}
/* TABLE */
.tbl-search-row{display:flex;gap:12px;margin-bottom:14px;align-items:center}
.tbl-search{flex:1;max-width:260px;padding:9px 14px;background:var(--surface2);
            border:1px solid var(--border);border-radius:8px;color:var(--tp);
            font-size:.88em;outline:none}
.tbl-search:focus{border-color:var(--acc2)}
.tbl-wrap{overflow-x:auto;-webkit-overflow-scrolling:touch;border-radius:8px;border:1px solid var(--border)}
.full-table{width:100%;border-collapse:collapse;min-width:620px}
.full-table thead{position:sticky;top:0;z-index:5}
.full-table th{padding:11px 13px;text-align:left;font-size:.8em;font-weight:700;
               background:linear-gradient(135deg,#667eea,#764ba2);color:#fff;
               letter-spacing:.04em;white-space:nowrap}
.full-table td{padding:10px 13px;font-size:.86em;border-bottom:1px solid var(--border);color:var(--tp)}
.full-table tbody tr:hover{background:var(--surface2)}
.dcell-bull{background:rgba(34,197,94,.12);color:var(--bull);font-weight:700;
            border-radius:4px;padding:2px 9px;font-size:.8em;display:inline-block}
.dcell-bear{background:rgba(239,68,68,.12);color:var(--bear);font-weight:700;
            border-radius:4px;padding:2px 9px;font-size:.8em;display:inline-block}
.dcell-neut{background:rgba(245,158,11,.12);color:var(--neut);font-weight:700;
            border-radius:4px;padding:2px 9px;font-size:.8em;display:inline-block}
.ml-btn-sm{display:inline-block;padding:3px 9px;background:linear-gradient(135deg,#667eea,#764ba2);
           color:#fff;border-radius:5px;font-size:.75em;font-weight:700;text-decoration:none}
.sc-h{color:var(--bull)}.sc-m{color:var(--neut)}.sc-l{color:var(--bear)}
/* COMPANY DEEP CARDS */
.company-grid{display:grid;grid-template-columns:repeat(auto-fit,minmax(360px,1fr));gap:20px}
@media(max-width:600px){.company-grid{grid-template-columns:1fr}}
.company-card{border:1px solid var(--border);border-radius:13px;overflow:hidden;background:var(--surface2)}
.cc-header{padding:14px 18px;color:#fff;display:flex;justify-content:space-between;align-items:center}
.cc-ticker{font-size:1.25em;font-weight:900}
.cc-dir{font-size:.78em;background:rgba(255,255,255,.18);padding:2px 10px;border-radius:10px}
.cc-score{font-size:.95em;font-weight:700}
.cc-body{padding:16px 18px}
.cc-two{display:grid;grid-template-columns:1fr 1fr;gap:14px;align-items:start}
.cc-metric{display:flex;justify-content:space-between;padding:4px 0;
           border-bottom:1px solid var(--border);font-size:.82em}
.cc-metric:last-child{border-bottom:none}
.cm-l{color:var(--ts)}.cm-v{font-weight:700;color:var(--tp)}
.cc-signals{list-style:none;padding:0;margin:12px 0 0}
.cc-signals li{padding:4px 0;border-bottom:1px dashed var(--border);
               font-size:.8em;color:var(--ts);line-height:1.5}
.cc-signals li:last-child{border-bottom:none}
.cc-footer{margin-top:12px;text-align:right}
.ml-btn-cc{display:inline-flex;align-items:center;gap:4px;padding:5px 13px;
           background:linear-gradient(135deg,#667eea,#764ba2);color:#fff;
           border-radius:7px;font-size:.76em;font-weight:700;text-decoration:none}
/* REPORT */
.report-body{max-height:750px;overflow-y:auto;padding-right:8px;font-size:.88em;
             line-height:1.8;color:var(--tp)}
.report-body h1{font-size:1.35em;color:var(--acc2);border-bottom:2px solid var(--acc2);
                padding-bottom:6px;margin:16px 0 8px}
.report-body h2{font-size:1.1em;color:var(--acc2);border-left:4px solid var(--acc2);
                padding-left:9px;margin:13px 0 5px}
.report-body h3{font-size:.98em;color:var(--acc3);font-weight:700;margin:9px 0 3px}
.report-body ul{margin:4px 0 8px 18px}.report-body li{margin:2px 0}
.report-body hr{border:none;border-top:1px solid var(--border);margin:11px 0}
.report-body p{margin:2px 0}.sub-ul{margin-top:4px;padding-left:16px}
/* MISC */
.res-y{background:rgba(34,197,94,.14);color:var(--bull);border-radius:7px;
       padding:2px 8px;font-size:.77em;font-weight:700;display:inline-block}
.res-n{background:rgba(239,68,68,.1);color:var(--bear);border-radius:7px;
       padding:2px 8px;font-size:.77em;font-weight:700;display:inline-block}
.bear-bar{height:5px;background:var(--border);border-radius:3px;margin-top:2px}
.bear-fill{height:100%;border-radius:3px;background:linear-gradient(90deg,#f59e0b,#ef4444)}
.footer{background:#0A0F1C;color:rgba(255,255,255,.45);text-align:center;
        padding:28px;font-size:.85em}
.footer p{margin:4px 0}
::-webkit-scrollbar{width:5px;height:5px}
::-webkit-scrollbar-track{background:var(--bg)}
::-webkit-scrollbar-thumb{background:rgba(102,126,234,.4);border-radius:3px}
@keyframes pulse{0%,100%{opacity:1}50%{opacity:.5}}
.status-dot{width:10px;height:10px;border-radius:50%;background:#22c55e;animation:pulse 2s infinite;display:inline-block}
"""

        # â”€â”€ Build new Top-6 cards â”€â”€
        new_cards_html = ""
        for _ci, _tc6 in enumerate(all_tickers_sorted[:6], 1):
            _oc6   = opp_by_ticker.get(_tc6, {})
            _sc6   = float(_oc6.get("opp_score") or swarm_detail.get(_tc6, {}).get("final_score", 0))
            _dr6   = str(_oc6.get("direction") or swarm_detail.get(_tc6, {}).get("direction", "neutral")).lower()
            if "å¤š" in _dr6: _dr6 = "bullish"
            elif "ç©º" in _dr6: _dr6 = "bearish"
            elif _dr6 not in ("bullish","bearish","neutral"): _dr6 = "neutral"
            _dlbl6 = {"bullish":"ğŸŸ¢ çœ‹å¤š","bearish":"ğŸ”´ çœ‹ç©º","neutral":"ğŸŸ¡ ä¸­æ€§"}[_dr6]
            _dcls6 = {"bullish":"sdir-bull","bearish":"sdir-bear","neutral":"sdir-neut"}[_dr6]
            _scls6 = sc_cls(_sc6)
            _fcls6 = "fill-h" if _sc6 >= 7.0 else ("fill-m" if _sc6 >= 5.5 else "fill-l")
            _pct6  = int(_sc6 * 10)
            _dom6  = _DOMAINS.get(_tc6, "")
            _logo6 = (f'<img class="slogo" src="https://logo.clearbit.com/{_dom6}" '
                      f'alt="{_html.escape(_tc6)}" onerror="this.style.display=\'none\';this.nextSibling.style.display=\'flex\'">'
                      f'<div class="slogo-fb" style="display:none">{_html.escape(_tc6[:2])}</div>') if _dom6 else \
                     f'<div class="slogo-fb">{_html.escape(_tc6[:2])}</div>'
            # Insight: first non-empty discovery
            _ins6 = ""
            for _agt6 in ["ScoutBeeNova","OracleBeeEcho","BuzzBeeWhisper","ChronosBeeHorizon"]:
                _d6 = swarm_detail.get(_tc6,{}).get("agent_details",{}).get(_agt6,{}).get("discovery","")
                if _d6:
                    _ins6 = _html.escape(_d6.split("|")[0].strip()[:100])
                    break
            _ml6ex = _Path(self.report_dir / f"alpha-hive-{_tc6}-ml-enhanced-{date_str}.html").exists()
            _ml6   = (f'<a href="alpha-hive-{_tc6}-ml-enhanced-{date_str}.html" class="ml-btn">ML è¯¦æƒ… â†’</a>'
                      if _ml6ex else '<span style="font-size:.75em;color:var(--ts);">ML æŠ¥å‘Šç”Ÿæˆä¸­</span>')
            new_cards_html += f"""
            <div class="scard">
              <div class="scard-head">
                <div class="slogo-wrap">{_logo6}<span class="srank">#{_ci}</span></div>
                <span class="sdir {_dcls6}">{_dlbl6}</span>
              </div>
              <div class="scard-body">
                <div class="sticker">{_html.escape(_tc6)}</div>
                <div class="score-row">
                  <span class="score-big {_scls6}">{_sc6:.1f}</span>
                  <div class="sbar-wrap">
                    <div class="sbar-lbl"><span>ç»¼åˆåˆ†</span><span>/10</span></div>
                    <div class="sbar"><div class="sbar-fill {_fcls6}" style="width:{_pct6}%"></div></div>
                  </div>
                </div>
                {f'<div class="sinsight">{_ins6}</div>' if _ins6 else ''}
                {_ml6}
              </div>
            </div>"""

        # â”€â”€ Build Full Table rows â”€â”€
        new_rows_html = ""
        for _ri, _trt in enumerate(all_tickers_sorted, 1):
            _ort = opp_by_ticker.get(_trt, {})
            _srt = float(_ort.get("opp_score") or swarm_detail.get(_trt, {}).get("final_score", 0))
            _drt = str(_ort.get("direction") or swarm_detail.get(_trt, {}).get("direction","neutral")).lower()
            if "å¤š" in _drt: _drt = "bullish"
            elif "ç©º" in _drt: _drt = "bearish"
            elif _drt not in ("bullish","bearish","neutral"): _drt = "neutral"
            _dlrt = {"bullish":"çœ‹å¤š","bearish":"çœ‹ç©º","neutral":"ä¸­æ€§"}[_drt]
            _dclrt = {"bullish":"dcell-bull","bearish":"dcell-bear","neutral":"dcell-neut"}[_drt]
            _scrt = sc_cls(_srt)
            _det_rt = _detail(_trt)
            _res_rt = swarm_detail.get(_trt,{}).get("resonance",{}).get("resonance_detected",False)
            _sup_rt = int(_ort.get("supporting_agents") or swarm_detail.get(_trt,{}).get("supporting_agents",0))
            _res_html_rt = (f'<span class="res-y">{_sup_rt}A</span>' if _res_rt else '<span class="res-n">æ— </span>')
            _ml_ex_rt = _Path(self.report_dir / f"alpha-hive-{_trt}-ml-enhanced-{date_str}.html").exists()
            _ml_rt = (f'<a href="alpha-hive-{_trt}-ml-enhanced-{date_str}.html" class="ml-btn-sm">æŸ¥çœ‹</a>'
                      if _ml_ex_rt else "-")
            _pc_st_rt = (' style="color:var(--bull);font-weight:700"' if _det_rt["pc"] != "-" and float(_det_rt["pc"]) < 0.7
                         else (' style="color:var(--bear);font-weight:700"' if _det_rt["pc"] != "-" and float(_det_rt["pc"]) > 1.5 else ""))
            new_rows_html += f"""
            <tr>
              <td>{_ri}</td>
              <td><strong>{_html.escape(_trt)}</strong></td>
              <td><span class="{_dclrt}">{_dlrt}</span></td>
              <td class="{_scrt}"><strong>{_srt:.1f}</strong>/10</td>
              <td>{_res_html_rt}</td>
              <td>{_det_rt['bullish']}/{_det_rt['bearish_v']}/{_det_rt['neutral_v']}</td>
              <td>{_det_rt['iv_rank']}</td>
              <td{_pc_st_rt}>{_det_rt['pc']}</td>
              <td style="color:var(--neut)">{_det_rt['bear_score']:.1f}</td>
              <td>{_ml_rt}</td>
            </tr>"""

        # â”€â”€ Build Deep Analysis cards (with radar canvas) â”€â”€
        _dir_hdr3 = {"bullish":"#1a7a3a","bearish":"#8b1a1a","neutral":"#7a5c1a"}
        new_company_html = ""
        for _tkrd in all_tickers_sorted:
            _sdd = swarm_detail.get(_tkrd, {})
            _add = _sdd.get("agent_details", {})
            _scd = float(opp_by_ticker.get(_tkrd,{}).get("opp_score") or _sdd.get("final_score", 0))
            _drd = str(opp_by_ticker.get(_tkrd,{}).get("direction") or _sdd.get("direction","neutral")).lower()
            if "å¤š" in _drd: _drd = "bullish"
            elif "ç©º" in _drd: _drd = "bearish"
            elif _drd not in ("bullish","bearish","neutral"): _drd = "neutral"
            _dlbld = {"bullish":"çœ‹å¤š â†‘","bearish":"çœ‹ç©º â†“","neutral":"ä¸­æ€§ â†’"}[_drd]
            _hcd   = _dir_hdr3.get(_drd, "#1a3a7a")
            _detd  = _detail(_tkrd)
            _blstd = []
            for _discd, _icod, _lbd in [
                (_add.get("ScoutBeeNova",{}).get("discovery",""),       "ğŸ“‹","å†…å¹•"),
                (_add.get("OracleBeeEcho",{}).get("discovery",""),      "ğŸ“Š","æœŸæƒ"),
                (_add.get("BuzzBeeWhisper",{}).get("discovery",""),     "ğŸ’¬","æƒ…ç»ª"),
                (_add.get("BearBeeContrarian",{}).get("discovery",""),  "ğŸ»","é£é™©"),
            ]:
                _fd = _discd.split("|")[0].strip()[:85] if _discd else ""
                if _fd:
                    _blstd.append(f'<li>{_icod} <strong>{_lbd}ï¼š</strong>{_html.escape(_fd)}</li>')
            _bhtmld = "\n                    ".join(_blstd) if _blstd else "<li>æ•°æ®é‡‡é›†ä¸­</li>"
            _ml_exd = _Path(self.report_dir / f"alpha-hive-{_tkrd}-ml-enhanced-{date_str}.html").exists()
            _mlbtnd = (f'<a href="alpha-hive-{_tkrd}-ml-enhanced-{date_str}.html" class="ml-btn-cc">ML å¢å¼ºåˆ†æ â†’</a>'
                       if _ml_exd else '<span style="font-size:.78em;color:var(--ts)">ML æŠ¥å‘Šç”Ÿæˆä¸­</span>')
            new_company_html += f"""
            <div class="company-card">
              <div class="cc-header" style="background:{_hcd};">
                <span class="cc-ticker">{_html.escape(_tkrd)}</span>
                <span class="cc-dir">{_dlbld}</span>
                <span class="cc-score">{_scd:.1f}/10</span>
              </div>
              <div class="cc-body">
                <div class="cc-two">
                  <div class="cc-metrics-col">
                    <div class="cc-metric"><span class="cm-l">IV Rank</span><span class="cm-v">{_detd['iv_rank']}</span></div>
                    <div class="cc-metric"><span class="cm-l">P/C Ratio</span><span class="cm-v">{_detd['pc']}</span></div>
                    <div class="cc-metric"><span class="cm-l">çœ‹ç©ºå¼ºåº¦</span><span class="cm-v">{_detd['bear_score']:.1f}/10</span></div>
                    <div class="cc-metric"><span class="cm-l">æŠ•ç¥¨</span><span class="cm-v">{_detd['bullish']}å¤š/{_detd['bearish_v']}ç©º</span></div>
                  </div>
                  <div class="radar-wrap"><canvas id="radar-{_html.escape(_tkrd)}" width="160" height="160"></canvas></div>
                </div>
                <ul class="cc-signals">{_bhtmld}</ul>
                <div class="cc-footer">{_mlbtnd}</div>
              </div>
            </div>"""

        # â”€â”€ Avg Score formatted â”€â”€
        _avg_score_str = f"{_avg_score:.1f}"
        _fg_str2 = _fg_str  # already computed above

        return f"""<!DOCTYPE html>
<html lang="zh-CN" class="">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Alpha Hive æŠ•èµ„ä»ªè¡¨æ¿</title>
<script src="https://cdn.jsdelivr.net/npm/chart.js@4.4.0/dist/chart.umd.min.js"><\/script>
<style>
{new_css}
</style>
</head>
<body>
<!-- â”€â”€ Fixed Nav â”€â”€ -->
<nav class="nav">
  <a href="#" class="nav-logo">ğŸ Alpha Hive</a>
  <div class="nav-links">
    <a href="#today"  class="nav-link">ä»Šæ—¥ç®€æŠ¥</a>
    <a href="#charts" class="nav-link">å›¾è¡¨</a>
    <a href="#list"   class="nav-link">å®Œæ•´æ¸…å•</a>
    <a href="#deep"   class="nav-link">ä¸ªè‚¡æ·±åº¦</a>
    <a href="#report" class="nav-link">å®Œæ•´ç®€æŠ¥</a>
  </div>
  <button class="dark-btn" id="darkBtn" onclick="toggleDark()">ğŸŒ™ æš—é»‘</button>
</nav>

<!-- â”€â”€ Hero Banner â”€â”€ -->
<section class="hero">
  <div class="hero-inner">
    <div class="hero-left">
      <div class="hero-badge">ğŸ Alpha Hive Intelligence Â· èœ‚ç¾¤é©±åŠ¨</div>
      <h1 class="hero-title">å»ä¸­å¿ƒåŒ–<span>èœ‚ç¾¤æ™ºèƒ½</span><br>æŠ•èµ„ç ”ç©¶å¹³å°</h1>
      <p class="hero-sub">{n_agents} è‡ªæ²»å·¥èœ‚åä½œ Â· SEC EDGAR çœŸå®æ•°æ® Â· æ¯æ—¥è‡ªåŠ¨æ‰«æ</p>
      <div class="hero-meta">
        <span class="hero-time">ğŸ• {now_str}</span>
        <span class="hero-dbadge">ğŸ“Š æ•°æ®çœŸå®åº¦ {avg_real}</span>
      </div>
    </div>
    <div class="hero-right">
      <svg class="hero-svg hive-anim" viewBox="0 0 280 260" xmlns="http://www.w3.org/2000/svg">
        <polygon points="140,55 180,78 180,124 140,147 100,124 100,78" fill="#F4A532" opacity=".9"/>
        <text x="140" y="112" text-anchor="middle" font-size="40" fill="white">ğŸ</text>
        <polygon class="hex-p" points="140,5 170,22 170,57 140,74 110,57 110,22" fill="none" stroke="#F4A532" stroke-width="1.5" opacity=".55" style="animation-delay:.3s"/>
        <polygon class="hex-p" points="190,32 220,49 220,84 190,101 160,84 160,49" fill="rgba(244,165,50,.12)" stroke="#F4A532" stroke-width="1" opacity=".5" style="animation-delay:.7s"/>
        <polygon class="hex-p" points="190,107 220,124 220,159 190,176 160,159 160,124" fill="rgba(102,126,234,.18)" stroke="#667eea" stroke-width="1" opacity=".45" style="animation-delay:1.1s"/>
        <polygon class="hex-p" points="190,182 220,199 220,234 190,251 160,234 160,199" fill="none" stroke="#764ba2" stroke-width="1" opacity=".35" style="animation-delay:1.5s"/>
        <polygon class="hex-p" points="140,155 170,172 170,207 140,224 110,207 110,172" fill="rgba(244,165,50,.09)" stroke="#F4A532" stroke-width="1.5" opacity=".45" style="animation-delay:1.9s"/>
        <polygon class="hex-p" points="90,182 120,199 120,234 90,251 60,234 60,199" fill="none" stroke="#667eea" stroke-width="1" opacity=".35" style="animation-delay:2.3s"/>
        <polygon class="hex-p" points="90,107 120,124 120,159 90,176 60,159 60,124" fill="rgba(102,126,234,.13)" stroke="#667eea" stroke-width="1" opacity=".45" style="animation-delay:2.7s"/>
        <polygon class="hex-p" points="90,32 120,49 120,84 90,101 60,84 60,49" fill="none" stroke="#764ba2" stroke-width="1" opacity=".35" style="animation-delay:3.1s"/>
      </svg>
    </div>
  </div>
  <!-- Stats Row -->
  <div class="hero-stats">
    <div class="hstat">
      <div class="hstat-val">{n_resonance}</div>
      <div class="hstat-lbl">å…±æŒ¯ä¿¡å·</div>
    </div>
    <div class="hstat">
      <div class="hstat-val" style="color:{_fg_color}">{_fg_str2}</div>
      <div class="hstat-lbl">Fear & Greed</div>
    </div>
    <div class="hstat">
      <div class="hstat-val">{n_tickers}</div>
      <div class="hstat-lbl">æ‰«ææ ‡çš„</div>
    </div>
    <div class="hstat">
      <div class="hstat-val">{_avg_score_str}</div>
      <div class="hstat-lbl">å¹³å‡ç»¼åˆåˆ†</div>
    </div>
  </div>
</section>

<div class="main">
  <!-- â”€â”€ Top 6 Cards â”€â”€ -->
  <div class="section" id="today">
    <div class="sec-title">ä»Šæ—¥ Top {min(6, len(all_tickers_sorted))} æœºä¼š</div>
    <div class="top6-grid">
      {new_cards_html}
    </div>
  </div>

  <!-- â”€â”€ Charts â”€â”€ -->
  <div class="section" id="charts">
    <div class="sec-title">å¸‚åœºå¯è§†åŒ–</div>
    <div class="charts-grid">
      <div class="chart-box">
        <div class="chart-ttl">ğŸ˜¨ Fear &amp; Greed æŒ‡æ•°</div>
        <div class="chart-canvas-wrap" style="height:180px"><canvas id="fgChart"></canvas></div>
      </div>
      <div class="chart-box">
        <div class="chart-ttl">ğŸ“Š å„æ ‡çš„ç»¼åˆè¯„åˆ†</div>
        <div class="chart-canvas-wrap" style="height:{'{}px'.format(max(160, len(all_tickers_sorted)*28))}"><canvas id="scoresChart"></canvas></div>
      </div>
      <div class="chart-box">
        <div class="chart-ttl">ğŸ—³ çœ‹å¤š / çœ‹ç©º / ä¸­æ€§</div>
        <div class="chart-canvas-wrap" style="height:180px"><canvas id="dirChart"></canvas></div>
      </div>
    </div>
  </div>

  <!-- â”€â”€ Full Table â”€â”€ -->
  <div class="section" id="list">
    <div class="sec-title">å®Œæ•´æœºä¼šæ¸…å•</div>
    <div class="tbl-search-row">
      <input class="tbl-search" id="tableSearch" type="text" placeholder="ğŸ” æœç´¢æ ‡çš„..." oninput="filterTable()">
    </div>
    <div class="tbl-wrap">
      <table class="full-table" id="oppTable">
        <thead><tr>
          <th>#</th><th>æ ‡çš„</th><th>æ–¹å‘</th><th>ç»¼åˆåˆ†</th><th>å…±æŒ¯</th>
          <th>æŠ•ç¥¨(å¤š/ç©º/ä¸­)</th><th>IV Rank</th><th>P/C</th><th>çœ‹ç©ºå¼ºåº¦</th><th>ML è¯¦æƒ…</th>
        </tr></thead>
        <tbody>{new_rows_html}</tbody>
      </table>
    </div>
  </div>

  <!-- â”€â”€ Deep Analysis â”€â”€ -->
  <div class="section" id="deep">
    <div class="sec-title">ä¸ªè‚¡æ·±åº¦åˆ†æï¼ˆå«é›·è¾¾å›¾ï¼‰</div>
    <div class="company-grid">{new_company_html}</div>
  </div>

  <!-- â”€â”€ Markdown Report â”€â”€ -->
  <div class="section" id="report">
    <div class="sec-title">å®Œæ•´èœ‚ç¾¤ç®€æŠ¥</div>
    <div class="report-body">{_rpt_body}</div>
  </div>
</div>

<footer class="footer">
  <p>ğŸ Alpha Hive â€” å»ä¸­å¿ƒåŒ–èœ‚ç¾¤æ™ºèƒ½æŠ•èµ„ç ”ç©¶å¹³å°</p>
  <p>æ›´æ–°ï¼š{now_str} | {n_tickers} æ ‡çš„ | SEC çœŸå®æ•°æ® | çœŸå®åº¦ {avg_real}</p>
  <p style="margin-top:8px;font-size:.82em;opacity:.6">
    å£°æ˜ï¼šæœ¬æŠ¥å‘Šç”± AI èœ‚ç¾¤è‡ªåŠ¨ç”Ÿæˆï¼Œä»…ä¾›ç ”ç©¶å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚æ‰€æœ‰å†³ç­–è¯·è‡ªè¡Œåˆ¤æ–­ã€‚
  </p>
</footer>

<script>
// â”€â”€ Dark Mode â”€â”€
function toggleDark(){{
  var h=document.documentElement;
  h.classList.toggle('dark');
  localStorage.setItem('ahDark',h.classList.contains('dark')?'1':'0');
  document.getElementById('darkBtn').textContent=h.classList.contains('dark')?'â˜€ï¸ äº®è‰²':'ğŸŒ™ æš—é»‘';
}}
if(localStorage.getItem('ahDark')==='1'){{
  document.documentElement.classList.add('dark');
}}
document.addEventListener('DOMContentLoaded',function(){{
  var b=document.getElementById('darkBtn');
  if(b&&document.documentElement.classList.contains('dark'))b.textContent='â˜€ï¸ äº®è‰²';
}});

// â”€â”€ Table Search â”€â”€
function filterTable(){{
  var q=document.getElementById('tableSearch').value.toLowerCase();
  document.querySelectorAll('#oppTable tbody tr').forEach(function(tr){{
    tr.style.display=tr.textContent.toLowerCase().includes(q)?'':'none';
  }});
}}

// â”€â”€ Charts â”€â”€
document.addEventListener('DOMContentLoaded',function(){{
  var dark=document.documentElement.classList.contains('dark');
  var tc=dark?'rgba(255,255,255,.65)':'rgba(0,0,0,.55)';
  var gc=dark?'rgba(255,255,255,.07)':'rgba(0,0,0,.06)';

  // F&G Gauge
  var fgCtx=document.getElementById('fgChart');
  if(fgCtx){{
    var fv={_fv3};
    var fc=fv<=25?'#ef4444':fv<=45?'#f97316':fv<=55?'#f59e0b':fv<=75?'#22c55e':'#16a34a';
    var fl='{_fg_label}';
    new Chart(fgCtx,{{
      type:'doughnut',
      data:{{datasets:[{{data:[fv,100-fv],backgroundColor:[fc,dark?'#2a3050':'#e8ecf3'],
                         borderWidth:0,circumference:180,rotation:-90}}]}},
      options:{{responsive:true,maintainAspectRatio:false,cutout:'72%',
               plugins:{{legend:{{display:false}},tooltip:{{enabled:false}}}}}},
      plugins:[{{id:'fgTxt',afterDraw:function(ch){{
        var cx=ch.ctx,w=ch.width,h=ch.height;
        cx.save();
        cx.font='bold 26px system-ui';cx.fillStyle=fc;cx.textAlign='center';cx.textBaseline='middle';
        cx.fillText(fv,w/2,h*.60);
        cx.font='11px system-ui';cx.fillStyle=tc;cx.fillText(fl,w/2,h*.60+20);
        cx.restore();
      }}}}]
    }});
  }}

  // Scores Bar
  var scCtx=document.getElementById('scoresChart');
  if(scCtx){{
    var sc={_scores_js};
    var clrs=sc.map(function(x){{return x[1]>=7?'rgba(34,197,94,.85)':x[1]>=5.5?'rgba(245,158,11,.85)':'rgba(239,68,68,.85)';}});
    new Chart(scCtx,{{
      type:'bar',
      data:{{labels:sc.map(function(x){{return x[0];}}),
             datasets:[{{data:sc.map(function(x){{return x[1];}}),backgroundColor:clrs,borderRadius:5,borderSkipped:false}}]}},
      options:{{indexAxis:'y',responsive:true,maintainAspectRatio:false,
               plugins:{{legend:{{display:false}},tooltip:{{callbacks:{{label:function(c){{return' '+c.raw+'/10';}}}}}}}},
               scales:{{
                 x:{{min:0,max:10,grid:{{color:gc}},ticks:{{color:tc,font:{{size:10}}}}}},
                 y:{{grid:{{display:false}},ticks:{{color:tc,font:{{size:10,weight:'bold'}}}}}}
               }}}}
    }});
  }}

  // Direction Donut
  var dirCtx=document.getElementById('dirChart');
  if(dirCtx){{
    var dd={_dir_js};
    new Chart(dirCtx,{{
      type:'doughnut',
      data:{{labels:['çœ‹å¤š','çœ‹ç©º','ä¸­æ€§'],
             datasets:[{{data:dd,
                         backgroundColor:['rgba(34,197,94,.85)','rgba(239,68,68,.85)','rgba(245,158,11,.85)'],
                         borderColor:[dark?'#141928':'#fff'],borderWidth:2}}]}},
      options:{{responsive:true,maintainAspectRatio:false,cutout:'58%',
               plugins:{{legend:{{position:'bottom',labels:{{color:tc,font:{{size:10}},boxWidth:11,padding:10}}}},
                         tooltip:{{callbacks:{{label:function(c){{return' '+c.label+': '+c.raw+' åª';}}}}}}}}}}
    }});
  }}

  // Radar per ticker
  var rd={_radar_js};
  var rl=['IV Rank','P/Cä¿¡å·','æƒ…ç»ª','èªæ˜é’±','å‚¬åŒ–å‰‚','é£é™©æ§åˆ¶'];
  Object.keys(rd).forEach(function(tk){{
    var cv=document.getElementById('radar-'+tk);
    if(!cv)return;
    new Chart(cv,{{
      type:'radar',
      data:{{labels:rl,datasets:[{{data:rd[tk],fill:true,
               backgroundColor:'rgba(102,126,234,.13)',borderColor:'#667eea',
               pointBackgroundColor:'#667eea',pointBorderColor:'#fff',pointRadius:2,borderWidth:1.5}}]}},
      options:{{responsive:true,maintainAspectRatio:true,
               scales:{{r:{{min:0,max:100,beginAtZero:true,
                            grid:{{color:gc}},angleLines:{{color:gc}},
                            ticks:{{display:false}},
                            pointLabels:{{color:tc,font:{{size:8}}}}}}}},
               plugins:{{legend:{{display:false}}}}}}
    }});
  }});
}});
<\/script>
</body>
</html>"""

def main():
    """ä¸»å…¥å£"""

    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(
        description="Alpha Hive æ¯æ—¥æŠ•èµ„ç®€æŠ¥ç”Ÿæˆå™¨",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•ï¼š
  # ä¼ ç»Ÿ ML æ¨¡å¼ï¼ˆé»˜è®¤ï¼‰
  python3 alpha_hive_daily_report.py
  python3 alpha_hive_daily_report.py --tickers NVDA TSLA VKTX
  python3 alpha_hive_daily_report.py --all-watchlist

  # èœ‚ç¾¤åä½œæ¨¡å¼ï¼ˆ7 ä¸ªè‡ªæ²»å·¥èœ‚ï¼š6 æ ¸å¿ƒ + BearBeeContrarianï¼‰
  python3 alpha_hive_daily_report.py --swarm --tickers NVDA TSLA VKTX
  python3 alpha_hive_daily_report.py --swarm --all-watchlist
        """
    )
    parser.add_argument(
        '--tickers',
        nargs='+',
        default=["NVDA", "TSLA", "VKTX", "META", "MSFT", "RKLB", "BILI", "AMZN", "CRCL"],
        help='è¦æ‰«æçš„è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼ˆç©ºæ ¼åˆ†éš”ï¼Œé»˜è®¤ï¼šNVDA TSLA VKTX META MSFT RKLB BILI AMZN CRCLï¼‰'
    )
    parser.add_argument(
        '--all-watchlist',
        action='store_true',
        help='æ‰«æé…ç½®ä¸­çš„å…¨éƒ¨ç›‘æ§åˆ—è¡¨'
    )
    parser.add_argument(
        '--swarm',
        action='store_true',
        help='å¯ç”¨èœ‚ç¾¤åä½œæ¨¡å¼ï¼ˆ7 ä¸ªè‡ªæ²»å·¥èœ‚ï¼š6 æ ¸å¿ƒå¹¶è¡Œ + BearBeeContrarian çœ‹ç©ºå¯¹å†²ï¼‰'
    )
    parser.add_argument(
        '--check-earnings',
        action='store_true',
        help='æ£€æŸ¥ä»Šæ—¥è´¢æŠ¥å¹¶è‡ªåŠ¨æ›´æ–°ç®€æŠ¥ï¼ˆå¯å•ç‹¬è¿è¡Œï¼Œä¸éœ€è¦é‡æ–°æ‰«æï¼‰'
    )
    parser.add_argument(
        '--no-llm',
        action='store_true',
        help='è·³è¿‡è¯¢é—®ï¼Œç›´æ¥ä½¿ç”¨è§„åˆ™å¼•æ“æ¨¡å¼ï¼ˆä¸è°ƒç”¨ Claude APIï¼‰'
    )
    parser.add_argument(
        '--use-llm',
        action='store_true',
        help='è·³è¿‡è¯¢é—®ï¼Œç›´æ¥ä½¿ç”¨ LLM æ··åˆæ¨¡å¼'
    )

    args = parser.parse_args()

    # â”€â”€ LLM æ¨¡å¼é€‰æ‹©ï¼ˆæ¯æ¬¡è·‘ç®€æŠ¥å‰è¯¢é—®ï¼‰â”€â”€
    import llm_service as _llm_svc
    _llm_key_exists = bool(_llm_svc._load_api_key())

    if args.no_llm:
        use_llm = False
    elif args.use_llm:
        use_llm = True
    elif _llm_key_exists:
        print("\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
        print("â”‚        Alpha Hive â€” åˆ†ææ¨¡å¼é€‰æ‹©        â”‚")
        print("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
        print("â”‚  [1] LLM æ··åˆæ¨¡å¼  Claude APIï¼ˆæ¨èï¼‰   â”‚")
        print("â”‚      QueenDistiller + BuzzBee è¯­ä¹‰å¢å¼º  â”‚")
        print("â”‚      è€—æ—¶ ~100s / 9 æ ‡çš„ï¼Œçº¦ $0.10      â”‚")
        print("â”‚                                         â”‚")
        print("â”‚  [2] è§„åˆ™å¼•æ“æ¨¡å¼  çº¯è§„åˆ™ï¼ˆæµ‹è¯•è¿­ä»£ï¼‰   â”‚")
        print("â”‚      è€—æ—¶ ~26sï¼Œ$0 API è´¹ç”¨             â”‚")
        print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
        choice = input("è¯·é€‰æ‹© [1/2ï¼Œé»˜è®¤ 1]ï¼š").strip()
        use_llm = (choice != "2")
    else:
        use_llm = False
        print("âš ï¸  æœªæ£€æµ‹åˆ° API Keyï¼Œä½¿ç”¨è§„åˆ™å¼•æ“æ¨¡å¼")

    if not use_llm:
        _llm_svc.disable()
        print("ğŸ”§ è§„åˆ™å¼•æ“æ¨¡å¼\n")
    else:
        print("ğŸ§  LLM æ··åˆæ¨¡å¼ï¼ˆClaude APIï¼‰\n")

    # åˆ›å»ºæŠ¥å‘Šç”Ÿæˆå™¨
    reporter = AlphaHiveDailyReporter()

    # å¦‚æœåªæ˜¯æ£€æŸ¥è´¢æŠ¥æ›´æ–°
    if args.check_earnings:
        focus_tickers = list(WATCHLIST.keys())[:10] if args.all_watchlist else args.tickers
        result = reporter.check_earnings_updates(tickers=focus_tickers)
        reporting = result.get("reporting_today", [])
        updated = result.get("updated", [])
        if reporting:
            _log.info("ä»Šæ—¥è´¢æŠ¥: %s | å·²æ›´æ–°: %s", reporting, updated)
        else:
            _log.info("ä»Šæ—¥æ—  watchlist æ ‡çš„å‘å¸ƒè´¢æŠ¥")
        return result

    # ç¡®å®šæ‰«ææ ‡çš„
    focus_tickers = list(WATCHLIST.keys())[:10] if args.all_watchlist else args.tickers

    if args.swarm:
        report = reporter.run_swarm_scan(focus_tickers=focus_tickers)
    else:
        report = reporter.run_daily_scan(focus_tickers=focus_tickers)

    # ä¿å­˜æŠ¥å‘Šï¼ˆHive app é€šè¿‡ .swarm_results_{date}.json è‡ªåŠ¨åŒæ­¥ï¼‰
    report_path = reporter.save_report(report)
    _log.info("æŠ¥å‘Šå·²ä¿å­˜ï¼š%s", report_path)

    # ä¸‰ç«¯åŒæ­¥ï¼šGitHub æäº¤æ¨é€ + Hive App + Slack
    print("\nğŸ“¡ åŒæ­¥ä¸‰ç«¯ï¼šGitHub / Hive App / Slack...")
    try:
        sync_results = reporter.auto_commit_and_notify(report)
        git_ok = sync_results.get("git_push", {}).get("success", False)
        deploy_env = sync_results.get("deploy_env", "production")
        remote_label = sync_results.get("git_push", {}).get("remote", "origin")
        if deploy_env == "test":
            print(f"   GitHub push : {'âœ…' if git_ok else 'âš ï¸  å¤±è´¥'} â†’ ğŸ”§ æµ‹è¯•ç¯å¢ƒ https://wangmingjie36-creator.github.io/alpha-hive-test/")
        else:
            print(f"   GitHub push : {'âœ…' if git_ok else 'âš ï¸  å¤±è´¥'} â†’ ğŸ§  ç”Ÿäº§ç¯å¢ƒ https://wangmingjie36-creator.github.io/alpha-hive-deploy/")
        print(f"   Hive App    : âœ… .swarm_results å·²è½ç›˜ï¼Œä¸‹æ¬¡å¯åŠ¨è‡ªåŠ¨åŠ è½½")
    except (OSError, ValueError, KeyError, RuntimeError) as e:
        _log.warning("ä¸‰ç«¯åŒæ­¥éƒ¨åˆ†å¤±è´¥: %s", e)
        print(f"   âš ï¸  ä¸‰ç«¯åŒæ­¥å‡ºé”™ï¼š{e}")

    return report


if __name__ == "__main__":
    main()
