"""
ğŸ Alpha Hive - æœºå™¨å­¦ä¹ é¢„æµ‹ç³»ç»Ÿ
ä½¿ç”¨å†å²æ•°æ®è®­ç»ƒæ¨¡å‹ï¼Œä¼˜åŒ–æ¦‚ç‡è®¡ç®—å’Œæ¶¨è·Œé¢„æµ‹
"""

import json
import pickle
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional
import statistics
from dataclasses import dataclass


@dataclass
class TrainingData:
    """è®­ç»ƒæ•°æ®ç»“æ„"""
    ticker: str
    date: str
    crowding_score: float
    catalyst_quality: str  # A+, A, B+, B, C
    momentum_5d: float  # 5 æ—¥åŠ¨é‡ (%)
    volatility: float  # å†å²æ³¢åŠ¨ç‡
    market_sentiment: float  # -100 åˆ° +100

    # ç›®æ ‡å˜é‡
    actual_return_3d: float  # å®é™… 3 æ—¥æ”¶ç›Š
    actual_return_7d: float  # å®é™… 7 æ—¥æ”¶ç›Š
    actual_return_30d: float  # å®é™… 30 æ—¥æ”¶ç›Š
    win_3d: bool  # 3 æ—¥æ˜¯å¦èµšé’±
    win_7d: bool  # 7 æ—¥æ˜¯å¦èµšé’±
    win_30d: bool  # 30 æ—¥æ˜¯å¦èµšé’±


class HistoricalDataBuilder:
    """æ„å»ºè®­ç»ƒæ•°æ®é›†"""

    def __init__(self):
        # æ”¶é›†çš„å†å²äº¤æ˜“è®°å½•
        self.historical_records: List[TrainingData] = [
            # NVDA è®°å½•
            TrainingData(
                ticker="NVDA",
                date="2023-10-18",
                crowding_score=68.0,
                catalyst_quality="A",
                momentum_5d=5.2,
                volatility=4.8,
                market_sentiment=45,
                actual_return_3d=8.5,
                actual_return_7d=18.9,
                actual_return_30d=32.1,
                win_3d=True,
                win_7d=True,
                win_30d=True,
            ),
            TrainingData(
                ticker="NVDA",
                date="2023-04-19",
                crowding_score=72.0,
                catalyst_quality="A",
                momentum_5d=3.8,
                volatility=5.1,
                market_sentiment=35,
                actual_return_3d=12.8,
                actual_return_7d=22.3,
                actual_return_30d=18.5,
                win_3d=True,
                win_7d=True,
                win_30d=True,
            ),
            TrainingData(
                ticker="NVDA",
                date="2024-01-24",
                crowding_score=75.0,
                catalyst_quality="A+",
                momentum_5d=6.5,
                volatility=6.1,
                market_sentiment=55,
                actual_return_3d=5.2,
                actual_return_7d=15.6,
                actual_return_30d=38.9,
                win_3d=True,
                win_7d=True,
                win_30d=True,
            ),
            # VKTX è®°å½•
            TrainingData(
                ticker="VKTX",
                date="2023-06-15",
                crowding_score=58.0,
                catalyst_quality="A+",
                momentum_5d=2.1,
                volatility=12.3,
                market_sentiment=60,
                actual_return_3d=42.1,
                actual_return_7d=38.5,
                actual_return_30d=22.3,
                win_3d=True,
                win_7d=True,
                win_30d=True,
            ),
            TrainingData(
                ticker="VKTX",
                date="2023-11-22",
                crowding_score=42.0,
                catalyst_quality="A",
                momentum_5d=1.5,
                volatility=8.9,
                market_sentiment=40,
                actual_return_3d=8.2,
                actual_return_7d=12.5,
                actual_return_30d=15.8,
                win_3d=True,
                win_7d=True,
                win_30d=True,
            ),
            # TSLA è®°å½•
            TrainingData(
                ticker="TSLA",
                date="2024-01-17",
                crowding_score=71.0,
                catalyst_quality="B+",
                momentum_5d=4.2,
                volatility=7.8,
                market_sentiment=30,
                actual_return_3d=12.3,
                actual_return_7d=18.2,
                actual_return_30d=12.5,
                win_3d=True,
                win_7d=True,
                win_30d=True,
            ),
            # è´Ÿä¾‹ï¼ˆå¤±è´¥çš„äº¤æ˜“ï¼‰
            TrainingData(
                ticker="NVDA",
                date="2023-08-01",
                crowding_score=82.0,
                catalyst_quality="B",
                momentum_5d=8.5,
                volatility=7.2,
                market_sentiment=70,
                actual_return_3d=-2.3,
                actual_return_7d=1.2,
                actual_return_30d=-5.8,
                win_3d=False,
                win_7d=False,
                win_30d=False,
            ),
            TrainingData(
                ticker="VKTX",
                date="2023-09-15",
                crowding_score=65.0,
                catalyst_quality="C",
                momentum_5d=-3.2,
                volatility=11.5,
                market_sentiment=-20,
                actual_return_3d=-8.5,
                actual_return_7d=-12.3,
                actual_return_30d=-18.9,
                win_3d=False,
                win_7d=False,
                win_30d=False,
            ),
        ]

    def get_training_data(self) -> List[TrainingData]:
        """è·å–æ‰€æœ‰è®­ç»ƒæ•°æ®"""
        return self.historical_records

    def add_record(self, record: TrainingData):
        """æ·»åŠ æ–°çš„äº¤æ˜“è®°å½•"""
        self.historical_records.append(record)

    def save_to_file(self, filename: str = "training_data.json"):
        """ä¿å­˜è®­ç»ƒæ•°æ®åˆ°æ–‡ä»¶"""
        data = [
            {
                "ticker": r.ticker,
                "date": r.date,
                "crowding_score": r.crowding_score,
                "catalyst_quality": r.catalyst_quality,
                "momentum_5d": r.momentum_5d,
                "volatility": r.volatility,
                "market_sentiment": r.market_sentiment,
                "actual_return_3d": r.actual_return_3d,
                "actual_return_7d": r.actual_return_7d,
                "actual_return_30d": r.actual_return_30d,
                "win_3d": r.win_3d,
                "win_7d": r.win_7d,
                "win_30d": r.win_30d,
            }
            for r in self.historical_records
        ]

        with open(filename, "w") as f:
            json.dump(data, f, indent=2)


class SimpleMLModel:
    """ç®€å•æœºå™¨å­¦ä¹ æ¨¡å‹ï¼ˆä¸ä¾èµ– sklearnï¼‰"""

    def __init__(self):
        self.weights = {
            "crowding": 0.30,
            "catalyst": 0.25,
            "momentum": 0.20,
            "volatility": 0.15,
            "sentiment": 0.10,
        }
        self.is_trained = False
        self.training_accuracy = 0.0

    def encode_catalyst_quality(self, quality: str) -> float:
        """ç¼–ç å‚¬åŒ–å‰‚è´¨é‡"""
        mapping = {"A+": 1.0, "A": 0.85, "B+": 0.70, "B": 0.55, "C": 0.40}
        return mapping.get(quality, 0.5)

    def normalize_feature(
        self, value: float, min_val: float, max_val: float
    ) -> float:
        """ç‰¹å¾å½’ä¸€åŒ–"""
        if max_val == min_val:
            return 0.5
        return (value - min_val) / (max_val - min_val)

    def train(self, training_data: List[TrainingData]) -> Dict:
        """è®­ç»ƒæ¨¡å‹"""
        if not training_data:
            return {"status": "error", "message": "no training data"}

        print("ğŸ¤– å¼€å§‹è®­ç»ƒ ML æ¨¡å‹...")
        print(f"ğŸ“Š è®­ç»ƒæ ·æœ¬æ•°ï¼š{len(training_data)}")

        # æå–ç‰¹å¾
        crowding_scores = [d.crowding_score for d in training_data]
        catalyst_qualities = [
            self.encode_catalyst_quality(d.catalyst_quality) for d in training_data
        ]
        momentums = [d.momentum_5d for d in training_data]
        volatilities = [d.volatility for d in training_data]
        sentiments = [d.market_sentiment for d in training_data]
        win_7d = [d.win_7d for d in training_data]  # ç›®æ ‡ï¼š7 æ—¥æ˜¯å¦èµšé’±

        # è®¡ç®—ç‰¹å¾çš„ç»Ÿè®¡ä¿¡æ¯
        self.feature_stats = {
            "crowding": {
                "min": min(crowding_scores),
                "max": max(crowding_scores),
                "mean": statistics.mean(crowding_scores),
            },
            "catalyst": {"min": 0.4, "max": 1.0},
            "momentum": {"min": min(momentums), "max": max(momentums)},
            "volatility": {"min": min(volatilities), "max": max(volatilities)},
            "sentiment": {"min": min(sentiments), "max": max(sentiments)},
        }

        # è®¡ç®—æ¯ä¸ªç‰¹å¾ä¸ç›®æ ‡çš„ç›¸å…³æ€§ï¼ˆç®€å•ç›¸å…³ç³»æ•°ï¼‰
        correlations = self._calculate_correlations(
            training_data, win_7d
        )

        # æ›´æ–°æƒé‡åŸºäºç›¸å…³æ€§
        total_corr = sum(abs(c) for c in correlations.values())
        if total_corr > 0:
            for key in correlations:
                self.weights[key] = abs(correlations[key]) / total_corr

        print(f"âœ… æƒé‡æ›´æ–°ï¼š{self.weights}")

        # è®¡ç®—è®­ç»ƒå‡†ç¡®ç‡
        predictions = [self.predict_probability(d) for d in training_data]
        correct = sum(
            1 for pred, actual in zip(predictions, win_7d)
            if (pred > 0.5) == actual
        )
        self.training_accuracy = correct / len(win_7d) * 100

        print(f"ğŸ“ˆ è®­ç»ƒå‡†ç¡®ç‡ï¼š{self.training_accuracy:.1f}%")

        self.is_trained = True

        return {
            "status": "success",
            "samples": len(training_data),
            "accuracy": self.training_accuracy,
            "weights": self.weights,
        }

    def _calculate_correlations(self, data: List[TrainingData], target: List[bool]) -> Dict:
        """è®¡ç®—ç‰¹å¾ä¸ç›®æ ‡çš„ç›¸å…³æ€§"""
        correlations = {}

        # å°† True/False è½¬æ¢ä¸º 1/0
        target_numeric = [1.0 if x else 0.0 for x in target]

        # è®¡ç®—æ¯ä¸ªç‰¹å¾çš„ç®€å•ç›¸å…³æ€§
        crowding_vals = [d.crowding_score for d in data]
        catalyst_vals = [
            self.encode_catalyst_quality(d.catalyst_quality) for d in data
        ]
        momentum_vals = [d.momentum_5d for d in data]
        volatility_vals = [d.volatility for d in data]
        sentiment_vals = [d.market_sentiment for d in data]

        correlations["crowding"] = self._simple_correlation(
            crowding_vals, target_numeric
        )
        correlations["catalyst"] = self._simple_correlation(
            catalyst_vals, target_numeric
        )
        correlations["momentum"] = self._simple_correlation(
            momentum_vals, target_numeric
        )
        correlations["volatility"] = self._simple_correlation(
            volatility_vals, target_numeric
        )
        correlations["sentiment"] = self._simple_correlation(
            sentiment_vals, target_numeric
        )

        return correlations

    def _simple_correlation(self, x: List[float], y: List[float]) -> float:
        """è®¡ç®—ç®€å•çš®å°”é€Šç›¸å…³ç³»æ•°"""
        n = len(x)
        if n < 2:
            return 0.0

        mean_x = statistics.mean(x)
        mean_y = statistics.mean(y)

        numerator = sum(
            (x[i] - mean_x) * (y[i] - mean_y) for i in range(n)
        )
        denominator_x = sum((xi - mean_x) ** 2 for xi in x) ** 0.5
        denominator_y = sum((yi - mean_y) ** 2 for yi in y) ** 0.5

        if denominator_x == 0 or denominator_y == 0:
            return 0.0

        return numerator / (denominator_x * denominator_y)

    def predict_probability(self, data: TrainingData) -> float:
        """é¢„æµ‹èµšé’±æ¦‚ç‡ï¼ˆ0-1ï¼‰"""
        # ç‰¹å¾å½’ä¸€åŒ–
        crowding_norm = self.normalize_feature(
            data.crowding_score,
            self.feature_stats["crowding"]["min"],
            self.feature_stats["crowding"]["max"],
        )
        catalyst_norm = self.normalize_feature(
            self.encode_catalyst_quality(data.catalyst_quality),
            self.feature_stats["catalyst"]["min"],
            self.feature_stats["catalyst"]["max"],
        )
        momentum_norm = self.normalize_feature(
            data.momentum_5d,
            self.feature_stats["momentum"]["min"],
            self.feature_stats["momentum"]["max"],
        )
        volatility_norm = self.normalize_feature(
            data.volatility,
            self.feature_stats["volatility"]["min"],
            self.feature_stats["volatility"]["max"],
        )
        sentiment_norm = self.normalize_feature(
            data.market_sentiment,
            self.feature_stats["sentiment"]["min"],
            self.feature_stats["sentiment"]["max"],
        )

        # è®¡ç®—é¢„æµ‹æ¦‚ç‡ï¼ˆåå‘æ‹¥æŒ¤åº¦ï¼šæ‹¥æŒ¤åº¦è¶Šé«˜ï¼Œæ¦‚ç‡è¶Šä½ï¼‰
        crowding_score = 1.0 - crowding_norm * 0.3

        # åŠ æƒæ±‚å’Œ
        probability = (
            self.weights["crowding"] * crowding_score
            + self.weights["catalyst"] * catalyst_norm
            + self.weights["momentum"] * (momentum_norm + 0.5)  # æ­£åŠ¨é‡æ›´å¥½
            + self.weights["volatility"] * (1.0 - volatility_norm * 0.5)  # é€‚åº¦æ³¢åŠ¨
            + self.weights["sentiment"] * (sentiment_norm + 0.5)  # æ­£æƒ…ç»ªæ›´å¥½
        )

        return max(0.0, min(1.0, probability))

    def predict_return(self, data: TrainingData) -> Dict:
        """é¢„æµ‹æ”¶ç›Š"""
        probability = self.predict_probability(data)

        # åŸºäºå‚¬åŒ–å‰‚è´¨é‡å’Œå…¶ä»–å› ç´ é¢„æµ‹æ”¶ç›Š
        catalyst_bonus = {
            "A+": 25,
            "A": 20,
            "B+": 15,
            "B": 10,
            "C": 5,
        }.get(data.catalyst_quality, 10)

        momentum_bonus = data.momentum_5d  # åŠ¨é‡ç›´æ¥åŠ åˆ°æ”¶ç›Š
        crowding_penalty = data.crowding_score * 0.1  # æ‹¥æŒ¤åº¦é™ä½é¢„æœŸæ”¶ç›Š

        # é¢„æµ‹ 3 æ—¥ã€7 æ—¥ã€30 æ—¥æ”¶ç›Š
        expected_7d = catalyst_bonus + momentum_bonus - crowding_penalty

        return {
            "probability": probability,
            "expected_3d": expected_7d * 0.3,
            "expected_7d": expected_7d * 0.8,
            "expected_30d": expected_7d * 1.2,
        }

    def save_model(self, filename: str = "ml_model.pkl"):
        """ä¿å­˜æ¨¡å‹"""
        model_data = {
            "weights": self.weights,
            "feature_stats": self.feature_stats,
            "training_accuracy": self.training_accuracy,
            "is_trained": self.is_trained,
        }

        with open(filename, "wb") as f:
            pickle.dump(model_data, f)

        print(f"âœ… æ¨¡å‹å·²ä¿å­˜ï¼š{filename}")

    def load_model(self, filename: str = "ml_model.pkl"):
        """åŠ è½½æ¨¡å‹"""
        try:
            with open(filename, "rb") as f:
                model_data = pickle.load(f)

            self.weights = model_data["weights"]
            self.feature_stats = model_data["feature_stats"]
            self.training_accuracy = model_data["training_accuracy"]
            self.is_trained = model_data["is_trained"]

            print(f"âœ… æ¨¡å‹å·²åŠ è½½ï¼š{filename}")
            return True
        except FileNotFoundError:
            print(f"âš ï¸ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼š{filename}")
            return False


class MLPredictionService:
    """ML é¢„æµ‹æœåŠ¡"""

    def __init__(self):
        self.model = SimpleMLModel()
        self.data_builder = HistoricalDataBuilder()

    def train_model(self) -> Dict:
        """è®­ç»ƒæ¨¡å‹"""
        training_data = self.data_builder.get_training_data()
        result = self.model.train(training_data)

        # ä¿å­˜æ¨¡å‹
        if result.get("status") == "success":
            self.model.save_model()

        return result

    def predict_for_opportunity(self, data: TrainingData) -> Dict:
        """ä¸ºæŸä¸ªæœºä¼šé¢„æµ‹"""
        if not self.model.is_trained:
            self.train_model()

        prediction = self.model.predict_return(data)

        return {
            "ticker": data.ticker,
            "date": datetime.now().isoformat(),
            "input": {
                "crowding_score": data.crowding_score,
                "catalyst_quality": data.catalyst_quality,
                "momentum_5d": data.momentum_5d,
                "volatility": data.volatility,
                "market_sentiment": data.market_sentiment,
            },
            "prediction": prediction,
            "recommendation": self._generate_recommendation(prediction),
        }

    def _generate_recommendation(self, prediction: Dict) -> str:
        """ç”Ÿæˆæ¨è"""
        prob = prediction["probability"]

        if prob >= 0.75:
            return "STRONG BUY - é«˜æ¦‚ç‡æœºä¼š"
        elif prob >= 0.65:
            return "BUY - å€¼å¾—å‚ä¸"
        elif prob >= 0.50:
            return "HOLD - ç­‰å¾…æ›´å¥½æœºä¼š"
        else:
            return "AVOID - é£é™©å¤§äºæ”¶ç›Š"

    def get_model_info(self) -> Dict:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        return {
            "is_trained": self.model.is_trained,
            "training_accuracy": self.model.training_accuracy,
            "weights": self.model.weights,
            "training_samples": len(self.data_builder.get_training_data()),
        }


# ==================== è„šæœ¬ç¤ºä¾‹ ====================
if __name__ == "__main__":
    print("ğŸ¤– Alpha Hive ML é¢„æµ‹ç³»ç»Ÿ")
    print("=" * 60)

    # åˆ›å»ºæœåŠ¡
    service = MLPredictionService()

    # è®­ç»ƒæ¨¡å‹
    print("\nğŸ“š ç¬¬ 1 æ­¥ï¼šè®­ç»ƒæ¨¡å‹")
    print("-" * 60)
    result = service.train_model()
    print(json.dumps(result, indent=2))

    # ä¸ºæ–°çš„æœºä¼šåšé¢„æµ‹
    print("\n\nğŸ”® ç¬¬ 2 æ­¥ï¼šé¢„æµ‹æ–°æœºä¼š")
    print("-" * 60)

    # æ¨¡æ‹Ÿä¸€ä¸ªæ–°çš„äº¤æ˜“æœºä¼š
    new_opportunity = TrainingData(
        ticker="NVDA",
        date="2026-02-23",
        crowding_score=63.5,
        catalyst_quality="A",
        momentum_5d=6.8,
        volatility=4.8,
        market_sentiment=45,
        actual_return_3d=0,  # æœªæ¥æ•°æ®
        actual_return_7d=0,
        actual_return_30d=0,
        win_3d=False,
        win_7d=False,
        win_30d=False,
    )

    prediction = service.predict_for_opportunity(new_opportunity)
    print(json.dumps(prediction, indent=2, default=str))

    # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
    print("\n\nğŸ“Š ç¬¬ 3 æ­¥ï¼šæ¨¡å‹æ€§èƒ½")
    print("-" * 60)
    info = service.get_model_info()
    print(f"è®­ç»ƒçŠ¶æ€ï¼š{'å·²è®­ç»ƒ' if info['is_trained'] else 'æœªè®­ç»ƒ'}")
    print(f"è®­ç»ƒå‡†ç¡®ç‡ï¼š{info['training_accuracy']:.1f}%")
    print(f"è®­ç»ƒæ ·æœ¬æ•°ï¼š{info['training_samples']}")
    print(f"\nç‰¹å¾æƒé‡ï¼š")
    for feature, weight in info['weights'].items():
        print(f"  â€¢ {feature}: {weight:.1%}")

    print("\n" + "=" * 60)
    print("âœ… ML é¢„æµ‹æ¼”ç¤ºå®Œæˆï¼")
    print("=" * 60)
