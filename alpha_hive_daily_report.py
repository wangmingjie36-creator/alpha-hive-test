#!/usr/bin/env python3
"""
ğŸ Alpha Hive æ—¥æŠ¥ç”Ÿæˆå™¨ - é›†æˆæœŸæƒåˆ†æçš„å®Œæ•´ç‰ˆæœ¬
æ¯æ—¥è‡ªåŠ¨æ‰«æ watchlist å¹¶ç”Ÿæˆç»“æ„åŒ–æŠ•èµ„ç®€æŠ¥ + X çº¿ç¨‹ç‰ˆæœ¬
"""

import json
import os
import argparse
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple
from dataclasses import dataclass
from concurrent.futures import ThreadPoolExecutor
from threading import Lock

# å¯¼å…¥ç°æœ‰æ¨¡å—
from config import WATCHLIST, EVALUATION_WEIGHTS
from hive_logger import get_logger, PATHS, set_correlation_id

_log = get_logger("daily_report")

# Week 4: æŒ‡æ ‡æ”¶é›†å™¨
try:
    from metrics_collector import MetricsCollector
except ImportError:
    MetricsCollector = None
from generate_ml_report import MLEnhancedReportGenerator
from pheromone_board import PheromoneBoard
from swarm_agents import (
    ScoutBeeNova, OracleBeeEcho, BuzzBeeWhisper,
    ChronosBeeHorizon, RivalBeeVanguard, GuardBeeSentinel,
    BearBeeContrarian,
    QueenDistiller, prefetch_shared_data, inject_prefetched
)
from concurrent.futures import as_completed
from agent_toolbox import AgentHelper

# Phase 2: Import memory store
try:
    from memory_store import MemoryStore
except ImportError:
    MemoryStore = None

# Phase 3 P2: Import Calendar integrator
try:
    from calendar_integrator import CalendarIntegrator
except ImportError:
    CalendarIntegrator = None

# Phase 3 P4: Import Code Execution Agent
try:
    from code_executor_agent import CodeExecutorAgent
    from config import CODE_EXECUTION_CONFIG
except ImportError:
    CodeExecutorAgent = None
    CODE_EXECUTION_CONFIG = {"enabled": False}

# Phase 3 P5: Import CrewAI å¤š Agent æ¡†æ¶
try:
    from crewai_adapter import AlphaHiveCrew
    from config import CREWAI_CONFIG
except (ImportError, TypeError) as e:
    AlphaHiveCrew = None
    CREWAI_CONFIG = {"enabled": False}
    _log.info("CrewAI æ¨¡å—å¯¼å…¥å¤±è´¥: %s (é™çº§åˆ°åŸå§‹èœ‚ç¾¤)", type(e).__name__)

# Phase 3 P6: Import Slack æŠ¥å‘Šé€šçŸ¥å™¨ï¼ˆæ›¿ä»£ Gmailï¼‰
try:
    from slack_report_notifier import SlackReportNotifier
except ImportError:
    SlackReportNotifier = None

# è´¢æŠ¥è‡ªåŠ¨ç›‘æ§å™¨
try:
    from earnings_watcher import EarningsWatcher
except ImportError:
    EarningsWatcher = None

# Phase 3 å†…å­˜ä¼˜åŒ–: å‘é‡è®°å¿†å±‚ï¼ˆChroma é•¿æœŸè®°å¿†ï¼‰
try:
    from vector_memory import VectorMemory
    from config import VECTOR_MEMORY_CONFIG
except ImportError:
    VectorMemory = None
    VECTOR_MEMORY_CONFIG = {"enabled": False}

# Phase 6: å›æµ‹åé¦ˆå¾ªç¯
try:
    from backtester import Backtester, run_full_backtest
except ImportError:
    Backtester = None
    run_full_backtest = None


# å…è´£å£°æ˜å¸¸é‡ï¼ˆå»é‡ï¼Œå…¨å±€å¼•ç”¨ï¼‰
DISCLAIMER_FULL = (
    "æœ¬æŠ¥å‘Šä¸ºèœ‚ç¾¤ AI åˆ†æï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ï¼Œä¸æ›¿ä»£æŒç‰ŒæŠ•é¡¾ã€‚"
    "é¢„æµ‹å­˜åœ¨è¯¯å·®ï¼Œæ‰€æœ‰äº¤æ˜“å†³ç­–éœ€è‡ªè¡Œåˆ¤æ–­å’Œé£æ§ã€‚"
)
DISCLAIMER_SHORT = "éæŠ•èµ„å»ºè®®ï¼Œä»…æ•°æ®åˆ†æä¸æƒ…æ™¯æ¨æ¼”ã€‚"


@dataclass
class OpportunityItem:
    """æœºä¼šé¡¹ç›®ç»“æ„"""
    ticker: str
    direction: str  # "çœ‹å¤š" / "çœ‹ç©º" / "ä¸­æ€§"
    signal_score: float  # 0-10
    catalyst_score: float  # 0-10
    sentiment_score: float  # 0-10
    odds_score: float  # 0-10
    risk_score: float  # 0-10
    options_score: float  # 0-10 (æ–°å¢)
    opportunity_score: float  # 0-10 (ç»¼åˆ)
    confidence: float  # 0-100%
    key_catalysts: List[str]
    options_signal: str  # æœŸæƒä¿¡å·æ‘˜è¦
    risks: List[str]
    thesis_break: str  # å¤±æ•ˆæ¡ä»¶


class AlphaHiveDailyReporter:
    """Alpha Hive æ—¥æŠ¥ç”Ÿæˆå¼•æ“"""

    def __init__(self):
        self.report_dir = PATHS.home
        self.timestamp = datetime.now()
        self.date_str = self.timestamp.strftime("%Y-%m-%d")

        # åˆå§‹åŒ–æŠ¥å‘Šç”Ÿæˆå™¨
        self.ml_generator = MLEnhancedReportGenerator()

        # åˆå§‹åŒ– Agent å·¥å…·é›†ï¼ˆæ–°å¢ï¼‰
        self.agent_helper = AgentHelper()

        # Phase 2: åˆå§‹åŒ–æŒä¹…åŒ–è®°å¿†å­˜å‚¨
        self.memory_store = None
        self._session_id = None
        if MemoryStore:
            try:
                self.memory_store = MemoryStore()
                self._session_id = self.memory_store.generate_session_id(run_mode="daily_scan")
            except (OSError, ValueError, RuntimeError) as e:
                _log.warning("MemoryStore åˆå§‹åŒ–å¤±è´¥ï¼Œç»§ç»­è¿è¡Œ: %s", e)

        # ç»“æœå­˜å‚¨
        self.opportunities: List[OpportunityItem] = []
        self.observations: List[Dict] = []
        self.risks: List[Dict] = []

        # çº¿ç¨‹å®‰å…¨é”ï¼ˆç”¨äºå¹¶è¡Œæ‰§è¡Œæ—¶ä¿æŠ¤å…±äº«æ•°æ®ï¼‰
        self._results_lock = Lock()

        # Phase 3 P2: åˆå§‹åŒ– Google Calendar é›†æˆï¼ˆå¤±è´¥æ—¶é™çº§ï¼‰
        self.calendar = None
        if CalendarIntegrator:
            try:
                self.calendar = CalendarIntegrator()
            except (OSError, ValueError, RuntimeError) as e:
                _log.warning("Calendar åˆå§‹åŒ–å¤±è´¥: %s", e)

        # Phase 3 P4: åˆå§‹åŒ–ä»£ç æ‰§è¡Œ Agentï¼ˆå¤±è´¥æ—¶é™çº§ï¼‰
        self.code_executor_agent = None
        if CodeExecutorAgent and CODE_EXECUTION_CONFIG.get("enabled"):
            try:
                self.code_executor_agent = CodeExecutorAgent(board=None)
                # board åœ¨ run_swarm_scan æ—¶æ³¨å…¥
            except (OSError, ValueError, RuntimeError, TypeError) as e:
                _log.warning("CodeExecutorAgent åˆå§‹åŒ–å¤±è´¥: %s", e)

        # Phase 3 å†…å­˜ä¼˜åŒ–: åˆå§‹åŒ–å‘é‡è®°å¿†å±‚ï¼ˆChroma é•¿æœŸè®°å¿†ï¼‰
        self.vector_memory = None
        if VectorMemory and VECTOR_MEMORY_CONFIG.get("enabled"):
            try:
                self.vector_memory = VectorMemory(
                    db_path=VECTOR_MEMORY_CONFIG.get("db_path"),
                    retention_days=VECTOR_MEMORY_CONFIG.get("retention_days", 90)
                )
                if self.vector_memory.enabled:
                    if VECTOR_MEMORY_CONFIG.get("cleanup_on_startup"):
                        self.vector_memory.cleanup()
            except (ImportError, OSError, ValueError, RuntimeError) as e:
                _log.warning("å‘é‡è®°å¿†åˆå§‹åŒ–å¤±è´¥: %s", e)

        # Week 4: æŒ‡æ ‡æ”¶é›†å™¨
        self.metrics = None
        if MetricsCollector:
            try:
                self.metrics = MetricsCollector()
            except (OSError, ValueError, RuntimeError) as e:
                _log.warning("MetricsCollector åˆå§‹åŒ–å¤±è´¥: %s", e)

        # Phase 2: å…±äº«çº¿ç¨‹æ± ï¼ˆæ›¿ä»£æ‰€æœ‰ daemon çº¿ç¨‹ï¼Œé€€å‡ºæ—¶ç­‰å¾…å®Œæˆï¼‰
        import atexit
        self._bg_executor = ThreadPoolExecutor(max_workers=3, thread_name_prefix="hive_bg")
        self._bg_futures = []
        atexit.register(self._shutdown_bg)

        # è´¢æŠ¥è‡ªåŠ¨ç›‘æ§å™¨
        self.earnings_watcher = None
        if EarningsWatcher:
            try:
                self.earnings_watcher = EarningsWatcher()
            except (OSError, ValueError, RuntimeError) as e:
                _log.warning("EarningsWatcher åˆå§‹åŒ–å¤±è´¥: %s", e)

        # Phase 3 P6: åˆå§‹åŒ– Slack æŠ¥å‘Šé€šçŸ¥å™¨ï¼ˆæ›¿ä»£ Gmailï¼‰
        self.slack_notifier = None
        if SlackReportNotifier:
            try:
                self.slack_notifier = SlackReportNotifier()
            except (OSError, ValueError, RuntimeError, ConnectionError) as e:
                _log.warning("Slack é€šçŸ¥å™¨åˆå§‹åŒ–å¤±è´¥: %s", e)

    def _shutdown_bg(self) -> None:
        """atexit å¤„ç†å™¨ï¼šç­‰å¾…åå°ä»»åŠ¡å®Œæˆ"""
        from concurrent.futures import TimeoutError as FuturesTimeout, CancelledError
        for f in self._bg_futures:
            try:
                f.result(timeout=10)
            except (FuturesTimeout, CancelledError, OSError, RuntimeError) as e:
                _log.debug("Background task cleanup: %s", e)
        self._bg_executor.shutdown(wait=True)

    def _submit_bg(self, fn, *args) -> None:
        """æäº¤åå°ä»»åŠ¡åˆ°å…±äº«çº¿ç¨‹æ± ï¼ˆæ›¿ä»£ daemon çº¿ç¨‹ï¼‰"""
        future = self._bg_executor.submit(fn, *args)
        self._bg_futures.append(future)
        # æ¸…ç†å·²å®Œæˆçš„ futuresï¼ˆé˜²æ­¢å†…å­˜æ³„æ¼ï¼‰
        self._bg_futures = [f for f in self._bg_futures if not f.done()]

    def _analyze_ticker_safe(self, ticker: str, index: int, total: int) -> Tuple[str, OpportunityItem, str]:
        """
        åˆ†æå•ä¸ªæ ‡çš„ï¼ˆçº¿ç¨‹å®‰å…¨ï¼Œå¯åœ¨å¹¶è¡Œä¸Šä¸‹æ–‡ä¸­è°ƒç”¨ï¼‰

        Args:
            ticker: è‚¡ç¥¨ä»£ç 
            index: å½“å‰ç´¢å¼•ï¼ˆç”¨äºæ˜¾ç¤ºè¿›åº¦ï¼‰
            total: æ€»æ•°ï¼ˆç”¨äºæ˜¾ç¤ºè¿›åº¦ï¼‰

        Returns:
            (ticker, opportunity_item_or_none, error_message_or_none)
        """
        try:
            # æ„å»ºæœ€å°åŒ–çš„å®æ—¶æ•°æ®ç»“æ„
            realtime_metrics = {
                "ticker": ticker,
                "sources": {
                    "yahoo_finance": {
                        "current_price": 100.0,
                        "change_pct": 2.5
                    }
                }
            }

            # ç”Ÿæˆ ML å¢å¼ºæŠ¥å‘Š
            ml_report = self.ml_generator.generate_ml_enhanced_report(
                ticker, realtime_metrics
            )

            # è§£æä¸º OpportunityItem
            opportunity = self._parse_ml_report_to_opportunity(ticker, ml_report)

            # çº¿ç¨‹å®‰å…¨åœ°æ·»åŠ åˆ°ç»“æœåˆ—è¡¨
            with self._results_lock:
                self.opportunities.append(opportunity)

            return ticker, opportunity, None

        except (ValueError, KeyError, TypeError, AttributeError, OSError) as e:
            _log.error("Ticker analysis failed for %s: %s", ticker, e, exc_info=True)
            error_msg = str(e)
            # çº¿ç¨‹å®‰å…¨åœ°æ·»åŠ è§‚å¯Ÿé¡¹
            with self._results_lock:
                self.observations.append({
                    "ticker": ticker,
                    "status": "error",
                    "error": error_msg
                })
            return ticker, None, error_msg

    def run_daily_scan(self, focus_tickers: List[str] = None) -> Dict:
        """
        æ‰§è¡Œæ¯æ—¥æ‰«æï¼ˆå¹¶è¡Œç‰ˆæœ¬ï¼‰

        Args:
            focus_tickers: é‡ç‚¹å…³æ³¨æ ‡çš„ï¼ˆå¦‚ä¸ºNoneåˆ™æ‰«æå…¨éƒ¨watchlistï¼‰

        Returns:
            å®Œæ•´çš„æ—¥æŠ¥æ•°æ®ç»“æ„
        """
        _log.info("Alpha Hive æ—¥æŠ¥ %s", self.date_str)

        targets = focus_tickers or list(WATCHLIST.keys())[:10]
        _log.info("æ ‡çš„ï¼š%s", " ".join(targets))

        start_parallel = time.time()

        with ThreadPoolExecutor(max_workers=len(targets)) as executor:
            futures = [
                executor.submit(self._analyze_ticker_safe, ticker, i + 1, len(targets))
                for i, ticker in enumerate(targets)
            ]

            for i, future in enumerate(futures, 1):
                ticker, opportunity, error = future.result()
                if error:
                    _log.warning("[%d/%d] %s åˆ†æå¤±è´¥: %s", i, len(targets), ticker, error[:60])
                else:
                    _log.info("[%d/%d] %s: %.1f/10", i, len(targets), ticker, opportunity.opportunity_score)

        elapsed_parallel = time.time() - start_parallel
        _log.info("åˆ†æè€—æ—¶ï¼š%.1fs", elapsed_parallel)

        # æ’åºæœºä¼š
        self.opportunities.sort(key=lambda x: x.opportunity_score, reverse=True)

        # æ„å»ºæŠ¥å‘Š
        report = self._build_report()

        # Phase 2: å¼‚æ­¥ä¿å­˜ä¼šè¯ï¼ˆä½¿ç”¨å…±äº«çº¿ç¨‹æ± ï¼Œé€€å‡ºæ—¶ç­‰å¾…å®Œæˆï¼‰
        if self.memory_store and self._session_id:
            self._submit_bg(
                self.memory_store.save_session,
                self._session_id, self.date_str, "daily_scan",
                targets, {}, [], elapsed_parallel
            )

        return report

    def run_swarm_scan(self, focus_tickers: List[str] = None, progress_callback=None) -> Dict:
        """
        çœŸæ­£çš„èœ‚ç¾¤åä½œæ‰«æ - 7 ä¸ªè‡ªæ²»å·¥èœ‚å¹¶è¡Œè¿è¡Œï¼ˆ6 æ ¸å¿ƒ + BearBeeContrarianï¼‰ï¼Œå®æ—¶é€šè¿‡ä¿¡æ¯ç´ æ¿äº¤æ¢å‘ç°

        Args:
            focus_tickers: é‡ç‚¹å…³æ³¨æ ‡çš„ï¼ˆå¦‚ä¸ºNoneåˆ™æ‰«æå…¨éƒ¨watchlistï¼‰

        Returns:
            å®Œæ•´çš„èœ‚ç¾¤åˆ†ææŠ¥å‘Š
        """
        # Week 4: è®¾ç½® correlation_id è¿½è¸ªæœ¬æ¬¡æ‰«æ
        set_correlation_id(self._session_id or f"swarm_{self.date_str}")
        _log.info("èœ‚ç¾¤åä½œå¯åŠ¨ %s", self.date_str)

        targets = focus_tickers or list(WATCHLIST.keys())[:10]
        _log.info("æ ‡çš„ï¼š%s", " ".join(targets))

        start_time = time.time()

        # åˆ›å»ºå…±äº«çš„ä¿¡æ¯ç´ æ¿
        board = PheromoneBoard(memory_store=self.memory_store, session_id=self._session_id)

        # å®ä¾‹åŒ– Agentï¼šç¬¬ä¸€é˜¶æ®µ 6 ä¸ªæ ¸å¿ƒ Agentï¼ˆå¯é€‰+CodeExecutorï¼‰ï¼Œç¬¬äºŒé˜¶æ®µ BearBeeContrarianï¼ˆè¯»å–ä¿¡æ¯ç´ æ¿ååˆ†æï¼‰
        retriever = self.vector_memory if (self.vector_memory and self.vector_memory.enabled) else None
        phase1_agents = [
            ScoutBeeNova(board, retriever=retriever),
            OracleBeeEcho(board, retriever=retriever),
            BuzzBeeWhisper(board, retriever=retriever),
            ChronosBeeHorizon(board, retriever=retriever),
            RivalBeeVanguard(board, retriever=retriever),
            GuardBeeSentinel(board, retriever=retriever),
        ]
        # çœ‹ç©ºå¯¹å†²èœ‚ï¼šäºŒé˜¶æ®µæ‰§è¡Œï¼ˆç­‰å…¶ä»– Agent å†™å…¥ä¿¡æ¯ç´ æ¿åå†åˆ†æï¼‰
        bear_agent = BearBeeContrarian(board, retriever=retriever)

        # Phase 3 P4: åŠ¨æ€æ³¨å…¥ CodeExecutorAgent
        if self.code_executor_agent and CODE_EXECUTION_CONFIG.get("add_to_swarm"):
            self.code_executor_agent.board = board
            phase1_agents.append(self.code_executor_agent)

        # Phase 6: è‡ªé€‚åº”æƒé‡
        adapted_w = Backtester.load_adapted_weights() if Backtester else None
        queen = QueenDistiller(board, adapted_weights=adapted_w)

        all_agents = phase1_agents + [bear_agent]
        _log.info("%d Agentï¼ˆå«äºŒé˜¶æ®µçœ‹ç©ºèœ‚ï¼‰| é¢„å–æ•°æ®ä¸­...", len(all_agents))

        # âš¡ ä¼˜åŒ– #1+#2: æ‰¹é‡é¢„å– yfinance + VectorMemoryï¼ˆæ¯ ticker ä»… 1 æ¬¡ï¼‰
        prefetched = prefetch_shared_data(targets, retriever)
        inject_prefetched(all_agents, prefetched)
        prefetch_elapsed = time.time() - start_time
        _log.info("é¢„å–å®Œæˆ (%.1fs) | å¼€å§‹å¹¶è¡Œåˆ†æ", prefetch_elapsed)

        # âš¡ ä¼˜åŒ– #3: å•å±‚çº¿ç¨‹æ± ï¼ŒæŒ‰ ticker ä¸²è¡Œã€Agent å¹¶è¡Œ
        swarm_results = {}

        # Phase 2: å´©æºƒæ¢å¤ checkpoint
        checkpoint_file = self.report_dir / f".checkpoint_{self._session_id or 'default'}.json"
        completed_tickers = set()
        if checkpoint_file.exists():
            try:
                with open(checkpoint_file, "r") as f:
                    ckpt = json.load(f)
                    swarm_results = ckpt.get("results", {})
                    completed_tickers = set(swarm_results.keys())
                    if completed_tickers:
                        _log.info("æ¢å¤ checkpointï¼š%d æ ‡çš„å·²å®Œæˆ", len(completed_tickers))
            except (json.JSONDecodeError, KeyError, OSError) as e:
                _log.warning("Checkpoint æ¢å¤å¤±è´¥ï¼Œé‡æ–°å¼€å§‹: %s", e)

        for idx, ticker in enumerate(targets, 1):
            if ticker in completed_tickers:
                res = "âœ…" if swarm_results[ticker]["resonance"]["resonance_detected"] else "â€”"
                _log.info("[%d/%d] %s: %.1f/10 (å·²ç¼“å­˜) %s", idx, len(targets), ticker, swarm_results[ticker]['final_score'], res)
                continue

            # ç¬¬ä¸€é˜¶æ®µï¼š6 ä¸ªæ ¸å¿ƒ Agent å¹¶è¡Œåˆ†æï¼ˆå«å¯é€‰ CodeExecutorAgentï¼‰
            with ThreadPoolExecutor(max_workers=len(phase1_agents)) as executor:
                futures = {executor.submit(agent.analyze, ticker): agent for agent in phase1_agents}
                agent_results = []
                for future in as_completed(futures):
                    try:
                        agent_results.append(future.result(timeout=60))
                    except (TimeoutError, ValueError, KeyError, TypeError, RuntimeError) as e:
                        _log.warning("Agent future failed: %s", e)
                        agent_results.append(None)

            # ç¬¬äºŒé˜¶æ®µï¼šBearBeeContrarian è¯»å–ä¿¡æ¯ç´ æ¿ååˆ†æï¼ˆæ­¤æ—¶å…¶ä»– Agent æ•°æ®å·²å¯ç”¨ï¼‰
            try:
                bear_result = bear_agent.analyze(ticker)
                agent_results.append(bear_result)
                _log.info("  ğŸ» çœ‹ç©ºèœ‚: %s %s (%.1fåˆ†, %dä¿¡å·)",
                          ticker, bear_result.get("direction", "?"),
                          bear_result.get("details", {}).get("bear_score", 0),
                          len(bear_result.get("details", {}).get("bearish_signals", [])))
            except (ValueError, KeyError, TypeError, AttributeError) as e:
                _log.warning("BearBeeContrarian failed for %s: %s", ticker, e)
                agent_results.append(None)

            distilled = queen.distill(ticker, agent_results)
            swarm_results[ticker] = distilled

            res = "âœ…" if distilled["resonance"]["resonance_detected"] else "â€”"
            _log.info("[%d/%d] %s: %.1f/10 %s %s", idx, len(targets), ticker, distilled['final_score'], distilled['direction'], res)

            # è¿›åº¦å›è°ƒï¼ˆä¾›æ¡Œé¢ App å®æ—¶åŠ¨ç”»ä½¿ç”¨ï¼‰
            if progress_callback:
                try:
                    progress_callback(idx, len(targets), ticker, distilled)
                except Exception as _cb_err:
                    _log.debug("Progress callback error: %s", _cb_err)

            # å†™å…¥ checkpointï¼ˆæ¯ä¸ª ticker å®Œæˆåï¼‰
            try:
                with open(checkpoint_file, "w") as f:
                    json.dump({"results": swarm_results, "targets": targets}, f, default=str)
            except (OSError, TypeError) as e:
                _log.warning("Checkpoint å†™å…¥å¤±è´¥: %s", e)

        # æ‰«æå®Œæˆï¼Œä¿å­˜èœ‚ç¾¤ç»“æœä¾› ML æŠ¥å‘ŠåŒæ­¥ä½¿ç”¨
        try:
            swarm_json = self.report_dir / f".swarm_results_{self.date_str}.json"
            with open(swarm_json, "w") as f:
                json.dump(swarm_results, f, default=str, ensure_ascii=False)
        except (OSError, TypeError) as e:
            _log.warning("Swarm results ä¿å­˜å¤±è´¥: %s", e)
        # æ¸…ç† checkpoint
        try:
            checkpoint_file.unlink(missing_ok=True)
        except OSError as e:
            _log.debug("Checkpoint æ¸…ç†å¤±è´¥: %s", e)

        elapsed = time.time() - start_time

        # LLM Token ä½¿ç”¨ç»Ÿè®¡
        try:
            import llm_service
            usage = llm_service.get_usage()
            if usage["call_count"] > 0:
                _log.info("èœ‚ç¾¤è€—æ—¶ï¼š%.1fs | LLM: %dè°ƒç”¨ $%.4f", elapsed, usage['call_count'], usage['total_cost_usd'])
            else:
                _log.info("èœ‚ç¾¤è€—æ—¶ï¼š%.1fs | è§„åˆ™å¼•æ“æ¨¡å¼", elapsed)
        except (ImportError, AttributeError, KeyError) as e:
            _log.info("èœ‚ç¾¤è€—æ—¶ï¼š%.1fs (LLM stats unavailable: %s)", elapsed, e)

        # Week 4: è®°å½•æ‰«ææŒ‡æ ‡ + SLO æ£€æŸ¥
        if self.metrics:
            try:
                scores = [d.get("final_score", 5.0) for d in swarm_results.values()]
                agent_errors = sum(
                    1 for d in swarm_results.values()
                    if d.get("supporting_agents", 0) == 0
                )
                resonance_n = sum(
                    1 for d in swarm_results.values()
                    if d.get("resonance", {}).get("resonance_detected")
                )
                avg_real = (
                    sum(d.get("data_real_pct", 0) for d in swarm_results.values()) / len(swarm_results)
                    if swarm_results else 0
                )
                llm_c, llm_cost = 0, 0.0
                try:
                    import llm_service as _ls
                    _u = _ls.get_usage()
                    llm_c, llm_cost = _u.get("call_count", 0), _u.get("total_cost_usd", 0.0)
                except (ImportError, AttributeError, KeyError):
                    pass

                self.metrics.record_scan(
                    ticker_count=len(swarm_results),
                    duration_seconds=elapsed,
                    agent_count=len(all_agents),
                    prefetch_seconds=prefetch_elapsed,
                    avg_score=sum(scores) / len(scores) if scores else 5.0,
                    max_score=max(scores) if scores else 5.0,
                    min_score=min(scores) if scores else 5.0,
                    agent_errors=agent_errors,
                    agent_total=len(swarm_results) * len(all_agents),
                    data_real_pct=avg_real,
                    resonance_count=resonance_n,
                    llm_calls=llm_c,
                    llm_cost_usd=llm_cost,
                    session_id=self._session_id or "",
                    scan_mode="swarm",
                )
                for ticker, data in swarm_results.items():
                    self.metrics.record_ticker(
                        ticker=ticker,
                        final_score=data.get("final_score", 5.0),
                        direction=data.get("direction", "neutral"),
                        supporting_agents=data.get("supporting_agents", 0),
                        data_real_pct=data.get("data_real_pct", 0),
                        resonance_detected=data.get("resonance", {}).get("resonance_detected", False),
                        session_id=self._session_id or "",
                    )

                # SLO æ£€æŸ¥
                violations = self.metrics.check_slo(days=1)
                if violations:
                    _log.warning("SLO è¿è§„ %d æ¡: %s",
                                 len(violations),
                                 "; ".join(v["details"] for v in violations))
            except (OSError, ValueError, KeyError, TypeError) as e:
                _log.warning("æŒ‡æ ‡æ”¶é›†å¼‚å¸¸: %s", e)

        # Phase 6: å›æµ‹åé¦ˆå¾ªç¯
        if Backtester:
            try:
                bt = Backtester()
                bt.save_predictions(swarm_results)
                bt.run_backtest()
                bt.adapt_weights(min_samples=5)
            except (OSError, ValueError, KeyError, TypeError) as e:
                _log.warning("å›æµ‹å¼‚å¸¸: %s", e)

        # Phase 6: Slack æ¨é€é«˜åˆ†æœºä¼š + å¼‚å¸¸ä¿¡å·
        if self.slack_notifier and self.slack_notifier.enabled:
            for ticker, data in swarm_results.items():
                score = data.get("final_score", 0)
                direction = data.get("direction", "neutral")
                dir_cn = {"bullish": "çœ‹å¤š", "bearish": "çœ‹ç©º", "neutral": "ä¸­æ€§"}.get(direction, direction)

                # é«˜åˆ†æœºä¼šæ¨é€ï¼ˆ>= 7.5ï¼‰
                if score >= 7.5:
                    self._submit_bg(
                        self.slack_notifier.send_opportunity_alert,
                        ticker, score, dir_cn,
                        data.get("discovery", "é«˜åˆ†æœºä¼š"),
                        [f"è¯„åˆ† {score:.1f}/10"]
                    )

                # å¼‚å¸¸ä¿¡å·æ¨é€ï¼šå¼ºçœ‹ç©º æˆ– å†…å¹•å¤§é¢äº¤æ˜“
                elif score <= 3.0:
                    self._submit_bg(
                        self.slack_notifier.send_risk_alert,
                        f"{ticker} ä½åˆ†é¢„è­¦",
                        f"èœ‚ç¾¤è¯„åˆ†ä»… {score:.1f}/10ï¼Œæ–¹å‘ {dir_cn}",
                        "HIGH"
                    )

        # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        report = self._build_swarm_report(swarm_results, board, agent_count=len(all_agents))

        # Phase 3 P2: ä¸ºé«˜åˆ†æœºä¼šæ·»åŠ æ—¥å†æé†’ï¼ˆåå°çº¿ç¨‹æ± ï¼Œé€€å‡ºæ—¶ç­‰å¾…å®Œæˆï¼‰
        if self.calendar and report.get('opportunities'):
            for opp in report['opportunities']:
                if opp.opportunity_score >= 7.5:
                    self._submit_bg(
                        self.calendar.add_opportunity_reminder,
                        opp.ticker, opp.opportunity_score, opp.direction,
                        f"{opp.key_catalysts[0] if opp.key_catalysts else 'é«˜åˆ†æœºä¼š'}"
                    )

        # Phase 2: å¼‚æ­¥ä¿å­˜ä¼šè¯ï¼ˆä½¿ç”¨å…±äº«çº¿ç¨‹æ± ï¼Œé€€å‡ºæ—¶ç­‰å¾…å®Œæˆï¼‰
        if self.memory_store and self._session_id:
            snapshot = board.compact_snapshot()  # åœ¨ä¸»çº¿ç¨‹å–å¿«ç…§ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
            self._submit_bg(
                self.memory_store.save_session,
                self._session_id, self.date_str, "swarm",
                targets, swarm_results, snapshot, elapsed
            )

        # Phase 3 å†…å­˜ä¼˜åŒ–: å°†é«˜ä»·å€¼å‘ç°å­˜å…¥å‘é‡è®°å¿†ï¼ˆé•¿æœŸè®°å¿†ï¼‰
        if self.vector_memory and self.vector_memory.enabled:
            stored = 0
            # 1. å­˜å‚¨ Queen çš„æœ€ç»ˆè¯„åˆ†
            for ticker, data in swarm_results.items():
                if data.get("final_score", 0) >= 5.0:
                    self.vector_memory.store(
                        ticker=ticker,
                        agent_id="QueenDistiller",
                        discovery=f"è¯„åˆ†{data['final_score']:.1f} {data['direction']} "
                                  f"æ”¯æŒ{data.get('supporting_agents', 0)}Agent",
                        direction=data["direction"],
                        score=data["final_score"],
                        source="swarm_scan",
                        session_id=self._session_id or ""
                    )
                    stored += 1
            # 2. å­˜å‚¨ä¿¡æ¯ç´ æ¿ä¸Šæ¯ä¸ª Agent çš„é«˜ä»·å€¼å‘ç°
            for entry in board.snapshot():
                if entry.get("self_score", 0) >= 6.0:
                    self.vector_memory.store(
                        ticker=entry.get("ticker", ""),
                        agent_id=entry.get("agent_id", ""),
                        discovery=entry.get("discovery", "")[:300],
                        direction=entry.get("direction", "neutral"),
                        score=entry.get("self_score", 5.0),
                        source=entry.get("source", ""),
                        session_id=self._session_id or ""
                    )
                    stored += 1
            if stored > 0:
                _log.info("å·²å­˜å…¥ %d æ¡é•¿æœŸè®°å¿† (Chroma)", stored)

        return report

    def run_crew_scan(self, focus_tickers: List[str] = None) -> Dict:
        """
        CrewAI æ¨¡å¼èœ‚ç¾¤æ‰«æ - ä½¿ç”¨ Process.hierarchical ä¸»-å­ Agent é€’å½’è°ƒåº¦
        è‹¥ crewai æœªå®‰è£…ï¼Œè‡ªåŠ¨é™çº§åˆ° run_swarm_scan()

        Args:
            focus_tickers: é‡ç‚¹å…³æ³¨æ ‡çš„ï¼ˆå¦‚ä¸ºNoneåˆ™æ‰«æå…¨éƒ¨watchlistï¼‰

        Returns:
            å®Œæ•´çš„èœ‚ç¾¤åˆ†ææŠ¥å‘Š
        """
        # æ£€æŸ¥ CrewAI æ˜¯å¦å¯ç”¨
        if not AlphaHiveCrew or not CREWAI_CONFIG.get("enabled"):
            _log.info("CrewAI æœªå®‰è£…æˆ–æœªå¯ç”¨ï¼Œé™çº§åˆ°æ ‡å‡†èœ‚ç¾¤æ¨¡å¼")
            return self.run_swarm_scan(focus_tickers)

        _log.info("CrewAI æ¨¡å¼ %s", self.date_str)

        targets = focus_tickers or list(WATCHLIST.keys())[:10]
        _log.info("æ ‡çš„ï¼š%s", " ".join(targets))

        # åˆ›å»ºå…±äº«çš„ä¿¡æ¯ç´ æ¿
        board = PheromoneBoard(memory_store=self.memory_store, session_id=self._session_id)

        # æ„å»º CrewAI Crew
        crew = AlphaHiveCrew(board=board, memory_store=self.memory_store)
        crew.build(targets)

        _log.info("CrewAI %d Agent", crew.get_agents_count())

        swarm_results = {}
        start_time = time.time()

        # ä½¿ç”¨ CrewAI åˆ†ææ¯ä¸ªæ ‡çš„
        for i, ticker in enumerate(targets, 1):
            _log.info("[%d/%d] CrewAI åˆ†æ %s", i, len(targets), ticker)

            try:
                result = crew.analyze(ticker)
                swarm_results[ticker] = result

                _log.info("  %s: %.1f/10 %s", ticker, result.get('final_score', 0), result.get('direction', 'neutral'))

            except (ValueError, KeyError, TypeError, RuntimeError, ConnectionError) as e:
                _log.warning("  %s CrewAI åˆ†æå¤±è´¥: %s", ticker, str(e)[:80])
                swarm_results[ticker] = {
                    "ticker": ticker,
                    "final_score": 0.0,
                    "direction": "neutral",
                    "discovery": f"CrewAI åˆ†æå¤±è´¥: {str(e)}",
                    "error": str(e)
                }

        elapsed = time.time() - start_time
        _log.info("CrewAI è€—æ—¶ï¼š%.1fs", elapsed)

        # è½¬æ¢ä¸ºæ ‡å‡†æŠ¥å‘Šæ ¼å¼ï¼ˆå…¼å®¹ run_swarm_scan è¾“å‡ºï¼‰
        # CrewAI æ¨¡å¼ï¼š6 æ ¸å¿ƒ BeeAgent + BearBeeContrarian = 7
        report = self._build_swarm_report(swarm_results, board, agent_count=7)

        # å¼‚æ­¥ä¿å­˜ä¼šè¯ï¼ˆä½¿ç”¨å…±äº«çº¿ç¨‹æ± ï¼Œé€€å‡ºæ—¶ç­‰å¾…å®Œæˆï¼‰
        if self.memory_store and self._session_id:
            snapshot = board.compact_snapshot()
            self._submit_bg(
                self.memory_store.save_session,
                self._session_id, self.date_str, "crew_scan",
                targets, swarm_results, snapshot, elapsed
            )

        return report

    def _build_swarm_report(self, swarm_results: Dict, board: PheromoneBoard,
                            agent_count: int = 7) -> Dict:
        """
        å°†èœ‚ç¾¤åˆ†æç»“æœè½¬æ¢ä¸ºæ ‡å‡†æŠ¥å‘Šæ ¼å¼

        Args:
            swarm_results: QueenDistiller çš„æ‰€æœ‰æ±‡æ€»ç»“æœ
            board: ä¿¡æ¯ç´ æ¿ï¼ˆç”¨äºæå–å…¨å±€ä¿¡æ¯ï¼‰
            agent_count: å®é™…è¿è¡Œçš„ Agent æ€»æ•°ï¼ˆPhase-1 + BearBeeContrarian + å¯é€‰ CodeExecutorï¼‰

        Returns:
            æ ‡å‡†æŠ¥å‘Šæ ¼å¼
        """
        # æ’åºç»“æœ
        sorted_results = sorted(
            swarm_results.items(),
            key=lambda x: x[1]["final_score"],
            reverse=True
        )

        # æ„å»º OpportunityItem åˆ—è¡¨ï¼ˆå…¼å®¹ç°æœ‰æŠ¥å‘Šæ ¼å¼ï¼‰
        opportunities = []
        for ticker, swarm_data in sorted_results:
            opp = OpportunityItem(
                ticker=ticker,
                direction="çœ‹å¤š" if swarm_data["direction"] == "bullish" else (
                    "çœ‹ç©º" if swarm_data["direction"] == "bearish" else "ä¸­æ€§"
                ),
                signal_score=swarm_data["final_score"],
                catalyst_score=swarm_data["final_score"] * 0.9,
                sentiment_score=swarm_data["final_score"] * 0.85,
                odds_score=swarm_data["final_score"] * 0.8,
                risk_score=swarm_data["final_score"] * 0.95,
                options_score=swarm_data["final_score"] * 0.88,
                opportunity_score=swarm_data["final_score"],
                confidence=min(95, swarm_data["final_score"] * 10) if swarm_data["final_score"] >= 7.5 else 60,
                key_catalysts=["å¤š Agent å…±æŒ¯ä¿¡å·"] if swarm_data["resonance"]["resonance_detected"] else ["å¾…éªŒè¯"],
                options_signal=f"å…±æŒ¯ä¿¡å· ({swarm_data['resonance']['supporting_agents']} Agent)",
                risks=["å¤šå¤´æ‹¥æŒ¤"] if swarm_data["resonance"]["resonance_detected"] else [],
                thesis_break="ä¿¡å·åˆ†æ•£"
            )
            opportunities.append(opp)

        self.opportunities = opportunities

        # â”€â”€ P4: æŠ•èµ„ç»„åˆé›†ä¸­åº¦åˆ†æï¼ˆæ¿å—é‡å  + ç›¸å…³æ€§çŸ©é˜µï¼‰â”€â”€
        concentration = {}
        try:
            from portfolio_concentration import analyze_concentration
            from config import WATCHLIST
            concentration = analyze_concentration(swarm_results, WATCHLIST)
            _log.info("P4 é›†ä¸­åº¦åˆ†æï¼š%sï¼ˆé£é™©=%sï¼‰",
                      concentration.get("summary", ""), concentration.get("concentration_risk", ""))
        except (ImportError, ValueError, KeyError, TypeError, AttributeError) as e:
            _log.debug("P4 portfolio_concentration ä¸å¯ç”¨: %s", e)

        # â”€â”€ P5: å®è§‚ç¯å¢ƒå¿«ç…§ï¼ˆé™„åŠ åˆ°æŠ¥å‘Šå…ƒæ•°æ®ï¼‰â”€â”€
        macro_snapshot = {}
        try:
            from fred_macro import get_macro_context
            macro_snapshot = get_macro_context()
            _log.info("P5 å®è§‚ç¯å¢ƒï¼š%s", macro_snapshot.get("summary", ""))
        except (ImportError, ConnectionError, TimeoutError, ValueError, KeyError) as e:
            _log.debug("P5 fred_macro ä¸å¯ç”¨: %s", e)

        # â”€â”€ P3: è·å–å›æµ‹å‡†ç¡®ç‡ç»Ÿè®¡ï¼ˆé™„åŠ åˆ°æŠ¥å‘Šï¼‰â”€â”€
        backtest_stats = {}
        try:
            if Backtester:
                _bt = Backtester()
                backtest_stats = _bt.store.get_accuracy_stats("t7", days=30)
        except (OSError, ValueError, KeyError, TypeError) as e:
            _log.debug("Backtest stats unavailable: %s", e)

        # æ„å»ºæ ‡å‡†æŠ¥å‘Š
        report = {
            "date": self.date_str,
            "timestamp": self.timestamp.isoformat(),
            "system_status": "âœ… èœ‚ç¾¤åä½œå®Œæˆ",
            "phase_completed": "å®Œæ•´èœ‚ç¾¤æµç¨‹ (Swarm Mode)",
            "swarm_metadata": {
                "total_agents": agent_count,
                "tickers_analyzed": len(swarm_results),
                "resonances_detected": sum(1 for r in swarm_results.values() if r["resonance"]["resonance_detected"]),
                "pheromone_board_entries": board.get_entry_count()
            },
            "concentration_analysis": concentration,
            "macro_context": macro_snapshot,
            "backtest_stats": backtest_stats,
            "markdown_report": self._generate_swarm_markdown_report(swarm_results, concentration, macro_snapshot, backtest_stats, agent_count=agent_count),
            "twitter_threads": self._generate_swarm_twitter_threads(swarm_results),
            "opportunities": [
                {
                    "rank": i + 1,
                    "ticker": opp.ticker,
                    "direction": opp.direction,
                    "opp_score": round(opp.opportunity_score, 1),
                    "confidence": f"{opp.confidence:.0f}%",
                    "resonance": swarm_results[opp.ticker]["resonance"]["resonance_detected"],
                    "supporting_agents": swarm_results[opp.ticker]["supporting_agents"],
                    "thesis_break": opp.thesis_break
                }
                for i, opp in enumerate(self.opportunities[:5])
            ]
        }

        return report

    def _generate_swarm_markdown_report(self, swarm_results: Dict,
                                         concentration: Dict = None,
                                         macro_context: Dict = None,
                                         backtest_stats: Dict = None,
                                         agent_count: int = 7) -> str:
        """ç”Ÿæˆèœ‚ç¾¤æ¨¡å¼çš„ Markdown æŠ¥å‘Šï¼ˆ8 ç‰ˆå— + P4é›†ä¸­åº¦ + P5å®è§‚ + P3å›æµ‹ï¼‰"""

        md = []
        md.append(f"# ã€{self.date_str}ã€‘Alpha Hive èœ‚ç¾¤åä½œæ—¥æŠ¥")
        md.append("")
        md.append(f"**è‡ªåŠ¨ç”Ÿæˆäº**ï¼š{self.timestamp.strftime('%Y-%m-%d %H:%M:%S')}")
        md.append(f"**ç³»ç»Ÿæ¨¡å¼**ï¼šå®Œå…¨å»ä¸­å¿ƒåŒ–èœ‚ç¾¤åä½œ | {agent_count} ä¸ªè‡ªæ²»å·¥èœ‚ï¼ˆ6 æ ¸å¿ƒ + BearBeeContrarianï¼‰")
        md.append("")

        sorted_results = sorted(
            swarm_results.items(),
            key=lambda x: x[1]["final_score"],
            reverse=True
        )

        # ====== ç‰ˆå— 1ï¼šä»Šæ—¥æ‘˜è¦ ======
        resonances = sum(1 for r in swarm_results.values() if r["resonance"]["resonance_detected"])
        md.append("## 1) ä»Šæ—¥æ‘˜è¦")
        md.append("")
        md.append(f"- æ‰«ææ ‡çš„ï¼š{len(swarm_results)} ä¸ª | å…±æŒ¯ä¿¡å·ï¼š{resonances}/{len(swarm_results)}")
        for i, (ticker, data) in enumerate(sorted_results[:3], 1):
            res = "å…±æŒ¯" if data["resonance"]["resonance_detected"] else ""
            md.append(f"- **{ticker}** {data['direction'].upper()} {data['final_score']:.1f}/10 {res}")
        md.append("")

        # ====== ç‰ˆå— 2ï¼šä»Šæ—¥èªæ˜é’±åŠ¨å‘ï¼ˆScoutBeeNovaï¼‰ ======
        md.append("## 2) ä»Šæ—¥èªæ˜é’±åŠ¨å‘")
        md.append("")
        for ticker, data in sorted_results:
            agent = data.get("agent_details", {}).get("ScoutBeeNova", {})
            discovery = agent.get("discovery", "")
            details = agent.get("details", {})
            insider = details.get("insider", {})
            md.append(f"### {ticker}")
            if discovery:
                md.append(f"- {discovery}")
            if insider:
                sentiment = insider.get("sentiment", "unknown")
                bought = insider.get("dollar_bought", 0)
                sold = insider.get("dollar_sold", 0)
                filings = insider.get("filings", 0)
                md.append(f"- å†…å¹•äº¤æ˜“æƒ…ç»ªï¼š**{sentiment}** | ç”³æŠ¥æ•°ï¼š{filings}")
                if bought > 0:
                    md.append(f"- å†…å¹•ä¹°å…¥é‡‘é¢ï¼š${bought:,.0f}")
                if sold > 0:
                    md.append(f"- å†…å¹•å–å‡ºé‡‘é¢ï¼š${sold:,.0f}")
                notable = insider.get("notable_trades", [])
                for t in notable[:2]:
                    if isinstance(t, dict):
                        md.append(f"  - {t.get('insider', '?')}ï¼š{t.get('code_desc', '?')} {t.get('shares', 0):,.0f} è‚¡")
            crowding = details.get("crowding_score", "")
            if crowding:
                md.append(f"- æ‹¥æŒ¤åº¦ï¼š{crowding:.0f}/100")
            md.append("")

        # ====== ç‰ˆå— 3ï¼šå¸‚åœºéšå«é¢„æœŸï¼ˆOracleBeeEchoï¼‰ ======
        md.append("## 3) å¸‚åœºéšå«é¢„æœŸ")
        md.append("")
        for ticker, data in sorted_results:
            agent = data.get("agent_details", {}).get("OracleBeeEcho", {})
            discovery = agent.get("discovery", "")
            details = agent.get("details", {})
            md.append(f"### {ticker}")
            if discovery:
                md.append(f"- {discovery}")
            if isinstance(details, dict) and details:
                iv = details.get("iv_rank")
                pc = details.get("put_call_ratio")
                gamma = details.get("gamma_exposure")
                if iv is not None:
                    md.append(f"- IV Rankï¼š{iv}")
                if pc is not None:
                    pc_val = pc if isinstance(pc, (int, float)) else pc
                    md.append(f"- Put/Call Ratioï¼š{pc_val}")
                if gamma is not None:
                    md.append(f"- Gamma Exposureï¼š{gamma}")
                # å¼‚å¸¸æ´»åŠ¨
                unusual = details.get("unusual_activity", [])
                if unusual:
                    md.append(f"- å¼‚å¸¸æ´»åŠ¨ï¼š{len(unusual)} ä¸ªä¿¡å·")
                    for u in unusual[:3]:
                        if isinstance(u, dict):
                            utype = u.get("type", "unknown").replace("_", " ")
                            strike = u.get("strike", "")
                            vol = u.get("volume", 0)
                            bull = "çœ‹æ¶¨" if u.get("bullish") else "çœ‹è·Œ"
                            md.append(f"  - {bull} {utype} ${strike} ({vol:,.0f}æ‰‹)")
                        elif isinstance(u, str):
                            md.append(f"  - {u}")
            md.append("")

        # ====== ç‰ˆå— 4ï¼šX æƒ…ç»ªæ±‡æ€»ï¼ˆBuzzBeeWhisperï¼‰ ======
        md.append("## 4) X æƒ…ç»ªæ±‡æ€»")
        md.append("")
        for ticker, data in sorted_results:
            agent = data.get("agent_details", {}).get("BuzzBeeWhisper", {})
            discovery = agent.get("discovery", "")
            details = agent.get("details", {})
            md.append(f"### {ticker}")
            if discovery:
                md.append(f"- {discovery}")
            if isinstance(details, dict) and details:
                sent_pct = details.get("sentiment_pct")
                mom = details.get("momentum_5d")
                vol = details.get("volume_ratio")
                if sent_pct is not None:
                    md.append(f"- çœ‹å¤šæƒ…ç»ªï¼š{sent_pct}%")
                if mom is not None:
                    md.append(f"- 5 æ—¥åŠ¨é‡ï¼š{mom:+.1f}%")
                if vol is not None:
                    md.append(f"- é‡æ¯”ï¼š{vol:.1f}x")
                reddit = details.get("reddit_mentions") or details.get("reddit_rank")
                if reddit:
                    md.append(f"- Reddit çƒ­åº¦ï¼š{reddit}")
            md.append("")

        # ====== ç‰ˆå— 5ï¼šè´¢æŠ¥/äº‹ä»¶å‚¬åŒ–å‰‚ï¼ˆChronosBeeHorizonï¼‰ ======
        md.append("## 5) è´¢æŠ¥/äº‹ä»¶å‚¬åŒ–å‰‚")
        md.append("")
        for ticker, data in sorted_results:
            agent = data.get("agent_details", {}).get("ChronosBeeHorizon", {})
            discovery = agent.get("discovery", "")
            details = agent.get("details", {})
            md.append(f"### {ticker}")
            if discovery:
                md.append(f"- {discovery}")
            if isinstance(details, dict) and details:
                earnings = details.get("next_earnings") or details.get("earnings_date")
                if earnings:
                    md.append(f"- ä¸‹æ¬¡è´¢æŠ¥ï¼š{earnings}")
                events = details.get("upcoming_events") or details.get("catalysts", [])
                if isinstance(events, list):
                    for ev in events[:3]:
                        if isinstance(ev, dict):
                            md.append(f"  - {ev.get('date', '?')}ï¼š{ev.get('event', ev.get('description', '?'))}")
                        elif isinstance(ev, str):
                            md.append(f"  - {ev}")
                past = details.get("recent_events", [])
                if isinstance(past, list):
                    for ev in past[:2]:
                        if isinstance(ev, dict):
                            md.append(f"  - [å·²å‘ç”Ÿ] {ev.get('description', ev)}")
            md.append("")

        # ====== ç‰ˆå— 6ï¼šç«äº‰æ ¼å±€åˆ†æï¼ˆRivalBeeVanguardï¼‰ ======
        md.append("## 6) ç«äº‰æ ¼å±€åˆ†æ")
        md.append("")
        for ticker, data in sorted_results:
            agent = data.get("agent_details", {}).get("RivalBeeVanguard", {})
            discovery = agent.get("discovery", "")
            details = agent.get("details", {})
            md.append(f"### {ticker}")
            if discovery:
                md.append(f"- {discovery}")
            if isinstance(details, dict) and details:
                ml_pred = details.get("ml_prediction") or details.get("prediction")
                if isinstance(ml_pred, dict):
                    md.append(f"- ML é¢„æµ‹æ–¹å‘ï¼š{ml_pred.get('direction', '?')}")
                    md.append(f"- ML ç½®ä¿¡åº¦ï¼š{ml_pred.get('confidence', '?')}")
                peers = details.get("peer_comparison") or details.get("peers", [])
                if isinstance(peers, list) and peers:
                    md.append(f"- åŒä¸šå¯¹æ ‡ï¼š{', '.join(str(p) for p in peers[:5])}")
            md.append("")

        # ====== ç‰ˆå— 6.5ï¼šçœ‹ç©ºå¯¹å†²è§‚ç‚¹ï¼ˆBearBeeContrarianï¼‰ ======
        md.append("## 6.5) çœ‹ç©ºå¯¹å†²è§‚ç‚¹")
        md.append("")
        md.append("> BearBeeContrarian ä¸“é—¨å¯»æ‰¾çœ‹ç©ºä¿¡å·ï¼Œå¹³è¡¡èœ‚ç¾¤ç³»ç»Ÿæ€§çœ‹å¤šåå·®")
        md.append("")
        for ticker, data in sorted_results:
            agent = data.get("agent_details", {}).get("BearBeeContrarian", {})
            discovery = agent.get("discovery", "")
            details = agent.get("details", {})
            bear_score = details.get("bear_score", 0)
            signals = details.get("bearish_signals", [])
            direction = agent.get("direction", "neutral")

            if direction == "bearish":
                severity = "**çœ‹ç©ºè­¦å‘Š**"
            elif direction == "neutral":
                severity = "éœ€å…³æ³¨é£é™©ç‚¹"
            elif signals:
                severity = "é£é™©æç¤º"
            else:
                severity = "æš‚æ— çœ‹ç©ºä¿¡å·"

            md.append(f"### {ticker} ({severity} | çœ‹ç©ºå¼ºåº¦ {bear_score:.1f}/10)")
            if signals:
                for sig in signals:
                    md.append(f"- {sig}")
            elif discovery:
                md.append(f"- {discovery}")
            else:
                md.append("- æœªå‘ç°æ˜¾è‘—çœ‹ç©ºä¿¡å·")
            # æ•°æ®æ¥æºæ ‡æ³¨
            sources = details.get("data_sources", {})
            if sources:
                src_labels = {"pheromone_board": "èœ‚ç¾¤å…±äº«", "sec_api": "SECç›´æŸ¥",
                              "options_api": "æœŸæƒç›´æŸ¥", "finviz_api": "Finviz",
                              "yfinance": "yfinance", "unavailable": "ä¸å¯ç”¨"}
                src_parts = [f"{k}={src_labels.get(v, v)}" for k, v in sources.items()]
                md.append(f"- *æ•°æ®æ¥æº*ï¼š{' | '.join(src_parts)}")
            md.append("")

        # ====== ç‰ˆå— 7ï¼šç»¼åˆåˆ¤æ–­ & ä¿¡å·å¼ºåº¦ï¼ˆGuardBeeSentinel + å…¨ä½“æŠ•ç¥¨ï¼‰ ======
        md.append("## 7) ç»¼åˆåˆ¤æ–­ & ä¿¡å·å¼ºåº¦")
        md.append("")
        md.append("| æ ‡çš„ | æ–¹å‘ | ç»¼åˆåˆ† | å…±æŒ¯ | æŠ•ç¥¨(å¤š/ç©º/ä¸­) | æ•°æ®% | å¤±æ•ˆæ¡ä»¶ |")
        md.append("|------|------|--------|------|---------------|-------|---------|")
        for ticker, data in sorted_results:
            res = "Y" if data["resonance"]["resonance_detected"] else "N"
            ab = data["agent_breakdown"]
            data_pct = data.get("data_real_pct", 0)
            # ä» GuardBeeSentinel è·å–äº¤å‰éªŒè¯ä¿¡æ¯
            guard = data.get("agent_details", {}).get("GuardBeeSentinel", {})
            guard_discovery = guard.get("discovery", "")
            thesis_break = "ä¿¡å·åˆ†æ•£" if not guard_discovery else guard_discovery[:30]
            md.append(
                f"| **{ticker}** | {data['direction'].upper()} | "
                f"{data['final_score']:.1f} | {res} | "
                f"{ab['bullish']}/{ab['bearish']}/{ab['neutral']} | "
                f"{data_pct:.0f}% | {thesis_break} |"
            )
        md.append("")

        # GuardBeeSentinel è¯¦ç»†äº¤å‰éªŒè¯
        md.append("### äº¤å‰éªŒè¯è¯¦æƒ…")
        md.append("")
        for ticker, data in sorted_results:
            guard = data.get("agent_details", {}).get("GuardBeeSentinel", {})
            discovery = guard.get("discovery", "")
            if discovery:
                md.append(f"- **{ticker}**ï¼š{discovery}")
        md.append("")

        # ====== ç‰ˆå— P4ï¼šæŠ•èµ„ç»„åˆé›†ä¸­åº¦é£é™© ======
        if concentration and concentration.get("sector_breakdown"):
            risk_level = concentration.get("concentration_risk", "low")
            risk_emoji = {"low": "âœ…", "medium": "âš ï¸", "high": "ğŸš¨"}.get(risk_level, "")
            md.append(f"## ğŸ“Š æŠ•èµ„ç»„åˆé›†ä¸­åº¦åˆ†æ {risk_emoji}")
            md.append("")
            md.append(f"**é›†ä¸­åº¦é£é™©**ï¼š{risk_level.upper()} | **ç»¼åˆè¯„åˆ†**ï¼š{concentration.get('risk_score', 0):.1f}/10")
            md.append("")

            # æ¿å—åˆ†å¸ƒ
            md.append("**æ¿å—åˆ†å¸ƒ**ï¼š")
            for sector, info in concentration.get("sector_breakdown", {}).items():
                tickers_str = " / ".join(info.get("tickers", []))
                md.append(f"- {sector}ï¼š{info.get('pct', 0):.0f}%ï¼ˆ{tickers_str}ï¼‰")
            md.append("")

            # ç›¸å…³æ€§è­¦å‘Š
            corr_warns = concentration.get("correlation_warnings", [])
            if corr_warns:
                md.append("**é«˜ç›¸å…³å¯¹ï¼ˆâ‰¥0.70ï¼‰**ï¼š")
                for w in corr_warns[:4]:
                    md.append(f"- {w['pair']}ï¼šç›¸å…³ç³»æ•° {w['correlation']:.2f} [{w['risk'].upper()}]")
                md.append("")

            # å»ºè®®
            md.append("**åˆ†æ•£åŒ–å»ºè®®**ï¼š")
            for rec in concentration.get("recommendations", []):
                md.append(f"- {rec}")
            md.append("")

        # ====== ç‰ˆå— P5ï¼šå®è§‚ç¯å¢ƒ ======
        if macro_context and macro_context.get("data_source") != "fallback":
            regime = macro_context.get("macro_regime", "neutral")
            regime_emoji = {"risk_on": "ğŸŸ¢", "risk_off": "ğŸ”´", "neutral": "ğŸŸ¡"}.get(regime, "")
            md.append(f"## ğŸŒ å®è§‚ç¯å¢ƒ {regime_emoji}")
            md.append("")
            md.append(f"**å®è§‚æ”¿ä½“**ï¼š{regime.upper()} | **è¯„åˆ†**ï¼š{macro_context.get('macro_score', 5):.1f}/10")
            md.append("")
            md.append(f"| æŒ‡æ ‡ | æ•°å€¼ | çŠ¶æ€ |")
            md.append(f"|------|------|------|")
            md.append(f"| VIX | {macro_context.get('vix', 0):.1f} | {macro_context.get('vix_regime', '')} |")
            md.append(f"| 10Yåˆ©ç‡ | {macro_context.get('treasury_10y', 0):.2f}% | {macro_context.get('rate_environment', '')} |")
            md.append(f"| å¤§ç›˜(5æ—¥) | {macro_context.get('spx_change_pct', 0):+.2f}% | {macro_context.get('market_trend', '')} |")
            md.append(f"| ç¾å…ƒ | â€” | {macro_context.get('dollar_trend', '')} |")
            md.append("")
            headwinds = macro_context.get("macro_headwinds", [])
            tailwinds = macro_context.get("macro_tailwinds", [])
            if headwinds:
                md.append("**é€†é£**ï¼š" + " | ".join(headwinds[:3]))
                md.append("")
            if tailwinds:
                md.append("**é¡ºé£**ï¼š" + " | ".join(tailwinds[:3]))
                md.append("")

        # ====== ç‰ˆå— P3ï¼šå†å²é¢„æµ‹å‡†ç¡®ç‡ï¼ˆT+7 å›æµ‹åé¦ˆï¼‰======
        if backtest_stats and backtest_stats.get("total_checked", 0) > 0:
            acc = backtest_stats["overall_accuracy"]
            total = backtest_stats["total_checked"]
            correct = backtest_stats["correct_count"]
            avg_ret = backtest_stats["avg_return"]
            md.append("## ğŸ“ˆ å†å²é¢„æµ‹å‡†ç¡®ç‡ï¼ˆT+7ï¼Œè¿‘30å¤©ï¼‰")
            md.append("")
            md.append(
                f"**æ ·æœ¬**ï¼š{total} æ¡ | "
                f"**å‡†ç¡®ç‡**ï¼š{acc * 100:.1f}% ({correct}/{total}) | "
                f"**å¹³å‡æ”¶ç›Š**ï¼š{avg_ret:+.2f}%"
            )
            md.append("")
            by_ticker = backtest_stats.get("by_ticker", {})
            if by_ticker:
                md.append("| æ ‡çš„ | æ–¹å‘å‡†ç¡®ç‡ | é¢„æµ‹æ¬¡æ•° | å¹³å‡æ”¶ç›Š |")
                md.append("|------|-----------|---------|---------|")
                for t, info in sorted(
                    by_ticker.items(), key=lambda x: x[1]["total"], reverse=True
                )[:6]:
                    md.append(
                        f"| {t} | {info['accuracy'] * 100:.0f}% "
                        f"| {info['total']} | {info['avg_return']:+.2f}% |"
                    )
                md.append("")
            by_dir = backtest_stats.get("by_direction", {})
            if by_dir:
                parts = []
                for d, label in [("bullish", "çœ‹å¤š"), ("bearish", "çœ‹ç©º"), ("neutral", "ä¸­æ€§")]:
                    info = by_dir.get(d, {})
                    if info.get("total", 0) > 0:
                        parts.append(
                            f"{label}:{info['accuracy']*100:.0f}%({info['total']}æ¬¡)"
                        )
                if parts:
                    md.append("**æŒ‰æ–¹å‘**ï¼š" + " | ".join(parts))
                    md.append("")

        # ====== ç‰ˆå— 8ï¼šæ•°æ®æ¥æº & å…è´£å£°æ˜ ======
        md.append("## 8) æ•°æ®æ¥æº & å…è´£å£°æ˜")
        md.append("")
        md.append("**èœ‚ç¾¤åˆ†å·¥**ï¼š")
        md.append("- ScoutBeeNovaï¼šèªæ˜é’±ä¾¦å¯Ÿï¼ˆSEC Form 4/13F + æ‹¥æŒ¤åº¦ï¼‰")
        md.append("- OracleBeeEchoï¼šå¸‚åœºé¢„æœŸï¼ˆæœŸæƒ IV/P-C Ratio/Gammaï¼‰")
        md.append("- BuzzBeeWhisperï¼šç¤¾äº¤æƒ…ç»ªï¼ˆX/Reddit/Finvizï¼‰")
        md.append("- ChronosBeeHorizonï¼šå‚¬åŒ–å‰‚è¿½è¸ªï¼ˆè´¢æŠ¥/äº‹ä»¶æ—¥å†ï¼‰")
        md.append("- RivalBeeVanguardï¼šç«äº‰æ ¼å±€ï¼ˆML é¢„æµ‹ + è¡Œä¸šå¯¹æ ‡ï¼‰")
        md.append("- GuardBeeSentinelï¼šäº¤å‰éªŒè¯ï¼ˆå…±æŒ¯æ£€æµ‹ + é£é™©è°ƒæ•´ï¼‰")
        md.append("")
        md.append("**å…è´£å£°æ˜**ï¼š")
        md.append(DISCLAIMER_FULL)
        md.append("")

        return "\n".join(md)

    def _generate_swarm_twitter_threads(self, swarm_results: Dict) -> List[str]:
        """ç”Ÿæˆèœ‚ç¾¤æ¨¡å¼çš„ X çº¿ç¨‹ç‰ˆæœ¬"""

        threads = []
        sorted_results = sorted(
            swarm_results.items(),
            key=lambda x: x[1]["final_score"],
            reverse=True
        )

        # ä¸»çº¿ç¨‹
        main_thread = []
        main_thread.append(
            f"ã€Alpha Hive èœ‚ç¾¤æ—¥æŠ¥ {self.date_str}ã€‘"
            f"7 ä¸ªè‡ªæ²»å·¥èœ‚åä½œåˆ†æï¼Œå¤šæ•°æŠ•ç¥¨å…±æŒ¯ä¿¡å·ã€‚"
            f"{DISCLAIMER_SHORT}ğŸ‘‡"
        )

        for i, (ticker, data) in enumerate(sorted_results[:3], 1):
            resonance_emoji = "âœ…" if data["resonance"]["resonance_detected"] else "âŒ"
            insight = data.get("key_insight", "")
            tweet = (
                f"{i}. **{ticker}** {data['direction'].upper()}\n"
                f"èœ‚ç¾¤è¯„åˆ†ï¼š{data['final_score']:.1f}/10 | å…±æŒ¯ï¼š{resonance_emoji}\n"
                f"Agent æŠ•ç¥¨ï¼šçœ‹å¤š{data['agent_breakdown']['bullish']} vs çœ‹ç©º{data['agent_breakdown']['bearish']}"
            )
            if insight:
                tweet += f"\nAIæ´å¯Ÿï¼š{insight}"
            main_thread.append(tweet)

        main_thread.append(
            f"ğŸ 7 ä¸ªå·¥èœ‚ç‹¬ç«‹åˆ†æï¼ˆ6 æ ¸å¿ƒ + çœ‹ç©ºå¯¹å†²èœ‚ï¼‰â†’ ä¿¡æ¯ç´ æ¿å®æ—¶äº¤æ¢ â†’ å¤šæ•°æŠ•ç¥¨æ±‡æ€»\n"
            f"é«˜å…±æŒ¯ä¿¡å·ä¼˜å…ˆçº§æœ€é«˜ã€‚é£é™©æç¤ºï¼šæ§åˆ¶ä»“ä½ã€‚\n"
            f"ä¸‹ä¸€æ­¥ï¼šT+1 éªŒè¯ï¼ŒT+7 å›çœ‹å‡†ç¡®ç‡ã€‚@igg_wang748"
        )

        threads.append("\n\n".join(main_thread))

        return threads

    def _parse_ml_report_to_opportunity(self, ticker: str, ml_report: Dict) -> OpportunityItem:
        """å°† ML æŠ¥å‘Šè§£æä¸º OpportunityItem"""

        adv = ml_report.get("advanced_analysis", {})
        opts = adv.get("options_analysis")
        ml_pred = ml_report.get("ml_prediction", {})

        # æå–å„ç»´åº¦è¯„åˆ†ï¼ˆå‡è®¾å·²æ ‡å‡†åŒ–ä¸º 0-10ï¼‰
        signal_score = adv.get("signal_strength", 5.0)
        catalyst_score = adv.get("catalyst_score", 5.0)
        sentiment_score = adv.get("sentiment_score", 5.0)
        odds_score = adv.get("odds_score", 5.0)
        risk_score = adv.get("risk_adjusted_score", 5.0)

        # å®‰å…¨æå–æœŸæƒåˆ†æ•°
        if opts and isinstance(opts, dict):
            options_score = float(opts.get("options_score", 5.0))
            options_signal = opts.get("signal_summary", "ä¿¡å·å¹³è¡¡")
        else:
            options_score = 5.0
            options_signal = "æœŸæƒæ•°æ®ä¸å¯ç”¨"

        # è®¡ç®—ç»¼åˆ Opportunity Scoreï¼ˆä¸ CLAUDE.md 5 ç»´å…¬å¼ä¸€è‡´ï¼‰
        # options_score åˆå¹¶å…¥ odds ç»´åº¦ï¼ˆå–å¹³å‡ï¼‰
        odds_combined = (odds_score + options_score) / 2.0
        opp_score = (
            0.30 * signal_score +
            0.20 * catalyst_score +
            0.20 * sentiment_score +
            0.15 * odds_combined +
            0.15 * risk_score
        )

        # åˆ¤æ–­æ–¹å‘
        if opp_score >= 7.5:
            direction = "çœ‹å¤š" if signal_score > 5.0 else "çœ‹ç©º"
            confidence = min(95, opp_score * 10)
        elif opp_score >= 6.0:
            direction = "ä¸­æ€§"
            confidence = 60
        else:
            direction = "ä¸­æ€§"
            confidence = 30

        return OpportunityItem(
            ticker=ticker,
            direction=direction,
            signal_score=signal_score,
            catalyst_score=catalyst_score,
            sentiment_score=sentiment_score,
            odds_score=odds_score,
            risk_score=risk_score,
            options_score=options_score,
            opportunity_score=opp_score,
            confidence=confidence,
            key_catalysts=adv.get("upcoming_catalysts", [])[:3] if adv.get("upcoming_catalysts") else [],
            options_signal=options_signal,
            risks=adv.get("key_risks", [])[:2] if adv.get("key_risks") else [],
            thesis_break=adv.get("thesis_break_conditions", "æœªå®šä¹‰")
        )

    def _build_report(self) -> Dict:
        """æ„å»ºå®Œæ•´æŠ¥å‘Š"""

        report = {
            "date": self.date_str,
            "timestamp": self.timestamp.isoformat(),
            "system_status": "âœ… å®Œæˆ",
            "phase_completed": "1-6 (å®Œæ•´èœ‚ç¾¤æµç¨‹)",
            "markdown_report": self._generate_markdown_report(),
            "twitter_threads": self._generate_twitter_threads(),
            "opportunities": [
                {
                    "rank": i + 1,
                    "ticker": opp.ticker,
                    "direction": opp.direction,
                    "opp_score": round(opp.opportunity_score, 1),
                    "confidence": f"{opp.confidence:.0f}%",
                    "options_signal": opp.options_signal,
                    "key_catalyst": opp.key_catalysts[0] if opp.key_catalysts else "N/A",
                    "thesis_break": opp.thesis_break
                }
                for i, opp in enumerate(self.opportunities[:5])
            ],
            "observation_list": self.observations
        }

        return report

    def _generate_markdown_report(self) -> str:
        """ç”Ÿæˆä¸­æ–‡ Markdown æŠ¥å‘Š"""

        md = []
        md.append(f"# ã€{self.date_str}ã€‘Alpha Hive æ¯æ—¥æŠ•èµ„ç®€æŠ¥")
        md.append("")
        md.append(f"**è‡ªåŠ¨ç”Ÿæˆäº**ï¼š{self.timestamp.strftime('%Y-%m-%d %H:%M:%S')}")
        md.append(f"**ç³»ç»ŸçŠ¶æ€**ï¼šâœ… å®Œå…¨æ¿€æ´» | Phase 1-6 å®Œæˆ")
        md.append("")

        # 1. ä»Šæ—¥æ‘˜è¦
        md.append("## ğŸ“Š ä»Šæ—¥æ‘˜è¦ï¼ˆTop 3ï¼‰")
        md.append("")

        for i, opp in enumerate(self.opportunities[:3], 1):
            md.append(f"### {i}. **{opp.ticker}** - {opp.direction}")
            md.append(f"- **æœºä¼šåˆ†æ•°**ï¼š{opp.opportunity_score:.1f}/10 | **ç½®ä¿¡åº¦**ï¼š{opp.confidence:.0f}%")
            md.append(f"- **æœŸæƒä¿¡å·**ï¼š{opp.options_signal}")
            if opp.key_catalysts:
                md.append(f"- **å…³é”®å‚¬åŒ–å‰‚**ï¼š{', '.join(opp.key_catalysts[:2])}")
            md.append("")

        # 2. æœºä¼šæ¸…å•
        md.append("## ğŸ¯ å®Œæ•´æœºä¼šæ¸…å•")
        md.append("")
        md.append("| æ’åº | æ ‡çš„ | æ–¹å‘ | ç»¼åˆåˆ† | æœŸæƒä¿¡å· | ç½®ä¿¡åº¦ |")
        md.append("|------|------|------|--------|---------|--------|")

        for i, opp in enumerate(self.opportunities[:5], 1):
            md.append(
                f"| {i} | **{opp.ticker}** | {opp.direction} | "
                f"{opp.opportunity_score:.1f} | {opp.options_signal[:12]}... | {opp.confidence:.0f}% |"
            )

        md.append("")

        # 3. é£é™©é›·è¾¾
        md.append("## âš ï¸ é£é™©é›·è¾¾")
        md.append("")
        for opp in self.opportunities[:3]:
            if opp.risks:
                md.append(f"**{opp.ticker}**ï¼š{', '.join(opp.risks)}")

        md.append("")

        # 4. æ•°æ®æ¥æºä¸å…è´£
        md.append("## ğŸ“ æ•°æ®æ¥æº & å…è´£å£°æ˜")
        md.append("")
        md.append("**æ•°æ®æº**ï¼š")
        md.append("- StockTwits æƒ…ç»ªï¼ˆå®æ—¶ï¼‰")
        md.append("- Polymarket èµ”ç‡ï¼ˆæ¯5åˆ†é’Ÿï¼‰")
        md.append("- Yahoo Finance / yFinanceï¼ˆå®æ—¶ï¼‰")
        md.append("- SEC æŠ«éœ²ï¼ˆæ¯æ—¥æ›´æ–°ï¼‰")
        md.append("- **æœŸæƒé“¾æ•°æ®**ï¼ˆyFinanceï¼Œæ¯5åˆ†é’Ÿç¼“å­˜ï¼‰")
        md.append("")
        md.append("**å…è´£å£°æ˜**ï¼š")
        md.append(DISCLAIMER_FULL)
        md.append("")

        return "\n".join(md)

    def _generate_twitter_threads(self) -> List[str]:
        """ç”Ÿæˆ X çº¿ç¨‹ç‰ˆæœ¬"""

        threads = []

        # ä¸»çº¿ç¨‹
        main_thread = []
        main_thread.append(
            f"ã€Alpha Hive æ—¥æŠ¥ {self.date_str}ã€‘"
            f"{DISCLAIMER_SHORT}"
            f"ä»Šå¤©æœ€å€¼å¾—è·Ÿè¸ªçš„ 3 ä¸ªæœºä¼š ğŸ‘‡"
        )

        for i, opp in enumerate(self.opportunities[:3], 1):
            main_thread.append(
                f"{i}. **{opp.ticker}** {opp.direction}\n"
                f"ç»¼åˆåˆ†ï¼š{opp.opportunity_score:.1f}/10 | æœŸæƒä¿¡å·ï¼š{opp.options_signal}\n"
                f"ä¸»å‚¬åŒ–å‰‚ï¼š{opp.key_catalysts[0] if opp.key_catalysts else 'TBD'}"
            )

        main_thread.append(
            f"æ›´å¤šè¯¦æƒ…è§å®Œæ•´æ—¥æŠ¥ã€‚é£é™©æç¤ºï¼šé«˜æ³¢åŠ¨æ ‡çš„éœ€æ§åˆ¶ä»“ä½ã€‚"
            f"ä¸‹ä¸€æ­¥è·Ÿè¸ªï¼šT+1 éªŒè¯ä¿¡å·å¼ºåº¦ï¼ŒT+7 å›çœ‹é¢„æµ‹åå·®ã€‚@igg_wang748"
        )

        threads.append("\n\n".join(main_thread))

        return threads

    def auto_commit_and_notify(self, report: Dict) -> Dict:
        """
        è‡ªåŠ¨æäº¤æŠ¥å‘Šåˆ° Git + Slack é€šçŸ¥ï¼ˆAgent Toolbox æ¼”ç¤ºï¼‰

        æ–°åŠŸèƒ½ï¼šä½¿ç”¨ AgentHelper è‡ªåŠ¨æ‰§è¡Œ Git æäº¤å’Œé€šçŸ¥
        """
        _log.info("Auto-commit & Notify å¯åŠ¨")

        results = {}

        # æ£€æŸ¥æœ€è¿‘ä¸€æ¬¡æäº¤æ˜¯å¦å·²æ˜¯ä»Šæ—¥æŠ¥å‘Šï¼ˆå†³å®š commit vs amendï¼‰
        today_commit_msg = f"Alpha Hive èœ‚ç¾¤æ—¥æŠ¥ {self.date_str}"
        last_r = self.agent_helper.git.run_git_cmd("git log -1 --pretty=%s")
        last_msg = last_r.get("stdout", "").strip()
        is_amend = (last_msg == today_commit_msg)
        did_amend = False

        # 1. Git æäº¤æŠ¥å‘Š
        _log.info("Git commit... (mode: %s)", "amend" if is_amend else "new")
        status = self.agent_helper.git.status()
        if status.get("modified_files"):
            if is_amend:
                # ä»Šæ—¥å·²æœ‰æäº¤ â†’ amend è¦†ç›–ï¼Œä¸å åŠ æ–° commit
                self.agent_helper.git.run_git_cmd("git add -A")
                r = self.agent_helper.git.run_git_cmd(
                    f"git commit --amend -m '{today_commit_msg}'"
                )
                commit_result = {"success": r["success"], "mode": "amend",
                                 "message": r.get("stdout", "") or r.get("stderr", "")}
                did_amend = True
            else:
                commit_result = self.agent_helper.git.commit(today_commit_msg)
            results["git_commit"] = commit_result
            if commit_result["success"]:
                _log.info("Git commit æˆåŠŸï¼ˆ%sï¼‰", "amend" if is_amend else "new")
            else:
                _log.warning("Git commit å¤±è´¥ï¼š%s", commit_result.get('message'))
        else:
            _log.info("æ— éœ€æäº¤ï¼ˆå·¥ä½œç›®å½•å¹²å‡€ï¼‰")

        # 2. Git æ¨é€ï¼ˆamend åéœ€è¦ force-with-lease å¼ºåˆ¶æ¨é€ï¼‰
        _log.info("Git push...")
        if did_amend:
            r = self.agent_helper.git.run_git_cmd("git push origin main --force-with-lease")
            push_result = {"success": r["success"],
                           "output": r.get("stdout", "") or r.get("stderr", ""),
                           "mode": "force-with-lease"}
        else:
            push_result = self.agent_helper.git.push("main")
        results["git_push"] = push_result
        if push_result["success"]:
            _log.info("Git push æˆåŠŸ")
        else:
            _log.warning("Git push å¤±è´¥")

        # 3. Slack é€šçŸ¥
        _log.info("å‘é€ Slack é€šçŸ¥...")
        top_opp = self.opportunities[0] if self.opportunities else None
        if top_opp:
            message = (
                f"ğŸ“Š *èœ‚ç¾¤æ—¥æŠ¥ {self.date_str}*\n"
                f"ğŸ¯ Top æœºä¼šï¼š{top_opp.ticker} {top_opp.direction}\n"
                f"ğŸ“ˆ ç»¼åˆåˆ†ï¼š{top_opp.opportunity_score:.1f}/10\n"
                f"ğŸ”— æŠ¥å‘Šï¼š`{self.report_dir / f'alpha-hive-daily-{self.date_str}.md'}`"
            )
            slack_result = self.agent_helper.notify.send_slack_message(
                "#alpha-hive",
                message
            )
            results["slack_notification"] = slack_result
            if slack_result.get("success"):
                _log.info("Slack é€šçŸ¥å·²å‘é€")
            else:
                _log.warning("Slack é€šçŸ¥å¤±è´¥ï¼š%s", slack_result.get('error'))

        _log.info("Auto-commit & Notify å®Œæˆ")
        return results

    def check_earnings_updates(self, report_path: str = None, tickers: List[str] = None) -> Dict:
        """
        æ£€æŸ¥ watchlist ä¸­ä»Šæ—¥æ˜¯å¦æœ‰æ ‡çš„å‘å¸ƒäº†è´¢æŠ¥ï¼Œè‹¥æœ‰åˆ™è‡ªåŠ¨æŠ“å–ç»“æœå¹¶æ›´æ–°ç®€æŠ¥

        Args:
            report_path: ç®€æŠ¥æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ä»Šæ—¥ç®€æŠ¥ï¼‰
            tickers: è¦æ£€æŸ¥çš„æ ‡çš„ï¼ˆé»˜è®¤ WATCHLIST å…¨éƒ¨ï¼‰

        Returns:
            {reporting_today: [], updated: [], earnings_data: {}, errors: []}
        """
        if not self.earnings_watcher:
            _log.info("EarningsWatcher ä¸å¯ç”¨ï¼Œè·³è¿‡è´¢æŠ¥æ£€æŸ¥")
            return {"reporting_today": [], "updated": [], "earnings_data": {}, "errors": ["EarningsWatcher not available"]}

        if tickers is None:
            tickers = list(WATCHLIST.keys())

        if report_path is None:
            # æŸ¥æ‰¾ä»Šæ—¥ç®€æŠ¥
            candidates = [
                self.report_dir / "reports" / f"alpha_hive_daily_{self.date_str}.md",
                self.report_dir / f"alpha-hive-daily-{self.date_str}.md",
            ]
            for c in candidates:
                if c.exists():
                    report_path = str(c)
                    break

        if report_path is None:
            _log.warning("æœªæ‰¾åˆ°ä»Šæ—¥ç®€æŠ¥æ–‡ä»¶ï¼Œè·³è¿‡è´¢æŠ¥æ›´æ–°")
            return {"reporting_today": [], "updated": [], "earnings_data": {}, "errors": ["no report file found"]}

        result = self.earnings_watcher.check_and_update(tickers, report_path)

        # å¦‚æœæœ‰æ›´æ–°ï¼Œé€šè¿‡ Slack å‘é€é€šçŸ¥
        if result.get("updated") and self.slack_notifier and self.slack_notifier.enabled:
            for ticker in result["updated"]:
                ed = result["earnings_data"].get(ticker, {})
                rev = ed.get("revenue_actual")
                eps = ed.get("eps_actual")
                yoy = ed.get("yoy_revenue_growth")

                msg_parts = [f"{ticker} è´¢æŠ¥æ•°æ®å·²è‡ªåŠ¨æ›´æ–°"]
                if rev:
                    rev_str = f"${rev / 1e9:.1f}B" if abs(rev) >= 1e9 else f"${rev / 1e6:.0f}M"
                    msg_parts.append(f"è¥æ”¶ {rev_str}")
                if yoy is not None:
                    msg_parts.append(f"YoY {'+' if yoy > 0 else ''}{yoy * 100:.1f}%")
                if eps is not None:
                    msg_parts.append(f"EPS ${eps:.2f}")

                try:
                    self.slack_notifier.send_opportunity_alert(
                        ticker,
                        0,  # score placeholder
                        "è´¢æŠ¥æ›´æ–°",
                        " | ".join(msg_parts),
                        ["è‡ªåŠ¨æŠ“å–", f"å®Œæ•´åº¦: {ed.get('data_completeness', 'N/A')}"]
                    )
                except (OSError, ValueError, RuntimeError) as e:
                    _log.warning("Slack è´¢æŠ¥é€šçŸ¥å‘é€å¤±è´¥: %s", e)

        # D1: è‡ªåŠ¨åŒæ­¥è´¢æŠ¥æ—¥æœŸåˆ°å‚¬åŒ–å‰‚æ—¥å†
        try:
            auto_catalysts = self.earnings_watcher.get_catalysts_for_calendar(tickers)
            if auto_catalysts and hasattr(self, 'calendar') and self.calendar:
                # åˆå¹¶è‡ªåŠ¨è·å–çš„è´¢æŠ¥æ—¥æœŸä¸ config.CATALYSTS
                from config import CATALYSTS
                merged = dict(CATALYSTS)
                for t, events in auto_catalysts.items():
                    if t in merged:
                        # å»é‡ï¼šåªæ·»åŠ å°šæœªå­˜åœ¨çš„ earnings äº‹ä»¶
                        existing_dates = {e.get("scheduled_date") for e in merged[t]}
                        for ev in events:
                            if ev.get("scheduled_date") not in existing_dates:
                                merged[t].append(ev)
                    else:
                        merged[t] = events
                self.calendar.sync_catalysts(catalysts=merged, tickers=tickers)
                _log.info("å·²è‡ªåŠ¨åŒæ­¥ %d ä¸ªæ ‡çš„çš„è´¢æŠ¥æ—¥æœŸåˆ°å‚¬åŒ–å‰‚æ—¥å†", len(auto_catalysts))
        except (ImportError, OSError, ValueError, TypeError, AttributeError) as e:
            _log.debug("å‚¬åŒ–å‰‚æ—¥å†è‡ªåŠ¨åŒæ­¥è·³è¿‡: %s", e)

        return result

    def _generate_ml_reports(self, report: Dict) -> List[str]:
        """ä¸ºæ‰«ææ ‡çš„æ‰¹é‡ç”Ÿæˆ ML å¢å¼º HTML æŠ¥å‘Šï¼ˆåŒæ­¥å†™å…¥ï¼Œä¾› _generate_index_html æ£€æµ‹åˆ°æ–‡ä»¶åæ·»åŠ é“¾æ¥ï¼‰"""
        opps = report.get("opportunities", [])
        tickers = [o.get("ticker") for o in opps if o.get("ticker")]
        if not tickers:
            return []

        # åŠ è½½èœ‚ç¾¤è¯¦ç»†æ•°æ®ï¼ˆsave_report å·²å†™å…¥ .swarm_results_*.jsonï¼‰
        swarm_data: Dict = {}
        sr_path = self.report_dir / f".swarm_results_{self.date_str}.json"
        if sr_path.exists():
            try:
                with open(sr_path) as f:
                    swarm_data = json.load(f)
            except (OSError, json.JSONDecodeError):
                pass

        generated = []
        for ticker in tickers:
            try:
                # ä» yfinance è·å–å½“å‰ä»·æ ¼
                real_price, real_change = 100.0, 0.0
                try:
                    import yfinance as _yf
                    _hist = _yf.Ticker(ticker).history(period="5d")
                    if not _hist.empty:
                        real_price = float(_hist["Close"].iloc[-1])
                        if len(_hist) >= 2:
                            real_change = (_hist["Close"].iloc[-1] / _hist["Close"].iloc[-2] - 1) * 100
                except Exception:
                    pass

                ticker_data = {
                    "ticker": ticker,
                    "sources": {
                        "yahoo_finance": {
                            "current_price": real_price,
                            "price_change_5d": real_change,
                            "change_pct": real_change,
                        }
                    },
                }

                # ç”Ÿæˆ ML å¢å¼ºåˆ†æ
                enhanced = self.ml_generator.generate_ml_enhanced_report(ticker, ticker_data)

                # æ³¨å…¥èœ‚ç¾¤æ•°æ®
                if ticker in swarm_data:
                    enhanced["swarm_results"] = swarm_data[ticker]

                # åŒæ­¥å†™å…¥ HTMLï¼ˆå¿…é¡»åœ¨ _generate_index_html å‰å®Œæˆï¼Œä»¥ä¾¿æ–‡ä»¶å­˜åœ¨æ€§æ£€æµ‹é€šè¿‡ï¼‰
                html = self.ml_generator.generate_html_report(ticker, enhanced)
                html_path = self.report_dir / f"alpha-hive-{ticker}-ml-enhanced-{self.date_str}.html"
                with open(html_path, "w", encoding="utf-8") as f:
                    f.write(html)

                generated.append(ticker)
                _log.info("ML å¢å¼ºæŠ¥å‘Šå·²ç”Ÿæˆï¼š%s", html_path.name)

            except Exception as e:
                _log.warning("ML æŠ¥å‘Šç”Ÿæˆå¤±è´¥ %s: %s", ticker, e)

        return generated

    def save_report(self, report: Dict) -> str:
        """ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶ï¼ˆMD / JSON / Xçº¿ç¨‹ / index.html GitHub Pagesï¼‰"""

        # ä¿å­˜ JSON ç‰ˆæœ¬
        json_file = self.report_dir / f"alpha-hive-daily-{self.date_str}.json"
        with open(json_file, "w", encoding="utf-8") as f:
            json.dump(report, f, ensure_ascii=False, indent=2)

        # ä¿å­˜ Markdown ç‰ˆæœ¬
        md_file = self.report_dir / f"alpha-hive-daily-{self.date_str}.md"
        with open(md_file, "w", encoding="utf-8") as f:
            f.write(report["markdown_report"])

        # æ¸…ç†å½“å¤©æ—§çš„ X çº¿ç¨‹æ–‡ä»¶ï¼ˆé˜²æ­¢å¤šæ¬¡è¿è¡Œæ—¶æ•°é‡ä¸åŒå¯¼è‡´æ®‹ç•™å åŠ ï¼‰
        for old in self.report_dir.glob(f"alpha-hive-thread-{self.date_str}-*.txt"):
            old.unlink()

        # ä¿å­˜ X çº¿ç¨‹ç‰ˆæœ¬
        for i, thread in enumerate(report["twitter_threads"], 1):
            thread_file = self.report_dir / f"alpha-hive-thread-{self.date_str}-{i}.txt"
            with open(thread_file, "w", encoding="utf-8") as f:
                f.write(thread)

        # ç”Ÿæˆ ML å¢å¼º HTML æŠ¥å‘Šï¼ˆå¿…é¡»åœ¨ _generate_index_html å‰å®Œæˆï¼Œä»¥ä¾¿ ML é“¾æ¥è‡ªåŠ¨å‡ºç°ï¼‰
        try:
            ml_tickers = self._generate_ml_reports(report)
            if ml_tickers:
                _log.info("ML å¢å¼ºæŠ¥å‘Šå®Œæˆï¼š%s", ml_tickers)
                print(f"   ML æŠ¥å‘Š     : âœ… {', '.join(ml_tickers)}")
        except Exception as e:
            _log.warning("ML æŠ¥å‘Šæ‰¹é‡ç”Ÿæˆå‡ºé”™: %s", e)

        # æ›´æ–° GitHub Pages ä»ªè¡¨æ¿
        try:
            html = self._generate_index_html(report)
            index_file = self.report_dir / "index.html"
            with open(index_file, "w", encoding="utf-8") as f:
                f.write(html)
            _log.info("index.html å·²æ›´æ–°ï¼ˆGitHub Pagesï¼‰")
        except Exception as e:
            _log.warning("index.html ç”Ÿæˆå¤±è´¥: %s", e)

        _log.info("æŠ¥å‘Šå·²ä¿å­˜ï¼š%s", md_file.name)

        return str(md_file)

    def _generate_index_html(self, report: Dict) -> str:
        """ä» swarm report + .swarm_results_*.json ç”Ÿæˆå®Œæ•´ GitHub Pages ä»ªè¡¨æ¿"""
        from datetime import datetime as _dt
        import html as _html
        from pathlib import Path as _Path

        now_str = _dt.now().strftime("%Y-%m-%d %H:%M PST")
        date_str = self.date_str
        opps = report.get("opportunities", [])
        meta = report.get("swarm_metadata", {})
        n_tickers = meta.get("tickers_analyzed", len(opps))
        n_agents = meta.get("total_agents", 7)
        n_resonance = meta.get("resonances_detected", 0)

        # è¯»å–è¯¦ç»† swarm_resultsï¼ˆå« IV Rankã€P/C Ratioã€å†…å¹•ä¿¡å·ç­‰ï¼‰
        swarm_detail: Dict = {}
        try:
            sr_path = self.report_dir / f".swarm_results_{date_str}.json"
            if sr_path.exists():
                with open(sr_path) as _f:
                    swarm_detail = json.load(_f)
        except (OSError, json.JSONDecodeError):
            pass

        # å°† opportunities æŒ‰ ticker å»ºç«‹ç´¢å¼•ï¼Œå¹¶è¡¥å…… swarm è¯¦ç»†æ•°æ®
        opp_by_ticker = {o.get("ticker"): o for o in opps}
        # è‹¥ swarm_detail æœ‰æ›´å¤š tickerï¼ˆè¶…è¿‡ opportunities çš„ 5 ä¸ªï¼‰ï¼Œå…¨éƒ¨çº³å…¥
        all_tickers_sorted = [o.get("ticker") for o in opps]
        for t in swarm_detail:
            if t not in all_tickers_sorted:
                all_tickers_sorted.append(t)

        dir_map = {"bullish": ("çœ‹å¤š", "bullish", "#28a745"),
                   "bearish": ("çœ‹ç©º", "bearish", "#dc3545"),
                   "neutral": ("ä¸­æ€§", "neutral", "#ffc107")}

        def sc_cls(score):
            return "sc-h" if score >= 7.0 else ("sc-m" if score >= 5.5 else "sc-l")

        def _detail(ticker):
            """æå–å•ä¸ª ticker çš„è¯¦ç»†æŒ‡æ ‡"""
            sd = swarm_detail.get(ticker, {})
            ad = sd.get("agent_details", {})
            oracle = ad.get("OracleBeeEcho", {}).get("details", {})
            scout_disc = ad.get("ScoutBeeNova", {}).get("discovery", "")
            bear_score = ad.get("BearBeeContrarian", {}).get("score", 0.0)
            ab = sd.get("agent_breakdown", {})
            iv_rank = oracle.get("iv_rank", None)
            pc = oracle.get("put_call_ratio", None)
            real_pct = sd.get("data_real_pct", None)
            # å†…å¹•ä¿¡å·ï¼šå– ScoutBeeNova discovery ç¬¬ä¸€ä¸ª | æ®µ
            insider_hint = scout_disc.split("|")[0].strip() if scout_disc else ""
            # æ˜¯å¦æœ‰å†…å¹•ä¹°å…¥/å–å‡º
            insider_color = "#28a745" if "ä¹°å…¥" in insider_hint else ("#dc3545" if "å–å‡º" in insider_hint else "#666")
            return {
                "iv_rank": f"{iv_rank:.1f}" if iv_rank is not None else "-",
                "pc": f"{pc:.2f}" if pc is not None else "-",
                "bear_score": float(bear_score),
                "bullish": ab.get("bullish", 0),
                "bearish_v": ab.get("bearish", 0),
                "neutral_v": ab.get("neutral", 0),
                "insider_hint": _html.escape(insider_hint[:35]) if insider_hint else "",
                "insider_color": insider_color,
                "real_pct": f"{real_pct:.0f}%" if real_pct is not None else "-",
            }

        # è®¡ç®— avg real_pct
        real_pcts = [swarm_detail[t].get("data_real_pct", 0) for t in swarm_detail if swarm_detail[t].get("data_real_pct")]
        avg_real = f"{sum(real_pcts)/len(real_pcts):.0f}%" if real_pcts else "-"

        # â”€â”€ æœºä¼šå¡ç‰‡ï¼ˆTop 6ï¼‰â”€â”€
        cards_html = ""
        for i, ticker in enumerate(all_tickers_sorted[:6], 1):
            opp = opp_by_ticker.get(ticker, {})
            score = float(opp.get("opp_score") or swarm_detail.get(ticker, {}).get("final_score", 0))
            direction = str(opp.get("direction") or swarm_detail.get(ticker, {}).get("direction", "neutral")).lower()
            if direction not in dir_map:
                direction = "bullish" if "å¤š" in direction else ("bearish" if "ç©º" in direction else "neutral")
            resonance = opp.get("resonance", swarm_detail.get(ticker, {}).get("resonance", {}).get("resonance_detected", False))
            supporting = int(opp.get("supporting_agents") or swarm_detail.get(ticker, {}).get("supporting_agents", 0))
            dir_label, dir_cls, dir_color = dir_map[direction]
            border = " style=\"border-color:#28a745;border-width:2px;\"" if i == 1 else ""
            rank_style = " style=\"background:#28a745;color:white;\"" if i == 1 else ""
            sc = sc_cls(score)
            res_badge = (f'<span class="res-badge res-y">{supporting} Agent å…±æŒ¯</span>'
                         if resonance else '<span class="res-badge res-n">æ— å…±æŒ¯</span>')
            d = _detail(ticker)
            pc_color = ' style="color:#28a745;font-weight:bold;"' if d["pc"] != "-" and float(d["pc"]) < 0.7 else (
                       ' style="color:#dc3545;font-weight:bold;"' if d["pc"] != "-" and float(d["pc"]) > 1.5 else "")
            bear_pct = min(100, int(d["bear_score"] * 10))
            insider_row = (f'<div class="mr"><span class="lbl">å†…å¹•ä¿¡å·</span>'
                           f'<span class="val" style="color:{d["insider_color"]};">{d["insider_hint"]}</span></div>'
                           if d["insider_hint"] else "")
            ml_link = _Path(self.report_dir / f"alpha-hive-{ticker}-ml-enhanced-{date_str}.html")
            ml_row = (f'<div class="mr"><span class="lbl">ML æŠ¥å‘Š</span>'
                      f'<span class="val"><a href="alpha-hive-{ticker}-ml-enhanced-{date_str}.html" style="color:#667eea;">æŸ¥çœ‹è¯¦æƒ…</a></span></div>'
                      if ml_link.exists() else "")
            cards_html += f"""
                <div class="opp-card"{border}>
                    <div class="card-rank"{rank_style}>#{i}</div>
                    <div class="card-hd">
                        <h3>{_html.escape(ticker)}</h3>
                        <div class="dir-badge dir-{dir_cls}">{dir_label}</div>
                    </div>
                    <div class="card-body">
                        <div class="mr"><span class="lbl">ç»¼åˆåˆ†</span><span class="val {sc}">{score:.1f}/10</span></div>
                        <div class="mr"><span class="lbl">å…±æŒ¯ä¿¡å·</span>{res_badge}</div>
                        <div class="mr"><span class="lbl">æŠ•ç¥¨</span><span class="val">{d['bullish']}å¤š / {d['bearish_v']}ç©º / {d['neutral_v']}ä¸­</span></div>
                        <div class="mr"><span class="lbl">IV Rank</span><span class="val">{d['iv_rank']}</span></div>
                        <div class="mr"><span class="lbl">P/C Ratio</span><span class="val"{pc_color}>{d['pc']}</span></div>
                        {insider_row}
                        <div class="mr"><span class="lbl">çœ‹ç©ºå¼ºåº¦</span><span class="val">{d['bear_score']:.1f}/10</span></div>
                        <div class="bear-bar"><div class="bear-fill" style="width:{bear_pct}%"></div></div>
                        {ml_row}
                    </div>
                </div>"""

        # â”€â”€ å®Œæ•´è¡¨æ ¼ï¼ˆå…¨éƒ¨ tickerï¼‰â”€â”€
        rows_html = ""
        for i, ticker in enumerate(all_tickers_sorted, 1):
            opp = opp_by_ticker.get(ticker, {})
            score = float(opp.get("opp_score") or swarm_detail.get(ticker, {}).get("final_score", 0))
            direction = str(opp.get("direction") or swarm_detail.get(ticker, {}).get("direction", "neutral")).lower()
            if direction not in dir_map:
                direction = "bullish" if "å¤š" in direction else ("bearish" if "ç©º" in direction else "neutral")
            resonance = opp.get("resonance", swarm_detail.get(ticker, {}).get("resonance", {}).get("resonance_detected", False))
            supporting = int(opp.get("supporting_agents") or swarm_detail.get(ticker, {}).get("supporting_agents", 0))
            dir_label, _, dir_color = dir_map[direction]
            sc = sc_cls(score)
            d = _detail(ticker)
            res_html = (f'<span class="res-badge res-y">{supporting} Agent</span>'
                        if resonance else '<span class="res-badge res-n">æ— </span>')
            row_style = " style=\"background:#f0fff0;\"" if i == 1 else ""
            ml_link = _Path(self.report_dir / f"alpha-hive-{ticker}-ml-enhanced-{date_str}.html")
            ml_td = (f'<a href="alpha-hive-{ticker}-ml-enhanced-{date_str}.html" style="color:#667eea;">æŸ¥çœ‹</a>'
                     if ml_link.exists() else "-")
            pc_style = (' style="color:#28a745;font-weight:bold;"' if d["pc"] != "-" and float(d["pc"]) < 0.7
                        else (' style="color:#dc3545;font-weight:bold;"' if d["pc"] != "-" and float(d["pc"]) > 1.5 else ""))
            rows_html += f"""
                <tr{row_style}>
                    <td>{i}</td>
                    <td><strong>{_html.escape(ticker)}</strong></td>
                    <td style="color:{dir_color};font-weight:bold;">{dir_label}</td>
                    <td class="{sc}"><strong>{score:.1f}</strong>/10</td>
                    <td>{res_html}</td>
                    <td>{d['bullish']} / {d['bearish_v']} / {d['neutral_v']}</td>
                    <td>{d['iv_rank']}</td>
                    <td{pc_style}>{d['pc']}</td>
                    <td style="color:#fd7e14;">{d['bear_score']:.1f}/10</td>
                    <td>{ml_td}</td>
                </tr>"""

        return f"""<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Alpha Hive - æŠ•èµ„ç®€æŠ¥ä»ªè¡¨æ¿</title>
    <style>
        * {{ margin: 0; padding: 0; box-sizing: border-box; }}
        body {{ font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
               background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
               min-height: 100vh; padding: 20px; }}
        .container {{ max-width: 1400px; margin: 0 auto; }}
        .header {{ background: white; border-radius: 15px; padding: 40px;
                   margin-bottom: 30px; box-shadow: 0 10px 40px rgba(0,0,0,0.1); text-align: center; }}
        .header h1 {{ font-size: 2.5em; color: #667eea; margin-bottom: 10px; }}
        .header p {{ color: #666; font-size: 1.1em; }}
        .header .update-time {{ display: inline-block; margin-top: 12px; padding: 6px 18px;
            background: #f0f0ff; border-radius: 20px; color: #667eea; font-size: 0.95em; font-weight: 500; }}
        .main-grid {{ display: grid; grid-template-columns: 2fr 1fr; gap: 30px; margin-bottom: 30px; }}
        .section {{ background: white; border-radius: 15px; padding: 30px; box-shadow: 0 10px 40px rgba(0,0,0,0.1); }}
        .section h2 {{ color: #667eea; font-size: 1.6em; margin-bottom: 20px;
                       display: flex; align-items: center; gap: 10px; }}
        .section h2::before {{ content: ''; display: inline-block; width: 4px; height: 28px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 2px; }}
        .opp-grid {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; }}
        .opp-card {{ border: 1px solid #e0e0e0; border-radius: 12px; padding: 22px;
            background: linear-gradient(135deg, #f8f9fa 0%, #fff 100%); position: relative;
            transition: transform 0.3s, box-shadow 0.3s; }}
        .opp-card:hover {{ transform: translateY(-5px); box-shadow: 0 15px 35px rgba(102,126,234,0.2); }}
        .card-rank {{ position: absolute; top: 10px; right: 15px; font-size: 0.85em;
            font-weight: bold; color: #667eea; background: #f0f0f0; padding: 4px 8px; border-radius: 5px; }}
        .card-hd {{ display: flex; justify-content: space-between; align-items: center;
            margin-bottom: 12px; padding-bottom: 10px; border-bottom: 1px solid #eee; }}
        .card-hd h3 {{ font-size: 1.5em; color: #333; }}
        .dir-badge {{ padding: 4px 14px; border-radius: 20px; color: white; font-size: 0.85em; font-weight: bold; }}
        .dir-bullish {{ background: #28a745; }} .dir-neutral {{ background: #ffc107; color: #333; }}
        .dir-bearish {{ background: #dc3545; }}
        .card-body {{ display: flex; flex-direction: column; gap: 8px; }}
        .mr {{ display: flex; justify-content: space-between; align-items: center; padding: 6px 0; font-size: 0.93em; }}
        .mr .lbl {{ color: #666; font-weight: 500; }} .mr .val {{ color: #333; font-weight: bold; }}
        .sc-h {{ color: #28a745; }} .sc-m {{ color: #fd7e14; }} .sc-l {{ color: #dc3545; }}
        .res-badge {{ display: inline-block; padding: 2px 10px; border-radius: 10px; font-size: 0.8em; font-weight: bold; }}
        .res-y {{ background: #d4edda; color: #155724; }} .res-n {{ background: #f8d7da; color: #721c24; }}
        .bear-bar {{ height: 6px; border-radius: 3px; background: #eee; margin-top: 4px; }}
        .bear-fill {{ height: 100%; border-radius: 3px; background: linear-gradient(90deg, #ffc107, #dc3545); }}
        .status-card {{ border: 2px solid #28a745; border-radius: 10px; padding: 20px;
            background: linear-gradient(135deg, rgba(102,126,234,0.05), rgba(118,75,162,0.05)); }}
        .status-hd {{ display: flex; justify-content: space-between; align-items: center;
            margin-bottom: 15px; padding-bottom: 10px; border-bottom: 1px solid #eee; }}
        .status-hd h3 {{ color: #667eea; font-size: 1.2em; }}
        .status-ind {{ display: flex; align-items: center; gap: 8px; font-size: 1.1em; font-weight: bold; color: #28a745; }}
        .status-dot {{ width: 12px; height: 12px; border-radius: 50%; background-color: #28a745; animation: pulse 2s infinite; }}
        @keyframes pulse {{ 0%,100% {{ opacity:1; }} 50% {{ opacity:0.5; }} }}
        .si {{ display: flex; flex-direction: column; gap: 10px; font-size: 0.95em; }}
        .sr {{ display: flex; justify-content: space-between; }}
        .sr .sl {{ color: #666; }} .sr .sv {{ color: #333; font-weight: bold; }}
        .full-table {{ width: 100%; border-collapse: collapse; margin-top: 10px; }}
        .full-table th, .full-table td {{ padding: 11px 12px; text-align: left; border-bottom: 1px solid #eee; }}
        .full-table th {{ background: linear-gradient(135deg, #667eea, #764ba2); color: white; font-weight: 600; font-size: 0.88em; }}
        .full-table tr:hover {{ background-color: #f8f9fa; }}
        .full-table td {{ font-size: 0.93em; }}
        .footer {{ text-align: center; color: white; margin-top: 30px; font-size: 0.95em; }}
        .footer p {{ margin: 5px 0; }}
        @media (max-width: 768px) {{
            .main-grid {{ grid-template-columns: 1fr; }}
            .header {{ padding: 20px; }} .header h1 {{ font-size: 1.8em; }}
            .opp-grid {{ grid-template-columns: 1fr; }}
            .full-table {{ font-size: 0.82em; }} .full-table th, .full-table td {{ padding: 8px 6px; }}
        }}
    </style>
</head>
<body>
<div class="container">
    <div class="header">
        <h1>Alpha Hive æ¯æ—¥æŠ•èµ„ç®€æŠ¥</h1>
        <p>å»ä¸­å¿ƒåŒ–èœ‚ç¾¤æ™ºèƒ½æŠ•èµ„ç ”ç©¶å¹³å° | {n_agents} ä¸ªè‡ªæ²»å·¥èœ‚ + äºŒé˜¶æ®µçœ‹ç©ºå¯¹å†²</p>
        <div class="update-time">{now_str} | {n_tickers} æ ‡çš„æ‰«æ | SEC çœŸå®æ•°æ® | æ•°æ®çœŸå®åº¦ {avg_real}</div>
    </div>
    <div class="main-grid">
        <div class="section">
            <h2>ä»Šæ—¥ Top 6 æœºä¼š</h2>
            <div class="opp-grid">{cards_html}
            </div>
        </div>
        <div>
            <div class="section" style="margin-bottom: 30px;">
                <div class="status-card">
                    <div class="status-hd">
                        <h3>ç³»ç»ŸçŠ¶æ€</h3>
                        <div class="status-ind"><div class="status-dot"></div>è¿è¡Œæ­£å¸¸</div>
                    </div>
                    <div class="si">
                        <div class="sr"><span class="sl">æ›´æ–°æ—¥æœŸ</span><span class="sv">{date_str}</span></div>
                        <div class="sr"><span class="sl">æœ€åæ›´æ–°</span><span class="sv">{now_str.split()[1]}</span></div>
                        <div class="sr"><span class="sl">æ‰«ææ ‡çš„</span><span class="sv">{n_tickers} ä¸ª</span></div>
                        <div class="sr"><span class="sl">Agent æ¶æ„</span><span class="sv">{n_agents} Agent + çœ‹ç©ºèœ‚</span></div>
                        <div class="sr"><span class="sl">å…±æŒ¯æ£€æµ‹</span><span class="sv" style="color:#28a745;">{n_resonance}/{n_tickers} æ ‡çš„</span></div>
                        <div class="sr"><span class="sl">æ•°æ®çœŸå®åº¦</span><span class="sv" style="color:#28a745;">{avg_real}</span></div>
                        <div class="sr"><span class="sl">SEC æ•°æ®</span><span class="sv" style="color:#28a745;">çœŸå® EDGAR API</span></div>
                    </div>
                </div>
            </div>
            <div class="section">
                <h2>ä»Šæ—¥æŠ¥å‘Š</h2>
                <div class="reports-list">
                    <div class="report-item">
                        <div class="report-date">{now_str} - èœ‚ç¾¤æ‰«æ ({n_tickers}æ ‡çš„)</div>
                        <div class="report-links">
                            <a href="alpha-hive-daily-{date_str}.md" class="rl md">å®Œæ•´ç®€æŠ¥</a>
                            <a href="alpha-hive-daily-{date_str}.json" class="rl" style="background:#764ba2;color:white;">JSON</a>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="section" style="margin-bottom: 30px;">
        <h2>å®Œæ•´æœºä¼šæ¸…å•</h2>
        <table class="full-table">
            <thead>
                <tr>
                    <th>#</th><th>æ ‡çš„</th><th>æ–¹å‘</th><th>ç»¼åˆåˆ†</th><th>å…±æŒ¯</th>
                    <th>æŠ•ç¥¨(å¤š/ç©º/ä¸­)</th><th>IV Rank</th><th>P/C Ratio</th><th>çœ‹ç©ºå¼ºåº¦</th><th>ML è¯¦æƒ…</th>
                </tr>
            </thead>
            <tbody>{rows_html}
            </tbody>
        </table>
    </div>
    <div class="footer">
        <p>Alpha Hive - å®Œå…¨è‡ªåŠ¨åŒ–èœ‚ç¾¤æ™ºèƒ½æŠ•èµ„ç ”ç©¶å¹³å°</p>
        <p>æœ€åæ›´æ–°ï¼š{now_str} | {n_tickers} æ ‡çš„èœ‚ç¾¤æ‰«æ | SEC çœŸå®æ•°æ® | æ•°æ®çœŸå®åº¦ {avg_real}</p>
        <p style="font-size:0.9em;margin-top:10px;opacity:0.8;">
            å£°æ˜ï¼šæœ¬æŠ¥å‘Šä¸º AI èœ‚ç¾¤è‡ªåŠ¨ç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚é¢„æµ‹å­˜åœ¨è¯¯å·®ï¼Œæ‰€æœ‰äº¤æ˜“å†³ç­–éœ€è‡ªè¡Œåˆ¤æ–­å’Œé£æ§ã€‚
        </p>
    </div>
</div>
</body>
</html>"""


def main():
    """ä¸»å…¥å£"""

    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(
        description="Alpha Hive æ¯æ—¥æŠ•èµ„ç®€æŠ¥ç”Ÿæˆå™¨",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•ï¼š
  # ä¼ ç»Ÿ ML æ¨¡å¼ï¼ˆé»˜è®¤ï¼‰
  python3 alpha_hive_daily_report.py
  python3 alpha_hive_daily_report.py --tickers NVDA TSLA VKTX
  python3 alpha_hive_daily_report.py --all-watchlist

  # èœ‚ç¾¤åä½œæ¨¡å¼ï¼ˆ7 ä¸ªè‡ªæ²»å·¥èœ‚ï¼š6 æ ¸å¿ƒ + BearBeeContrarianï¼‰
  python3 alpha_hive_daily_report.py --swarm --tickers NVDA TSLA VKTX
  python3 alpha_hive_daily_report.py --swarm --all-watchlist
        """
    )
    parser.add_argument(
        '--tickers',
        nargs='+',
        default=["NVDA", "TSLA", "VKTX", "META", "MSFT", "RKLB", "BILI"],
        help='è¦æ‰«æçš„è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼ˆç©ºæ ¼åˆ†éš”ï¼Œé»˜è®¤ï¼šNVDA TSLA VKTX META MSFT RKLB BILIï¼‰'
    )
    parser.add_argument(
        '--all-watchlist',
        action='store_true',
        help='æ‰«æé…ç½®ä¸­çš„å…¨éƒ¨ç›‘æ§åˆ—è¡¨'
    )
    parser.add_argument(
        '--swarm',
        action='store_true',
        help='å¯ç”¨èœ‚ç¾¤åä½œæ¨¡å¼ï¼ˆ7 ä¸ªè‡ªæ²»å·¥èœ‚ï¼š6 æ ¸å¿ƒå¹¶è¡Œ + BearBeeContrarian çœ‹ç©ºå¯¹å†²ï¼‰'
    )
    parser.add_argument(
        '--check-earnings',
        action='store_true',
        help='æ£€æŸ¥ä»Šæ—¥è´¢æŠ¥å¹¶è‡ªåŠ¨æ›´æ–°ç®€æŠ¥ï¼ˆå¯å•ç‹¬è¿è¡Œï¼Œä¸éœ€è¦é‡æ–°æ‰«æï¼‰'
    )

    args = parser.parse_args()

    # åˆ›å»ºæŠ¥å‘Šç”Ÿæˆå™¨
    reporter = AlphaHiveDailyReporter()

    # å¦‚æœåªæ˜¯æ£€æŸ¥è´¢æŠ¥æ›´æ–°
    if args.check_earnings:
        focus_tickers = list(WATCHLIST.keys())[:10] if args.all_watchlist else args.tickers
        result = reporter.check_earnings_updates(tickers=focus_tickers)
        reporting = result.get("reporting_today", [])
        updated = result.get("updated", [])
        if reporting:
            _log.info("ä»Šæ—¥è´¢æŠ¥: %s | å·²æ›´æ–°: %s", reporting, updated)
        else:
            _log.info("ä»Šæ—¥æ—  watchlist æ ‡çš„å‘å¸ƒè´¢æŠ¥")
        return result

    # ç¡®å®šæ‰«ææ ‡çš„
    focus_tickers = list(WATCHLIST.keys())[:10] if args.all_watchlist else args.tickers

    if args.swarm:
        report = reporter.run_swarm_scan(focus_tickers=focus_tickers)
    else:
        report = reporter.run_daily_scan(focus_tickers=focus_tickers)

    # ä¿å­˜æŠ¥å‘Šï¼ˆHive app é€šè¿‡ .swarm_results_{date}.json è‡ªåŠ¨åŒæ­¥ï¼‰
    report_path = reporter.save_report(report)
    _log.info("æŠ¥å‘Šå·²ä¿å­˜ï¼š%s", report_path)

    # ä¸‰ç«¯åŒæ­¥ï¼šGitHub æäº¤æ¨é€ + Hive App + Slack ä¸‹åˆ2ç‚¹ï¼ˆæ¸©å“¥å PSTï¼‰
    print("\nğŸ“¡ åŒæ­¥ä¸‰ç«¯ï¼šGitHub / Hive App / Slack...")
    try:
        sync_results = reporter.auto_commit_and_notify(report)
        git_ok = sync_results.get("git_push", {}).get("success", False)
        print(f"   GitHub push : {'âœ…' if git_ok else 'âš ï¸  å¤±è´¥ï¼ˆè§æ—¥å¿—ï¼‰'}")
        print(f"   Hive App    : âœ… .swarm_results å·²è½ç›˜ï¼Œä¸‹æ¬¡å¯åŠ¨è‡ªåŠ¨åŠ è½½")
    except (OSError, ValueError, KeyError, RuntimeError) as e:
        _log.warning("ä¸‰ç«¯åŒæ­¥éƒ¨åˆ†å¤±è´¥: %s", e)
        print(f"   âš ï¸  ä¸‰ç«¯åŒæ­¥å‡ºé”™ï¼š{e}")

    return report


if __name__ == "__main__":
    main()
