#!/usr/bin/env python3
"""
ğŸ Alpha Hive æ—¥æŠ¥ç”Ÿæˆå™¨ - é›†æˆæœŸæƒåˆ†æçš„å®Œæ•´ç‰ˆæœ¬
æ¯æ—¥è‡ªåŠ¨æ‰«æ watchlist å¹¶ç”Ÿæˆç»“æ„åŒ–æŠ•èµ„ç®€æŠ¥ + X çº¿ç¨‹ç‰ˆæœ¬
"""

import json
import os
import argparse
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple
from dataclasses import dataclass
from concurrent.futures import ThreadPoolExecutor
from threading import Lock

# å¯¼å…¥ç°æœ‰æ¨¡å—
from config import WATCHLIST, EVALUATION_WEIGHTS
from hive_logger import get_logger, PATHS, set_correlation_id

_log = get_logger("daily_report")

# Week 4: æŒ‡æ ‡æ”¶é›†å™¨
try:
    from metrics_collector import MetricsCollector
except ImportError:
    MetricsCollector = None
from generate_ml_report import MLEnhancedReportGenerator
from pheromone_board import PheromoneBoard
from swarm_agents import (
    ScoutBeeNova, OracleBeeEcho, BuzzBeeWhisper,
    ChronosBeeHorizon, RivalBeeVanguard, GuardBeeSentinel,
    QueenDistiller, prefetch_shared_data, inject_prefetched
)
from concurrent.futures import as_completed
from agent_toolbox import AgentHelper

# Phase 2: Import memory store
try:
    from memory_store import MemoryStore
except ImportError:
    MemoryStore = None

# Phase 3 P2: Import Calendar integrator
try:
    from calendar_integrator import CalendarIntegrator
except ImportError:
    CalendarIntegrator = None

# Phase 3 P4: Import Code Execution Agent
try:
    from code_executor_agent import CodeExecutorAgent
    from config import CODE_EXECUTION_CONFIG
except ImportError:
    CodeExecutorAgent = None
    CODE_EXECUTION_CONFIG = {"enabled": False}

# Phase 3 P5: Import CrewAI å¤š Agent æ¡†æ¶
try:
    from crewai_adapter import AlphaHiveCrew
    from config import CREWAI_CONFIG
except (ImportError, TypeError) as e:
    AlphaHiveCrew = None
    CREWAI_CONFIG = {"enabled": False}
    _log.info("CrewAI æ¨¡å—å¯¼å…¥å¤±è´¥: %s (é™çº§åˆ°åŸå§‹èœ‚ç¾¤)", type(e).__name__)

# Phase 3 P6: Import Slack æŠ¥å‘Šé€šçŸ¥å™¨ï¼ˆæ›¿ä»£ Gmailï¼‰
try:
    from slack_report_notifier import SlackReportNotifier
except ImportError:
    SlackReportNotifier = None

# Phase 3 å†…å­˜ä¼˜åŒ–: å‘é‡è®°å¿†å±‚ï¼ˆChroma é•¿æœŸè®°å¿†ï¼‰
try:
    from vector_memory import VectorMemory
    from config import VECTOR_MEMORY_CONFIG
except ImportError:
    VectorMemory = None
    VECTOR_MEMORY_CONFIG = {"enabled": False}

# Phase 6: å›æµ‹åé¦ˆå¾ªç¯
try:
    from backtester import Backtester, run_full_backtest
except ImportError:
    Backtester = None
    run_full_backtest = None


# å…è´£å£°æ˜å¸¸é‡ï¼ˆå»é‡ï¼Œå…¨å±€å¼•ç”¨ï¼‰
DISCLAIMER_FULL = (
    "æœ¬æŠ¥å‘Šä¸ºèœ‚ç¾¤ AI åˆ†æï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ï¼Œä¸æ›¿ä»£æŒç‰ŒæŠ•é¡¾ã€‚"
    "é¢„æµ‹å­˜åœ¨è¯¯å·®ï¼Œæ‰€æœ‰äº¤æ˜“å†³ç­–éœ€è‡ªè¡Œåˆ¤æ–­å’Œé£æ§ã€‚"
)
DISCLAIMER_SHORT = "éæŠ•èµ„å»ºè®®ï¼Œä»…æ•°æ®åˆ†æä¸æƒ…æ™¯æ¨æ¼”ã€‚"


@dataclass
class OpportunityItem:
    """æœºä¼šé¡¹ç›®ç»“æ„"""
    ticker: str
    direction: str  # "çœ‹å¤š" / "çœ‹ç©º" / "ä¸­æ€§"
    signal_score: float  # 0-10
    catalyst_score: float  # 0-10
    sentiment_score: float  # 0-10
    odds_score: float  # 0-10
    risk_score: float  # 0-10
    options_score: float  # 0-10 (æ–°å¢)
    opportunity_score: float  # 0-10 (ç»¼åˆ)
    confidence: float  # 0-100%
    key_catalysts: List[str]
    options_signal: str  # æœŸæƒä¿¡å·æ‘˜è¦
    risks: List[str]
    thesis_break: str  # å¤±æ•ˆæ¡ä»¶


class AlphaHiveDailyReporter:
    """Alpha Hive æ—¥æŠ¥ç”Ÿæˆå¼•æ“"""

    def __init__(self):
        self.report_dir = PATHS.home
        self.timestamp = datetime.now()
        self.date_str = self.timestamp.strftime("%Y-%m-%d")

        # åˆå§‹åŒ–æŠ¥å‘Šç”Ÿæˆå™¨
        self.ml_generator = MLEnhancedReportGenerator()

        # åˆå§‹åŒ– Agent å·¥å…·é›†ï¼ˆæ–°å¢ï¼‰
        self.agent_helper = AgentHelper()

        # Phase 2: åˆå§‹åŒ–æŒä¹…åŒ–è®°å¿†å­˜å‚¨
        self.memory_store = None
        self._session_id = None
        if MemoryStore:
            try:
                self.memory_store = MemoryStore()
                self._session_id = self.memory_store.generate_session_id(run_mode="daily_scan")
            except Exception as e:
                _log.warning("MemoryStore åˆå§‹åŒ–å¤±è´¥ï¼Œç»§ç»­è¿è¡Œ: %s", e)

        # ç»“æœå­˜å‚¨
        self.opportunities: List[OpportunityItem] = []
        self.observations: List[Dict] = []
        self.risks: List[Dict] = []

        # çº¿ç¨‹å®‰å…¨é”ï¼ˆç”¨äºå¹¶è¡Œæ‰§è¡Œæ—¶ä¿æŠ¤å…±äº«æ•°æ®ï¼‰
        self._results_lock = Lock()

        # Phase 3 P2: åˆå§‹åŒ– Google Calendar é›†æˆï¼ˆå¤±è´¥æ—¶é™çº§ï¼‰
        self.calendar = None
        if CalendarIntegrator:
            try:
                self.calendar = CalendarIntegrator()
            except Exception as e:
                _log.warning("Calendar åˆå§‹åŒ–å¤±è´¥: %s", e)

        # Phase 3 P4: åˆå§‹åŒ–ä»£ç æ‰§è¡Œ Agentï¼ˆå¤±è´¥æ—¶é™çº§ï¼‰
        self.code_executor_agent = None
        if CodeExecutorAgent and CODE_EXECUTION_CONFIG.get("enabled"):
            try:
                self.code_executor_agent = CodeExecutorAgent(board=None)
                # board åœ¨ run_swarm_scan æ—¶æ³¨å…¥
            except Exception as e:
                _log.warning("CodeExecutorAgent åˆå§‹åŒ–å¤±è´¥: %s", e)

        # Phase 3 å†…å­˜ä¼˜åŒ–: åˆå§‹åŒ–å‘é‡è®°å¿†å±‚ï¼ˆChroma é•¿æœŸè®°å¿†ï¼‰
        self.vector_memory = None
        if VectorMemory and VECTOR_MEMORY_CONFIG.get("enabled"):
            try:
                self.vector_memory = VectorMemory(
                    db_path=VECTOR_MEMORY_CONFIG.get("db_path"),
                    retention_days=VECTOR_MEMORY_CONFIG.get("retention_days", 90)
                )
                if self.vector_memory.enabled:
                    if VECTOR_MEMORY_CONFIG.get("cleanup_on_startup"):
                        self.vector_memory.cleanup()
            except Exception as e:
                _log.warning("å‘é‡è®°å¿†åˆå§‹åŒ–å¤±è´¥: %s", e)

        # Week 4: æŒ‡æ ‡æ”¶é›†å™¨
        self.metrics = None
        if MetricsCollector:
            try:
                self.metrics = MetricsCollector()
            except Exception as e:
                _log.warning("MetricsCollector åˆå§‹åŒ–å¤±è´¥: %s", e)

        # Phase 2: å…±äº«çº¿ç¨‹æ± ï¼ˆæ›¿ä»£æ‰€æœ‰ daemon çº¿ç¨‹ï¼Œé€€å‡ºæ—¶ç­‰å¾…å®Œæˆï¼‰
        import atexit
        self._bg_executor = ThreadPoolExecutor(max_workers=3, thread_name_prefix="hive_bg")
        self._bg_futures = []
        atexit.register(self._shutdown_bg)

        # Phase 3 P6: åˆå§‹åŒ– Slack æŠ¥å‘Šé€šçŸ¥å™¨ï¼ˆæ›¿ä»£ Gmailï¼‰
        self.slack_notifier = None
        if SlackReportNotifier:
            try:
                self.slack_notifier = SlackReportNotifier()
                pass  # Slack å°±ç»ª
            except Exception as e:
                _log.warning("Slack é€šçŸ¥å™¨åˆå§‹åŒ–å¤±è´¥: %s", e)

    def _shutdown_bg(self) -> None:
        """atexit å¤„ç†å™¨ï¼šç­‰å¾…åå°ä»»åŠ¡å®Œæˆ"""
        for f in self._bg_futures:
            try:
                f.result(timeout=10)
            except Exception:
                pass
        self._bg_executor.shutdown(wait=True)

    def _submit_bg(self, fn, *args) -> None:
        """æäº¤åå°ä»»åŠ¡åˆ°å…±äº«çº¿ç¨‹æ± ï¼ˆæ›¿ä»£ daemon çº¿ç¨‹ï¼‰"""
        future = self._bg_executor.submit(fn, *args)
        self._bg_futures.append(future)
        # æ¸…ç†å·²å®Œæˆçš„ futuresï¼ˆé˜²æ­¢å†…å­˜æ³„æ¼ï¼‰
        self._bg_futures = [f for f in self._bg_futures if not f.done()]

    def _analyze_ticker_safe(self, ticker: str, index: int, total: int) -> Tuple[str, OpportunityItem, str]:
        """
        åˆ†æå•ä¸ªæ ‡çš„ï¼ˆçº¿ç¨‹å®‰å…¨ï¼Œå¯åœ¨å¹¶è¡Œä¸Šä¸‹æ–‡ä¸­è°ƒç”¨ï¼‰

        Args:
            ticker: è‚¡ç¥¨ä»£ç 
            index: å½“å‰ç´¢å¼•ï¼ˆç”¨äºæ˜¾ç¤ºè¿›åº¦ï¼‰
            total: æ€»æ•°ï¼ˆç”¨äºæ˜¾ç¤ºè¿›åº¦ï¼‰

        Returns:
            (ticker, opportunity_item_or_none, error_message_or_none)
        """
        try:
            # æ„å»ºæœ€å°åŒ–çš„å®æ—¶æ•°æ®ç»“æ„
            realtime_metrics = {
                "ticker": ticker,
                "sources": {
                    "yahoo_finance": {
                        "current_price": 100.0,
                        "change_pct": 2.5
                    }
                }
            }

            # ç”Ÿæˆ ML å¢å¼ºæŠ¥å‘Š
            ml_report = self.ml_generator.generate_ml_enhanced_report(
                ticker, realtime_metrics
            )

            # è§£æä¸º OpportunityItem
            opportunity = self._parse_ml_report_to_opportunity(ticker, ml_report)

            # çº¿ç¨‹å®‰å…¨åœ°æ·»åŠ åˆ°ç»“æœåˆ—è¡¨
            with self._results_lock:
                self.opportunities.append(opportunity)

            return ticker, opportunity, None

        except Exception as e:
            error_msg = str(e)
            # çº¿ç¨‹å®‰å…¨åœ°æ·»åŠ è§‚å¯Ÿé¡¹
            with self._results_lock:
                self.observations.append({
                    "ticker": ticker,
                    "status": "error",
                    "error": error_msg
                })
            return ticker, None, error_msg

    def run_daily_scan(self, focus_tickers: List[str] = None) -> Dict:
        """
        æ‰§è¡Œæ¯æ—¥æ‰«æï¼ˆå¹¶è¡Œç‰ˆæœ¬ï¼‰

        Args:
            focus_tickers: é‡ç‚¹å…³æ³¨æ ‡çš„ï¼ˆå¦‚ä¸ºNoneåˆ™æ‰«æå…¨éƒ¨watchlistï¼‰

        Returns:
            å®Œæ•´çš„æ—¥æŠ¥æ•°æ®ç»“æ„
        """
        _log.info("Alpha Hive æ—¥æŠ¥ %s", self.date_str)

        targets = focus_tickers or list(WATCHLIST.keys())[:10]
        _log.info("æ ‡çš„ï¼š%s", " ".join(targets))

        start_parallel = time.time()

        with ThreadPoolExecutor(max_workers=len(targets)) as executor:
            futures = [
                executor.submit(self._analyze_ticker_safe, ticker, i + 1, len(targets))
                for i, ticker in enumerate(targets)
            ]

            for i, future in enumerate(futures, 1):
                ticker, opportunity, error = future.result()
                if error:
                    _log.warning("[%d/%d] %s åˆ†æå¤±è´¥: %s", i, len(targets), ticker, error[:60])
                else:
                    _log.info("[%d/%d] %s: %.1f/10", i, len(targets), ticker, opportunity.opportunity_score)

        elapsed_parallel = time.time() - start_parallel
        _log.info("åˆ†æè€—æ—¶ï¼š%.1fs", elapsed_parallel)

        # æ’åºæœºä¼š
        self.opportunities.sort(key=lambda x: x.opportunity_score, reverse=True)

        # æ„å»ºæŠ¥å‘Š
        report = self._build_report()

        # Phase 2: å¼‚æ­¥ä¿å­˜ä¼šè¯ï¼ˆä½¿ç”¨å…±äº«çº¿ç¨‹æ± ï¼Œé€€å‡ºæ—¶ç­‰å¾…å®Œæˆï¼‰
        if self.memory_store and self._session_id:
            self._submit_bg(
                self.memory_store.save_session,
                self._session_id, self.date_str, "daily_scan",
                targets, {}, [], elapsed_parallel
            )

        return report

    def run_swarm_scan(self, focus_tickers: List[str] = None) -> Dict:
        """
        çœŸæ­£çš„èœ‚ç¾¤åä½œæ‰«æ - 6 ä¸ª Agent å¹¶è¡Œè¿è¡Œï¼Œå®æ—¶é€šè¿‡ä¿¡æ¯ç´ æ¿äº¤æ¢å‘ç°

        Args:
            focus_tickers: é‡ç‚¹å…³æ³¨æ ‡çš„ï¼ˆå¦‚ä¸ºNoneåˆ™æ‰«æå…¨éƒ¨watchlistï¼‰

        Returns:
            å®Œæ•´çš„èœ‚ç¾¤åˆ†ææŠ¥å‘Š
        """
        # Week 4: è®¾ç½® correlation_id è¿½è¸ªæœ¬æ¬¡æ‰«æ
        set_correlation_id(self._session_id or f"swarm_{self.date_str}")
        _log.info("èœ‚ç¾¤åä½œå¯åŠ¨ %s", self.date_str)

        targets = focus_tickers or list(WATCHLIST.keys())[:10]
        _log.info("æ ‡çš„ï¼š%s", " ".join(targets))

        start_time = time.time()

        # åˆ›å»ºå…±äº«çš„ä¿¡æ¯ç´ æ¿
        board = PheromoneBoard(memory_store=self.memory_store, session_id=self._session_id)

        # å®ä¾‹åŒ– 6 ä¸ª Agent
        retriever = self.vector_memory if (self.vector_memory and self.vector_memory.enabled) else None
        agents = [
            ScoutBeeNova(board, retriever=retriever),
            OracleBeeEcho(board, retriever=retriever),
            BuzzBeeWhisper(board, retriever=retriever),
            ChronosBeeHorizon(board, retriever=retriever),
            RivalBeeVanguard(board, retriever=retriever),
            GuardBeeSentinel(board, retriever=retriever)
        ]

        # Phase 3 P4: åŠ¨æ€æ³¨å…¥ CodeExecutorAgent
        if self.code_executor_agent and CODE_EXECUTION_CONFIG.get("add_to_swarm"):
            self.code_executor_agent.board = board
            agents.append(self.code_executor_agent)

        # Phase 6: è‡ªé€‚åº”æƒé‡
        adapted_w = Backtester.load_adapted_weights() if Backtester else None
        queen = QueenDistiller(board, adapted_weights=adapted_w)

        _log.info("%d Agent | é¢„å–æ•°æ®ä¸­...", len(agents))

        # âš¡ ä¼˜åŒ– #1+#2: æ‰¹é‡é¢„å– yfinance + VectorMemoryï¼ˆæ¯ ticker ä»… 1 æ¬¡ï¼‰
        prefetched = prefetch_shared_data(targets, retriever)
        inject_prefetched(agents, prefetched)
        prefetch_elapsed = time.time() - start_time
        _log.info("é¢„å–å®Œæˆ (%.1fs) | å¼€å§‹å¹¶è¡Œåˆ†æ", prefetch_elapsed)

        # âš¡ ä¼˜åŒ– #3: å•å±‚çº¿ç¨‹æ± ï¼ŒæŒ‰ ticker ä¸²è¡Œã€Agent å¹¶è¡Œ
        swarm_results = {}

        # Phase 2: å´©æºƒæ¢å¤ checkpoint
        checkpoint_file = self.report_dir / f".checkpoint_{self._session_id or 'default'}.json"
        completed_tickers = set()
        if checkpoint_file.exists():
            try:
                with open(checkpoint_file, "r") as f:
                    ckpt = json.load(f)
                    swarm_results = ckpt.get("results", {})
                    completed_tickers = set(swarm_results.keys())
                    if completed_tickers:
                        _log.info("æ¢å¤ checkpointï¼š%d æ ‡çš„å·²å®Œæˆ", len(completed_tickers))
            except Exception:
                pass

        for idx, ticker in enumerate(targets, 1):
            if ticker in completed_tickers:
                res = "âœ…" if swarm_results[ticker]["resonance"]["resonance_detected"] else "â€”"
                _log.info("[%d/%d] %s: %.1f/10 (å·²ç¼“å­˜) %s", idx, len(targets), ticker, swarm_results[ticker]['final_score'], res)
                continue

            with ThreadPoolExecutor(max_workers=len(agents)) as executor:
                futures = {executor.submit(agent.analyze, ticker): agent for agent in agents}
                agent_results = []
                for future in as_completed(futures):
                    try:
                        agent_results.append(future.result(timeout=60))
                    except Exception:
                        agent_results.append(None)

            distilled = queen.distill(ticker, agent_results)
            swarm_results[ticker] = distilled

            res = "âœ…" if distilled["resonance"]["resonance_detected"] else "â€”"
            _log.info("[%d/%d] %s: %.1f/10 %s %s", idx, len(targets), ticker, distilled['final_score'], distilled['direction'], res)

            # å†™å…¥ checkpointï¼ˆæ¯ä¸ª ticker å®Œæˆåï¼‰
            try:
                with open(checkpoint_file, "w") as f:
                    json.dump({"results": swarm_results, "targets": targets}, f, default=str)
            except Exception:
                pass

        # æ‰«æå®Œæˆï¼Œæ¸…ç† checkpoint
        try:
            checkpoint_file.unlink(missing_ok=True)
        except Exception:
            pass

        elapsed = time.time() - start_time

        # LLM Token ä½¿ç”¨ç»Ÿè®¡
        try:
            import llm_service
            usage = llm_service.get_usage()
            if usage["call_count"] > 0:
                _log.info("èœ‚ç¾¤è€—æ—¶ï¼š%.1fs | LLM: %dè°ƒç”¨ $%.4f", elapsed, usage['call_count'], usage['total_cost_usd'])
            else:
                _log.info("èœ‚ç¾¤è€—æ—¶ï¼š%.1fs | è§„åˆ™å¼•æ“æ¨¡å¼", elapsed)
        except Exception:
            _log.info("èœ‚ç¾¤è€—æ—¶ï¼š%.1fs", elapsed)

        # Week 4: è®°å½•æ‰«ææŒ‡æ ‡ + SLO æ£€æŸ¥
        if self.metrics:
            try:
                scores = [d.get("final_score", 5.0) for d in swarm_results.values()]
                agent_errors = sum(
                    1 for d in swarm_results.values()
                    if d.get("supporting_agents", 0) == 0
                )
                resonance_n = sum(
                    1 for d in swarm_results.values()
                    if d.get("resonance", {}).get("resonance_detected")
                )
                avg_real = (
                    sum(d.get("data_real_pct", 0) for d in swarm_results.values()) / len(swarm_results)
                    if swarm_results else 0
                )
                llm_c, llm_cost = 0, 0.0
                try:
                    import llm_service as _ls
                    _u = _ls.get_usage()
                    llm_c, llm_cost = _u.get("call_count", 0), _u.get("total_cost_usd", 0.0)
                except Exception:
                    pass

                self.metrics.record_scan(
                    ticker_count=len(swarm_results),
                    duration_seconds=elapsed,
                    agent_count=len(agents),
                    prefetch_seconds=prefetch_elapsed,
                    avg_score=sum(scores) / len(scores) if scores else 5.0,
                    max_score=max(scores) if scores else 5.0,
                    min_score=min(scores) if scores else 5.0,
                    agent_errors=agent_errors,
                    agent_total=len(swarm_results) * len(agents),
                    data_real_pct=avg_real,
                    resonance_count=resonance_n,
                    llm_calls=llm_c,
                    llm_cost_usd=llm_cost,
                    session_id=self._session_id or "",
                    scan_mode="swarm",
                )
                for ticker, data in swarm_results.items():
                    self.metrics.record_ticker(
                        ticker=ticker,
                        final_score=data.get("final_score", 5.0),
                        direction=data.get("direction", "neutral"),
                        supporting_agents=data.get("supporting_agents", 0),
                        data_real_pct=data.get("data_real_pct", 0),
                        resonance_detected=data.get("resonance", {}).get("resonance_detected", False),
                        session_id=self._session_id or "",
                    )

                # SLO æ£€æŸ¥
                violations = self.metrics.check_slo(days=1)
                if violations:
                    _log.warning("SLO è¿è§„ %d æ¡: %s",
                                 len(violations),
                                 "; ".join(v["details"] for v in violations))
            except Exception as e:
                _log.warning("æŒ‡æ ‡æ”¶é›†å¼‚å¸¸: %s", e)

        # Phase 6: å›æµ‹åé¦ˆå¾ªç¯
        if Backtester:
            try:
                bt = Backtester()
                bt.save_predictions(swarm_results)
                bt.run_backtest()
                bt.adapt_weights(min_samples=5)
            except Exception as e:
                _log.warning("å›æµ‹å¼‚å¸¸: %s", e)

        # Phase 6: Slack æ¨é€é«˜åˆ†æœºä¼š + å¼‚å¸¸ä¿¡å·
        if self.slack_notifier and self.slack_notifier.enabled:
            for ticker, data in swarm_results.items():
                score = data.get("final_score", 0)
                direction = data.get("direction", "neutral")
                dir_cn = {"bullish": "çœ‹å¤š", "bearish": "çœ‹ç©º", "neutral": "ä¸­æ€§"}.get(direction, direction)

                # é«˜åˆ†æœºä¼šæ¨é€ï¼ˆ>= 7.5ï¼‰
                if score >= 7.5:
                    self._submit_bg(
                        self.slack_notifier.send_opportunity_alert,
                        ticker, score, dir_cn,
                        data.get("discovery", "é«˜åˆ†æœºä¼š"),
                        [f"è¯„åˆ† {score:.1f}/10"]
                    )

                # å¼‚å¸¸ä¿¡å·æ¨é€ï¼šå¼ºçœ‹ç©º æˆ– å†…å¹•å¤§é¢äº¤æ˜“
                elif score <= 3.0:
                    self._submit_bg(
                        self.slack_notifier.send_risk_alert,
                        f"{ticker} ä½åˆ†é¢„è­¦",
                        f"èœ‚ç¾¤è¯„åˆ†ä»… {score:.1f}/10ï¼Œæ–¹å‘ {dir_cn}",
                        "HIGH"
                    )

        # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        report = self._build_swarm_report(swarm_results, board)

        # Phase 3 P2: ä¸ºé«˜åˆ†æœºä¼šæ·»åŠ æ—¥å†æé†’ï¼ˆåå°çº¿ç¨‹æ± ï¼Œé€€å‡ºæ—¶ç­‰å¾…å®Œæˆï¼‰
        if self.calendar and report.get('opportunities'):
            for opp in report['opportunities']:
                if opp.opportunity_score >= 7.5:
                    self._submit_bg(
                        self.calendar.add_opportunity_reminder,
                        opp.ticker, opp.opportunity_score, opp.direction,
                        f"{opp.key_catalysts[0] if opp.key_catalysts else 'é«˜åˆ†æœºä¼š'}"
                    )

        # Phase 2: å¼‚æ­¥ä¿å­˜ä¼šè¯ï¼ˆä½¿ç”¨å…±äº«çº¿ç¨‹æ± ï¼Œé€€å‡ºæ—¶ç­‰å¾…å®Œæˆï¼‰
        if self.memory_store and self._session_id:
            snapshot = board.compact_snapshot()  # åœ¨ä¸»çº¿ç¨‹å–å¿«ç…§ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
            self._submit_bg(
                self.memory_store.save_session,
                self._session_id, self.date_str, "swarm",
                targets, swarm_results, snapshot, elapsed
            )

        # Phase 3 å†…å­˜ä¼˜åŒ–: å°†é«˜ä»·å€¼å‘ç°å­˜å…¥å‘é‡è®°å¿†ï¼ˆé•¿æœŸè®°å¿†ï¼‰
        if self.vector_memory and self.vector_memory.enabled:
            stored = 0
            # 1. å­˜å‚¨ Queen çš„æœ€ç»ˆè¯„åˆ†
            for ticker, data in swarm_results.items():
                if data.get("final_score", 0) >= 5.0:
                    self.vector_memory.store(
                        ticker=ticker,
                        agent_id="QueenDistiller",
                        discovery=f"è¯„åˆ†{data['final_score']:.1f} {data['direction']} "
                                  f"æ”¯æŒ{data.get('supporting_agents', 0)}Agent",
                        direction=data["direction"],
                        score=data["final_score"],
                        source="swarm_scan",
                        session_id=self._session_id or ""
                    )
                    stored += 1
            # 2. å­˜å‚¨ä¿¡æ¯ç´ æ¿ä¸Šæ¯ä¸ª Agent çš„é«˜ä»·å€¼å‘ç°
            for entry in board.snapshot():
                if entry.get("self_score", 0) >= 6.0:
                    self.vector_memory.store(
                        ticker=entry.get("ticker", ""),
                        agent_id=entry.get("agent_id", ""),
                        discovery=entry.get("discovery", "")[:300],
                        direction=entry.get("direction", "neutral"),
                        score=entry.get("self_score", 5.0),
                        source=entry.get("source", ""),
                        session_id=self._session_id or ""
                    )
                    stored += 1
            if stored > 0:
                _log.info("å·²å­˜å…¥ %d æ¡é•¿æœŸè®°å¿† (Chroma)", stored)

        # Slack æ¨é€
        if self.slack_notifier and self.slack_notifier.enabled:
            try:
                self.slack_notifier.send_daily_report(report)
                _log.info("Slack æ—¥æŠ¥å·²å‘é€")
            except Exception as e:
                _log.error("Slack æ—¥æŠ¥å‘é€å¤±è´¥: %s", e, exc_info=True)

        return report

    def run_crew_scan(self, focus_tickers: List[str] = None) -> Dict:
        """
        CrewAI æ¨¡å¼èœ‚ç¾¤æ‰«æ - ä½¿ç”¨ Process.hierarchical ä¸»-å­ Agent é€’å½’è°ƒåº¦
        è‹¥ crewai æœªå®‰è£…ï¼Œè‡ªåŠ¨é™çº§åˆ° run_swarm_scan()

        Args:
            focus_tickers: é‡ç‚¹å…³æ³¨æ ‡çš„ï¼ˆå¦‚ä¸ºNoneåˆ™æ‰«æå…¨éƒ¨watchlistï¼‰

        Returns:
            å®Œæ•´çš„èœ‚ç¾¤åˆ†ææŠ¥å‘Š
        """
        # æ£€æŸ¥ CrewAI æ˜¯å¦å¯ç”¨
        if not AlphaHiveCrew or not CREWAI_CONFIG.get("enabled"):
            _log.info("CrewAI æœªå®‰è£…æˆ–æœªå¯ç”¨ï¼Œé™çº§åˆ°æ ‡å‡†èœ‚ç¾¤æ¨¡å¼")
            return self.run_swarm_scan(focus_tickers)

        _log.info("CrewAI æ¨¡å¼ %s", self.date_str)

        targets = focus_tickers or list(WATCHLIST.keys())[:10]
        _log.info("æ ‡çš„ï¼š%s", " ".join(targets))

        # åˆ›å»ºå…±äº«çš„ä¿¡æ¯ç´ æ¿
        board = PheromoneBoard(memory_store=self.memory_store, session_id=self._session_id)

        # æ„å»º CrewAI Crew
        crew = AlphaHiveCrew(board=board, memory_store=self.memory_store)
        crew.build(targets)

        _log.info("CrewAI %d Agent", crew.get_agents_count())

        swarm_results = {}
        start_time = time.time()

        # ä½¿ç”¨ CrewAI åˆ†ææ¯ä¸ªæ ‡çš„
        for i, ticker in enumerate(targets, 1):
            _log.info("[%d/%d] CrewAI åˆ†æ %s", i, len(targets), ticker)

            try:
                result = crew.analyze(ticker)
                swarm_results[ticker] = result

                _log.info("  %s: %.1f/10 %s", ticker, result.get('final_score', 0), result.get('direction', 'neutral'))

            except Exception as e:
                _log.warning("  %s åˆ†æå¤±è´¥: %s", ticker, str(e)[:80])
                swarm_results[ticker] = {
                    "ticker": ticker,
                    "final_score": 0.0,
                    "direction": "neutral",
                    "discovery": f"CrewAI åˆ†æå¤±è´¥: {str(e)}",
                    "error": str(e)
                }

        elapsed = time.time() - start_time
        _log.info("CrewAI è€—æ—¶ï¼š%.1fs", elapsed)

        # è½¬æ¢ä¸ºæ ‡å‡†æŠ¥å‘Šæ ¼å¼ï¼ˆå…¼å®¹ run_swarm_scan è¾“å‡ºï¼‰
        report = self._build_swarm_report(swarm_results, board)

        # å¼‚æ­¥ä¿å­˜ä¼šè¯ï¼ˆä½¿ç”¨å…±äº«çº¿ç¨‹æ± ï¼Œé€€å‡ºæ—¶ç­‰å¾…å®Œæˆï¼‰
        if self.memory_store and self._session_id:
            snapshot = board.compact_snapshot()
            self._submit_bg(
                self.memory_store.save_session,
                self._session_id, self.date_str, "crew_scan",
                targets, swarm_results, snapshot, elapsed
            )

        # Slack æ¨é€
        if self.slack_notifier and self.slack_notifier.enabled:
            try:
                self.slack_notifier.send_daily_report(report)
                _log.info("Slack æ—¥æŠ¥å·²å‘é€")
            except Exception as e:
                _log.error("Slack æ—¥æŠ¥å‘é€å¤±è´¥: %s", e, exc_info=True)

        return report

    def _build_swarm_report(self, swarm_results: Dict, board: PheromoneBoard) -> Dict:
        """
        å°†èœ‚ç¾¤åˆ†æç»“æœè½¬æ¢ä¸ºæ ‡å‡†æŠ¥å‘Šæ ¼å¼

        Args:
            swarm_results: QueenDistiller çš„æ‰€æœ‰æ±‡æ€»ç»“æœ
            board: ä¿¡æ¯ç´ æ¿ï¼ˆç”¨äºæå–å…¨å±€ä¿¡æ¯ï¼‰

        Returns:
            æ ‡å‡†æŠ¥å‘Šæ ¼å¼
        """
        # æ’åºç»“æœ
        sorted_results = sorted(
            swarm_results.items(),
            key=lambda x: x[1]["final_score"],
            reverse=True
        )

        # æ„å»º OpportunityItem åˆ—è¡¨ï¼ˆå…¼å®¹ç°æœ‰æŠ¥å‘Šæ ¼å¼ï¼‰
        opportunities = []
        for ticker, swarm_data in sorted_results:
            opp = OpportunityItem(
                ticker=ticker,
                direction="çœ‹å¤š" if swarm_data["direction"] == "bullish" else (
                    "çœ‹ç©º" if swarm_data["direction"] == "bearish" else "ä¸­æ€§"
                ),
                signal_score=swarm_data["final_score"],
                catalyst_score=swarm_data["final_score"] * 0.9,
                sentiment_score=swarm_data["final_score"] * 0.85,
                odds_score=swarm_data["final_score"] * 0.8,
                risk_score=swarm_data["final_score"] * 0.95,
                options_score=swarm_data["final_score"] * 0.88,
                opportunity_score=swarm_data["final_score"],
                confidence=min(95, swarm_data["final_score"] * 10) if swarm_data["final_score"] >= 7.5 else 60,
                key_catalysts=["å¤š Agent å…±æŒ¯ä¿¡å·"] if swarm_data["resonance"]["resonance_detected"] else ["å¾…éªŒè¯"],
                options_signal=f"å…±æŒ¯ä¿¡å· ({swarm_data['resonance']['supporting_agents']} Agent)",
                risks=["å¤šå¤´æ‹¥æŒ¤"] if swarm_data["resonance"]["resonance_detected"] else [],
                thesis_break="ä¿¡å·åˆ†æ•£"
            )
            opportunities.append(opp)

        self.opportunities = opportunities

        # æ„å»ºæ ‡å‡†æŠ¥å‘Š
        report = {
            "date": self.date_str,
            "timestamp": self.timestamp.isoformat(),
            "system_status": "âœ… èœ‚ç¾¤åä½œå®Œæˆ",
            "phase_completed": "å®Œæ•´èœ‚ç¾¤æµç¨‹ (Swarm Mode)",
            "swarm_metadata": {
                "total_agents": 6,
                "tickers_analyzed": len(swarm_results),
                "resonances_detected": sum(1 for r in swarm_results.values() if r["resonance"]["resonance_detected"]),
                "pheromone_board_entries": board.get_entry_count()
            },
            "markdown_report": self._generate_swarm_markdown_report(swarm_results),
            "twitter_threads": self._generate_swarm_twitter_threads(swarm_results),
            "opportunities": [
                {
                    "rank": i + 1,
                    "ticker": opp.ticker,
                    "direction": opp.direction,
                    "opp_score": round(opp.opportunity_score, 1),
                    "confidence": f"{opp.confidence:.0f}%",
                    "resonance": swarm_results[opp.ticker]["resonance"]["resonance_detected"],
                    "supporting_agents": swarm_results[opp.ticker]["supporting_agents"],
                    "thesis_break": opp.thesis_break
                }
                for i, opp in enumerate(self.opportunities[:5])
            ]
        }

        return report

    def _generate_swarm_markdown_report(self, swarm_results: Dict) -> str:
        """ç”Ÿæˆèœ‚ç¾¤æ¨¡å¼çš„ Markdown æŠ¥å‘Šï¼ˆ8 ç‰ˆå—å®Œæ•´ç»“æ„ï¼‰"""

        md = []
        md.append(f"# ã€{self.date_str}ã€‘Alpha Hive èœ‚ç¾¤åä½œæ—¥æŠ¥")
        md.append("")
        md.append(f"**è‡ªåŠ¨ç”Ÿæˆäº**ï¼š{self.timestamp.strftime('%Y-%m-%d %H:%M:%S')}")
        md.append(f"**ç³»ç»Ÿæ¨¡å¼**ï¼šå®Œå…¨å»ä¸­å¿ƒåŒ–èœ‚ç¾¤åä½œ | 6 ä¸ªè‡ªæ²» Agent")
        md.append("")

        sorted_results = sorted(
            swarm_results.items(),
            key=lambda x: x[1]["final_score"],
            reverse=True
        )

        # ====== ç‰ˆå— 1ï¼šä»Šæ—¥æ‘˜è¦ ======
        resonances = sum(1 for r in swarm_results.values() if r["resonance"]["resonance_detected"])
        md.append("## 1) ä»Šæ—¥æ‘˜è¦")
        md.append("")
        md.append(f"- æ‰«ææ ‡çš„ï¼š{len(swarm_results)} ä¸ª | å…±æŒ¯ä¿¡å·ï¼š{resonances}/{len(swarm_results)}")
        for i, (ticker, data) in enumerate(sorted_results[:3], 1):
            res = "å…±æŒ¯" if data["resonance"]["resonance_detected"] else ""
            md.append(f"- **{ticker}** {data['direction'].upper()} {data['final_score']:.1f}/10 {res}")
        md.append("")

        # ====== ç‰ˆå— 2ï¼šä»Šæ—¥èªæ˜é’±åŠ¨å‘ï¼ˆScoutBeeNovaï¼‰ ======
        md.append("## 2) ä»Šæ—¥èªæ˜é’±åŠ¨å‘")
        md.append("")
        for ticker, data in sorted_results:
            agent = data.get("agent_details", {}).get("ScoutBeeNova", {})
            discovery = agent.get("discovery", "")
            details = agent.get("details", {})
            insider = details.get("insider", {})
            md.append(f"### {ticker}")
            if discovery:
                md.append(f"- {discovery}")
            if insider:
                sentiment = insider.get("sentiment", "unknown")
                bought = insider.get("dollar_bought", 0)
                sold = insider.get("dollar_sold", 0)
                filings = insider.get("filings", 0)
                md.append(f"- å†…å¹•äº¤æ˜“æƒ…ç»ªï¼š**{sentiment}** | ç”³æŠ¥æ•°ï¼š{filings}")
                if bought > 0:
                    md.append(f"- å†…å¹•ä¹°å…¥é‡‘é¢ï¼š${bought:,.0f}")
                if sold > 0:
                    md.append(f"- å†…å¹•å–å‡ºé‡‘é¢ï¼š${sold:,.0f}")
                notable = insider.get("notable_trades", [])
                for t in notable[:2]:
                    if isinstance(t, dict):
                        md.append(f"  - {t.get('insider', '?')}ï¼š{t.get('code_desc', '?')} {t.get('shares', 0):,.0f} è‚¡")
            crowding = details.get("crowding_score", "")
            if crowding:
                md.append(f"- æ‹¥æŒ¤åº¦ï¼š{crowding:.0f}/100")
            md.append("")

        # ====== ç‰ˆå— 3ï¼šå¸‚åœºéšå«é¢„æœŸï¼ˆOracleBeeEchoï¼‰ ======
        md.append("## 3) å¸‚åœºéšå«é¢„æœŸ")
        md.append("")
        for ticker, data in sorted_results:
            agent = data.get("agent_details", {}).get("OracleBeeEcho", {})
            discovery = agent.get("discovery", "")
            details = agent.get("details", {})
            md.append(f"### {ticker}")
            if discovery:
                md.append(f"- {discovery}")
            if isinstance(details, dict) and details:
                iv = details.get("iv_rank")
                pc = details.get("put_call_ratio")
                gamma = details.get("gamma_exposure")
                if iv is not None:
                    md.append(f"- IV Rankï¼š{iv}")
                if pc is not None:
                    pc_val = pc if isinstance(pc, (int, float)) else pc
                    md.append(f"- Put/Call Ratioï¼š{pc_val}")
                if gamma is not None:
                    md.append(f"- Gamma Exposureï¼š{gamma}")
                # å¼‚å¸¸æ´»åŠ¨
                unusual = details.get("unusual_activity", [])
                if unusual:
                    md.append(f"- å¼‚å¸¸æ´»åŠ¨ï¼š{len(unusual)} ä¸ªä¿¡å·")
                    for u in unusual[:3]:
                        if isinstance(u, dict):
                            utype = u.get("type", "unknown").replace("_", " ")
                            strike = u.get("strike", "")
                            vol = u.get("volume", 0)
                            bull = "çœ‹æ¶¨" if u.get("bullish") else "çœ‹è·Œ"
                            md.append(f"  - {bull} {utype} ${strike} ({vol:,.0f}æ‰‹)")
                        elif isinstance(u, str):
                            md.append(f"  - {u}")
            md.append("")

        # ====== ç‰ˆå— 4ï¼šX æƒ…ç»ªæ±‡æ€»ï¼ˆBuzzBeeWhisperï¼‰ ======
        md.append("## 4) X æƒ…ç»ªæ±‡æ€»")
        md.append("")
        for ticker, data in sorted_results:
            agent = data.get("agent_details", {}).get("BuzzBeeWhisper", {})
            discovery = agent.get("discovery", "")
            details = agent.get("details", {})
            md.append(f"### {ticker}")
            if discovery:
                md.append(f"- {discovery}")
            if isinstance(details, dict) and details:
                sent_pct = details.get("sentiment_pct")
                mom = details.get("momentum_5d")
                vol = details.get("volume_ratio")
                if sent_pct is not None:
                    md.append(f"- çœ‹å¤šæƒ…ç»ªï¼š{sent_pct}%")
                if mom is not None:
                    md.append(f"- 5 æ—¥åŠ¨é‡ï¼š{mom:+.1f}%")
                if vol is not None:
                    md.append(f"- é‡æ¯”ï¼š{vol:.1f}x")
                reddit = details.get("reddit_mentions") or details.get("reddit_rank")
                if reddit:
                    md.append(f"- Reddit çƒ­åº¦ï¼š{reddit}")
            md.append("")

        # ====== ç‰ˆå— 5ï¼šè´¢æŠ¥/äº‹ä»¶å‚¬åŒ–å‰‚ï¼ˆChronosBeeHorizonï¼‰ ======
        md.append("## 5) è´¢æŠ¥/äº‹ä»¶å‚¬åŒ–å‰‚")
        md.append("")
        for ticker, data in sorted_results:
            agent = data.get("agent_details", {}).get("ChronosBeeHorizon", {})
            discovery = agent.get("discovery", "")
            details = agent.get("details", {})
            md.append(f"### {ticker}")
            if discovery:
                md.append(f"- {discovery}")
            if isinstance(details, dict) and details:
                earnings = details.get("next_earnings") or details.get("earnings_date")
                if earnings:
                    md.append(f"- ä¸‹æ¬¡è´¢æŠ¥ï¼š{earnings}")
                events = details.get("upcoming_events") or details.get("catalysts", [])
                if isinstance(events, list):
                    for ev in events[:3]:
                        if isinstance(ev, dict):
                            md.append(f"  - {ev.get('date', '?')}ï¼š{ev.get('event', ev.get('description', '?'))}")
                        elif isinstance(ev, str):
                            md.append(f"  - {ev}")
                past = details.get("recent_events", [])
                if isinstance(past, list):
                    for ev in past[:2]:
                        if isinstance(ev, dict):
                            md.append(f"  - [å·²å‘ç”Ÿ] {ev.get('description', ev)}")
            md.append("")

        # ====== ç‰ˆå— 6ï¼šç«äº‰æ ¼å±€åˆ†æï¼ˆRivalBeeVanguardï¼‰ ======
        md.append("## 6) ç«äº‰æ ¼å±€åˆ†æ")
        md.append("")
        for ticker, data in sorted_results:
            agent = data.get("agent_details", {}).get("RivalBeeVanguard", {})
            discovery = agent.get("discovery", "")
            details = agent.get("details", {})
            md.append(f"### {ticker}")
            if discovery:
                md.append(f"- {discovery}")
            if isinstance(details, dict) and details:
                ml_pred = details.get("ml_prediction") or details.get("prediction")
                if isinstance(ml_pred, dict):
                    md.append(f"- ML é¢„æµ‹æ–¹å‘ï¼š{ml_pred.get('direction', '?')}")
                    md.append(f"- ML ç½®ä¿¡åº¦ï¼š{ml_pred.get('confidence', '?')}")
                peers = details.get("peer_comparison") or details.get("peers", [])
                if isinstance(peers, list) and peers:
                    md.append(f"- åŒä¸šå¯¹æ ‡ï¼š{', '.join(str(p) for p in peers[:5])}")
            md.append("")

        # ====== ç‰ˆå— 7ï¼šç»¼åˆåˆ¤æ–­ & ä¿¡å·å¼ºåº¦ï¼ˆGuardBeeSentinel + å…¨ä½“æŠ•ç¥¨ï¼‰ ======
        md.append("## 7) ç»¼åˆåˆ¤æ–­ & ä¿¡å·å¼ºåº¦")
        md.append("")
        md.append("| æ ‡çš„ | æ–¹å‘ | ç»¼åˆåˆ† | å…±æŒ¯ | æŠ•ç¥¨(å¤š/ç©º/ä¸­) | æ•°æ®% | å¤±æ•ˆæ¡ä»¶ |")
        md.append("|------|------|--------|------|---------------|-------|---------|")
        for ticker, data in sorted_results:
            res = "Y" if data["resonance"]["resonance_detected"] else "N"
            ab = data["agent_breakdown"]
            data_pct = data.get("data_real_pct", 0)
            # ä» GuardBeeSentinel è·å–äº¤å‰éªŒè¯ä¿¡æ¯
            guard = data.get("agent_details", {}).get("GuardBeeSentinel", {})
            guard_discovery = guard.get("discovery", "")
            thesis_break = "ä¿¡å·åˆ†æ•£" if not guard_discovery else guard_discovery[:30]
            md.append(
                f"| **{ticker}** | {data['direction'].upper()} | "
                f"{data['final_score']:.1f} | {res} | "
                f"{ab['bullish']}/{ab['bearish']}/{ab['neutral']} | "
                f"{data_pct:.0f}% | {thesis_break} |"
            )
        md.append("")

        # GuardBeeSentinel è¯¦ç»†äº¤å‰éªŒè¯
        md.append("### äº¤å‰éªŒè¯è¯¦æƒ…")
        md.append("")
        for ticker, data in sorted_results:
            guard = data.get("agent_details", {}).get("GuardBeeSentinel", {})
            discovery = guard.get("discovery", "")
            if discovery:
                md.append(f"- **{ticker}**ï¼š{discovery}")
        md.append("")

        # ====== ç‰ˆå— 8ï¼šæ•°æ®æ¥æº & å…è´£å£°æ˜ ======
        md.append("## 8) æ•°æ®æ¥æº & å…è´£å£°æ˜")
        md.append("")
        md.append("**èœ‚ç¾¤åˆ†å·¥**ï¼š")
        md.append("- ScoutBeeNovaï¼šèªæ˜é’±ä¾¦å¯Ÿï¼ˆSEC Form 4/13F + æ‹¥æŒ¤åº¦ï¼‰")
        md.append("- OracleBeeEchoï¼šå¸‚åœºé¢„æœŸï¼ˆæœŸæƒ IV/P-C Ratio/Gammaï¼‰")
        md.append("- BuzzBeeWhisperï¼šç¤¾äº¤æƒ…ç»ªï¼ˆX/Reddit/Finvizï¼‰")
        md.append("- ChronosBeeHorizonï¼šå‚¬åŒ–å‰‚è¿½è¸ªï¼ˆè´¢æŠ¥/äº‹ä»¶æ—¥å†ï¼‰")
        md.append("- RivalBeeVanguardï¼šç«äº‰æ ¼å±€ï¼ˆML é¢„æµ‹ + è¡Œä¸šå¯¹æ ‡ï¼‰")
        md.append("- GuardBeeSentinelï¼šäº¤å‰éªŒè¯ï¼ˆå…±æŒ¯æ£€æµ‹ + é£é™©è°ƒæ•´ï¼‰")
        md.append("")
        md.append("**å…è´£å£°æ˜**ï¼š")
        md.append(DISCLAIMER_FULL)
        md.append("")

        return "\n".join(md)

    def _generate_swarm_twitter_threads(self, swarm_results: Dict) -> List[str]:
        """ç”Ÿæˆèœ‚ç¾¤æ¨¡å¼çš„ X çº¿ç¨‹ç‰ˆæœ¬"""

        threads = []
        sorted_results = sorted(
            swarm_results.items(),
            key=lambda x: x[1]["final_score"],
            reverse=True
        )

        # ä¸»çº¿ç¨‹
        main_thread = []
        main_thread.append(
            f"ã€Alpha Hive èœ‚ç¾¤æ—¥æŠ¥ {self.date_str}ã€‘"
            f"6 ä¸ªè‡ªæ²» Agent åä½œåˆ†æï¼Œå¤šæ•°æŠ•ç¥¨å…±æŒ¯ä¿¡å·ã€‚"
            f"{DISCLAIMER_SHORT}ğŸ‘‡"
        )

        for i, (ticker, data) in enumerate(sorted_results[:3], 1):
            resonance_emoji = "âœ…" if data["resonance"]["resonance_detected"] else "âŒ"
            insight = data.get("key_insight", "")
            tweet = (
                f"{i}. **{ticker}** {data['direction'].upper()}\n"
                f"èœ‚ç¾¤è¯„åˆ†ï¼š{data['final_score']:.1f}/10 | å…±æŒ¯ï¼š{resonance_emoji}\n"
                f"Agent æŠ•ç¥¨ï¼šçœ‹å¤š{data['agent_breakdown']['bullish']} vs çœ‹ç©º{data['agent_breakdown']['bearish']}"
            )
            if insight:
                tweet += f"\nAIæ´å¯Ÿï¼š{insight}"
            main_thread.append(tweet)

        main_thread.append(
            f"ğŸ 6 ä¸ª Agent ç‹¬ç«‹åˆ†æ â†’ ä¿¡æ¯ç´ æ¿å®æ—¶äº¤æ¢ â†’ å¤šæ•°æŠ•ç¥¨æ±‡æ€»\n"
            f"é«˜å…±æŒ¯ä¿¡å·ä¼˜å…ˆçº§æœ€é«˜ã€‚é£é™©æç¤ºï¼šæ§åˆ¶ä»“ä½ã€‚\n"
            f"ä¸‹ä¸€æ­¥ï¼šT+1 éªŒè¯ï¼ŒT+7 å›çœ‹å‡†ç¡®ç‡ã€‚@igg_wang748"
        )

        threads.append("\n\n".join(main_thread))

        return threads

    def _parse_ml_report_to_opportunity(self, ticker: str, ml_report: Dict) -> OpportunityItem:
        """å°† ML æŠ¥å‘Šè§£æä¸º OpportunityItem"""

        adv = ml_report.get("advanced_analysis", {})
        opts = adv.get("options_analysis")
        ml_pred = ml_report.get("ml_prediction", {})

        # æå–å„ç»´åº¦è¯„åˆ†ï¼ˆå‡è®¾å·²æ ‡å‡†åŒ–ä¸º 0-10ï¼‰
        signal_score = adv.get("signal_strength", 5.0)
        catalyst_score = adv.get("catalyst_score", 5.0)
        sentiment_score = adv.get("sentiment_score", 5.0)
        odds_score = adv.get("odds_score", 5.0)
        risk_score = adv.get("risk_adjusted_score", 5.0)

        # å®‰å…¨æå–æœŸæƒåˆ†æ•°
        if opts and isinstance(opts, dict):
            options_score = float(opts.get("options_score", 5.0))
            options_signal = opts.get("signal_summary", "ä¿¡å·å¹³è¡¡")
        else:
            options_score = 5.0
            options_signal = "æœŸæƒæ•°æ®ä¸å¯ç”¨"

        # è®¡ç®—ç»¼åˆ Opportunity Scoreï¼ˆä¸ CLAUDE.md 5 ç»´å…¬å¼ä¸€è‡´ï¼‰
        # options_score åˆå¹¶å…¥ odds ç»´åº¦ï¼ˆå–å¹³å‡ï¼‰
        odds_combined = (odds_score + options_score) / 2.0
        opp_score = (
            0.30 * signal_score +
            0.20 * catalyst_score +
            0.20 * sentiment_score +
            0.15 * odds_combined +
            0.15 * risk_score
        )

        # åˆ¤æ–­æ–¹å‘
        if opp_score >= 7.5:
            direction = "çœ‹å¤š" if signal_score > 5.0 else "çœ‹ç©º"
            confidence = min(95, opp_score * 10)
        elif opp_score >= 6.0:
            direction = "ä¸­æ€§"
            confidence = 60
        else:
            direction = "ä¸­æ€§"
            confidence = 30

        return OpportunityItem(
            ticker=ticker,
            direction=direction,
            signal_score=signal_score,
            catalyst_score=catalyst_score,
            sentiment_score=sentiment_score,
            odds_score=odds_score,
            risk_score=risk_score,
            options_score=options_score,
            opportunity_score=opp_score,
            confidence=confidence,
            key_catalysts=adv.get("upcoming_catalysts", [])[:3] if adv.get("upcoming_catalysts") else [],
            options_signal=options_signal,
            risks=adv.get("key_risks", [])[:2] if adv.get("key_risks") else [],
            thesis_break=adv.get("thesis_break_conditions", "æœªå®šä¹‰")
        )

    def _build_report(self) -> Dict:
        """æ„å»ºå®Œæ•´æŠ¥å‘Š"""

        report = {
            "date": self.date_str,
            "timestamp": self.timestamp.isoformat(),
            "system_status": "âœ… å®Œæˆ",
            "phase_completed": "1-6 (å®Œæ•´èœ‚ç¾¤æµç¨‹)",
            "markdown_report": self._generate_markdown_report(),
            "twitter_threads": self._generate_twitter_threads(),
            "opportunities": [
                {
                    "rank": i + 1,
                    "ticker": opp.ticker,
                    "direction": opp.direction,
                    "opp_score": round(opp.opportunity_score, 1),
                    "confidence": f"{opp.confidence:.0f}%",
                    "options_signal": opp.options_signal,
                    "key_catalyst": opp.key_catalysts[0] if opp.key_catalysts else "N/A",
                    "thesis_break": opp.thesis_break
                }
                for i, opp in enumerate(self.opportunities[:5])
            ],
            "observation_list": self.observations
        }

        return report

    def _generate_markdown_report(self) -> str:
        """ç”Ÿæˆä¸­æ–‡ Markdown æŠ¥å‘Š"""

        md = []
        md.append(f"# ã€{self.date_str}ã€‘Alpha Hive æ¯æ—¥æŠ•èµ„ç®€æŠ¥")
        md.append("")
        md.append(f"**è‡ªåŠ¨ç”Ÿæˆäº**ï¼š{self.timestamp.strftime('%Y-%m-%d %H:%M:%S')}")
        md.append(f"**ç³»ç»ŸçŠ¶æ€**ï¼šâœ… å®Œå…¨æ¿€æ´» | Phase 1-6 å®Œæˆ")
        md.append("")

        # 1. ä»Šæ—¥æ‘˜è¦
        md.append("## ğŸ“Š ä»Šæ—¥æ‘˜è¦ï¼ˆTop 3ï¼‰")
        md.append("")

        for i, opp in enumerate(self.opportunities[:3], 1):
            md.append(f"### {i}. **{opp.ticker}** - {opp.direction}")
            md.append(f"- **æœºä¼šåˆ†æ•°**ï¼š{opp.opportunity_score:.1f}/10 | **ç½®ä¿¡åº¦**ï¼š{opp.confidence:.0f}%")
            md.append(f"- **æœŸæƒä¿¡å·**ï¼š{opp.options_signal}")
            if opp.key_catalysts:
                md.append(f"- **å…³é”®å‚¬åŒ–å‰‚**ï¼š{', '.join(opp.key_catalysts[:2])}")
            md.append("")

        # 2. æœºä¼šæ¸…å•
        md.append("## ğŸ¯ å®Œæ•´æœºä¼šæ¸…å•")
        md.append("")
        md.append("| æ’åº | æ ‡çš„ | æ–¹å‘ | ç»¼åˆåˆ† | æœŸæƒä¿¡å· | ç½®ä¿¡åº¦ |")
        md.append("|------|------|------|--------|---------|--------|")

        for i, opp in enumerate(self.opportunities[:5], 1):
            md.append(
                f"| {i} | **{opp.ticker}** | {opp.direction} | "
                f"{opp.opportunity_score:.1f} | {opp.options_signal[:12]}... | {opp.confidence:.0f}% |"
            )

        md.append("")

        # 3. é£é™©é›·è¾¾
        md.append("## âš ï¸ é£é™©é›·è¾¾")
        md.append("")
        for opp in self.opportunities[:3]:
            if opp.risks:
                md.append(f"**{opp.ticker}**ï¼š{', '.join(opp.risks)}")

        md.append("")

        # 4. æ•°æ®æ¥æºä¸å…è´£
        md.append("## ğŸ“ æ•°æ®æ¥æº & å…è´£å£°æ˜")
        md.append("")
        md.append("**æ•°æ®æº**ï¼š")
        md.append("- StockTwits æƒ…ç»ªï¼ˆå®æ—¶ï¼‰")
        md.append("- Polymarket èµ”ç‡ï¼ˆæ¯5åˆ†é’Ÿï¼‰")
        md.append("- Yahoo Finance / yFinanceï¼ˆå®æ—¶ï¼‰")
        md.append("- SEC æŠ«éœ²ï¼ˆæ¯æ—¥æ›´æ–°ï¼‰")
        md.append("- **æœŸæƒé“¾æ•°æ®**ï¼ˆyFinanceï¼Œæ¯5åˆ†é’Ÿç¼“å­˜ï¼‰")
        md.append("")
        md.append("**å…è´£å£°æ˜**ï¼š")
        md.append(DISCLAIMER_FULL)
        md.append("")

        return "\n".join(md)

    def _generate_twitter_threads(self) -> List[str]:
        """ç”Ÿæˆ X çº¿ç¨‹ç‰ˆæœ¬"""

        threads = []

        # ä¸»çº¿ç¨‹
        main_thread = []
        main_thread.append(
            f"ã€Alpha Hive æ—¥æŠ¥ {self.date_str}ã€‘"
            f"{DISCLAIMER_SHORT}"
            f"ä»Šå¤©æœ€å€¼å¾—è·Ÿè¸ªçš„ 3 ä¸ªæœºä¼š ğŸ‘‡"
        )

        for i, opp in enumerate(self.opportunities[:3], 1):
            main_thread.append(
                f"{i}. **{opp.ticker}** {opp.direction}\n"
                f"ç»¼åˆåˆ†ï¼š{opp.opportunity_score:.1f}/10 | æœŸæƒä¿¡å·ï¼š{opp.options_signal}\n"
                f"ä¸»å‚¬åŒ–å‰‚ï¼š{opp.key_catalysts[0] if opp.key_catalysts else 'TBD'}"
            )

        main_thread.append(
            f"æ›´å¤šè¯¦æƒ…è§å®Œæ•´æ—¥æŠ¥ã€‚é£é™©æç¤ºï¼šé«˜æ³¢åŠ¨æ ‡çš„éœ€æ§åˆ¶ä»“ä½ã€‚"
            f"ä¸‹ä¸€æ­¥è·Ÿè¸ªï¼šT+1 éªŒè¯ä¿¡å·å¼ºåº¦ï¼ŒT+7 å›çœ‹é¢„æµ‹åå·®ã€‚@igg_wang748"
        )

        threads.append("\n\n".join(main_thread))

        return threads

    def auto_commit_and_notify(self, report: Dict) -> Dict:
        """
        è‡ªåŠ¨æäº¤æŠ¥å‘Šåˆ° Git + Slack é€šçŸ¥ï¼ˆAgent Toolbox æ¼”ç¤ºï¼‰

        æ–°åŠŸèƒ½ï¼šä½¿ç”¨ AgentHelper è‡ªåŠ¨æ‰§è¡Œ Git æäº¤å’Œé€šçŸ¥
        """
        _log.info("Auto-commit & Notify å¯åŠ¨")

        results = {}

        # 1. Git æäº¤æŠ¥å‘Š
        _log.info("Git commit...")
        status = self.agent_helper.git.status()
        if status.get("modified_files"):
            commit_result = self.agent_helper.git.commit(
                f"Alpha Hive èœ‚ç¾¤æ—¥æŠ¥ {self.date_str}"
            )
            results["git_commit"] = commit_result
            if commit_result["success"]:
                _log.info("Git commit æˆåŠŸ")
            else:
                _log.warning("Git commit å¤±è´¥ï¼š%s", commit_result.get('message'))
        else:
            _log.info("æ— éœ€æäº¤ï¼ˆå·¥ä½œç›®å½•å¹²å‡€ï¼‰")

        # 2. Git æ¨é€
        _log.info("Git push...")
        push_result = self.agent_helper.git.push("main")
        results["git_push"] = push_result
        if push_result["success"]:
            _log.info("Git push æˆåŠŸ")
        else:
            _log.warning("Git push å¤±è´¥")

        # 3. Slack é€šçŸ¥
        _log.info("å‘é€ Slack é€šçŸ¥...")
        top_opp = self.opportunities[0] if self.opportunities else None
        if top_opp:
            message = (
                f"ğŸ“Š *èœ‚ç¾¤æ—¥æŠ¥ {self.date_str}*\n"
                f"ğŸ¯ Top æœºä¼šï¼š{top_opp.ticker} {top_opp.direction}\n"
                f"ğŸ“ˆ ç»¼åˆåˆ†ï¼š{top_opp.opportunity_score:.1f}/10\n"
                f"ğŸ”— æŠ¥å‘Šï¼š`{self.report_dir / f'alpha-hive-daily-{self.date_str}.md'}`"
            )
            slack_result = self.agent_helper.notify.send_slack_message(
                "#alpha-hive",
                message
            )
            results["slack_notification"] = slack_result
            if slack_result.get("success"):
                _log.info("Slack é€šçŸ¥å·²å‘é€")
            else:
                _log.warning("Slack é€šçŸ¥å¤±è´¥ï¼š%s", slack_result.get('error'))

        _log.info("Auto-commit & Notify å®Œæˆ")
        return results

    def save_report(self, report: Dict) -> str:
        """ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶"""

        # ä¿å­˜ JSON ç‰ˆæœ¬
        json_file = self.report_dir / f"alpha-hive-daily-{self.date_str}.json"
        with open(json_file, "w", encoding="utf-8") as f:
            json.dump(report, f, ensure_ascii=False, indent=2)

        # ä¿å­˜ Markdown ç‰ˆæœ¬
        md_file = self.report_dir / f"alpha-hive-daily-{self.date_str}.md"
        with open(md_file, "w", encoding="utf-8") as f:
            f.write(report["markdown_report"])

        # ä¿å­˜ X çº¿ç¨‹ç‰ˆæœ¬
        for i, thread in enumerate(report["twitter_threads"], 1):
            thread_file = self.report_dir / f"alpha-hive-thread-{self.date_str}-{i}.txt"
            with open(thread_file, "w", encoding="utf-8") as f:
                f.write(thread)

        _log.info("æŠ¥å‘Šå·²ä¿å­˜ï¼š%s", md_file.name)

        return str(md_file)


def main():
    """ä¸»å…¥å£"""

    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(
        description="Alpha Hive æ¯æ—¥æŠ•èµ„ç®€æŠ¥ç”Ÿæˆå™¨",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•ï¼š
  # ä¼ ç»Ÿ ML æ¨¡å¼ï¼ˆé»˜è®¤ï¼‰
  python3 alpha_hive_daily_report.py
  python3 alpha_hive_daily_report.py --tickers NVDA TSLA VKTX
  python3 alpha_hive_daily_report.py --all-watchlist

  # èœ‚ç¾¤åä½œæ¨¡å¼ï¼ˆ6 ä¸ªè‡ªæ²» Agentï¼‰
  python3 alpha_hive_daily_report.py --swarm --tickers NVDA TSLA VKTX
  python3 alpha_hive_daily_report.py --swarm --all-watchlist
        """
    )
    parser.add_argument(
        '--tickers',
        nargs='+',
        default=["NVDA", "TSLA", "VKTX"],
        help='è¦æ‰«æçš„è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼ˆç©ºæ ¼åˆ†éš”ï¼Œé»˜è®¤ï¼šNVDA TSLA VKTXï¼‰'
    )
    parser.add_argument(
        '--all-watchlist',
        action='store_true',
        help='æ‰«æé…ç½®ä¸­çš„å…¨éƒ¨ç›‘æ§åˆ—è¡¨'
    )
    parser.add_argument(
        '--swarm',
        action='store_true',
        help='å¯ç”¨èœ‚ç¾¤åä½œæ¨¡å¼ï¼ˆ6 ä¸ªè‡ªæ²» Agent å¹¶è¡Œåˆ†æï¼‰'
    )

    args = parser.parse_args()

    # åˆ›å»ºæŠ¥å‘Šç”Ÿæˆå™¨
    reporter = AlphaHiveDailyReporter()

    # ç¡®å®šæ‰«ææ ‡çš„
    focus_tickers = list(WATCHLIST.keys())[:10] if args.all_watchlist else args.tickers

    if args.swarm:
        report = reporter.run_swarm_scan(focus_tickers=focus_tickers)
    else:
        report = reporter.run_daily_scan(focus_tickers=focus_tickers)

    # ä¿å­˜æŠ¥å‘Š
    report_path = reporter.save_report(report)

    _log.info("å®Œæˆï¼æŠ¥å‘Šï¼š%s", report_path)

    return report


if __name__ == "__main__":
    main()
