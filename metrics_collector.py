#!/usr/bin/env python3
"""
ğŸ“Š Alpha Hive æ€§èƒ½ç›‘æ§ç³»ç»Ÿ (Week 2)
è®°å½•æ¯æ¬¡è¿è¡Œçš„æ€§èƒ½æŒ‡æ ‡åˆ° SQLite æ—¶åºæ•°æ®åº“
"""

import json
import sqlite3
import argparse
import os
import sys
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional
import traceback

# å¯¼å…¥é…ç½®
sys.path.insert(0, str(Path(__file__).parent))
try:
    from config import METRICS_CONFIG
except ImportError:
    METRICS_CONFIG = {
        "enabled": True,
        "db_path": "/Users/igg/.claude/reports/metrics.db",
        "retention_days": 90,
    }


class MetricsCollector:
    """æ€§èƒ½æŒ‡æ ‡æ”¶é›†å™¨"""

    def __init__(self, db_path: str = None):
        """
        åˆå§‹åŒ–æŒ‡æ ‡æ”¶é›†å™¨

        Args:
            db_path: SQLite æ•°æ®åº“è·¯å¾„
        """
        self.db_path = db_path or METRICS_CONFIG["db_path"]
        self.retention_days = METRICS_CONFIG.get("retention_days", 90)
        self._init_db()

    def _init_db(self):
        """åˆå§‹åŒ–æ•°æ®åº“å’Œè¡¨"""
        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)

        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            # åˆ›å»º run_metrics è¡¨
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS run_metrics (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    run_id TEXT UNIQUE,
                    date TEXT,
                    timestamp TEXT,
                    tickers TEXT,
                    status TEXT,
                    total_duration_seconds REAL,
                    step1_duration REAL,
                    step2_duration REAL,
                    step3_duration REAL,
                    step4_duration REAL,
                    step5_duration REAL,
                    step6_duration REAL,
                    step7_duration REAL,
                    step1_status TEXT,
                    step2_status TEXT,
                    step3_status TEXT,
                    step4_status TEXT,
                    step5_status TEXT,
                    step6_status TEXT,
                    step7_status TEXT,
                    report_quality_score REAL,
                    agent_count INTEGER,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)

            # åˆ›å»ºç´¢å¼•ä»¥åŠ å¿«æŸ¥è¯¢
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_date ON run_metrics(date)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_timestamp ON run_metrics(timestamp)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_status ON run_metrics(status)")

            conn.commit()
            conn.close()
            print(f"âœ… æ•°æ®åº“å·²åˆå§‹åŒ–ï¼š{self.db_path}")
        except Exception as e:
            print(f"âš ï¸ æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥ï¼š{str(e)}")
            traceback.print_exc()

    def record(self, status_json_path: str, agent_count: int = 10, report_quality_score: float = 7.0) -> bool:
        """
        è®°å½•ä¸€æ¬¡è¿è¡Œçš„æ€§èƒ½æŒ‡æ ‡

        Args:
            status_json_path: status.json æ–‡ä»¶è·¯å¾„
            agent_count: æœ¬æ¬¡è¿è¡Œçš„ Agent æ•°é‡
            report_quality_score: æŠ¥å‘Šè´¨é‡è¯„åˆ†ï¼ˆ0-10ï¼‰

        Returns:
            æ˜¯å¦æˆåŠŸè®°å½•
        """
        try:
            # è¯»å– status.json
            if not os.path.exists(status_json_path):
                print(f"âš ï¸ çŠ¶æ€æ–‡ä»¶ä¸å­˜åœ¨ï¼š{status_json_path}")
                return False

            with open(status_json_path, "r") as f:
                status_data = json.load(f)

            # è§£ææ•°æ®
            last_run_date = status_data.get("last_run_date", datetime.now().strftime("%Y-%m-%d"))
            last_run = status_data.get("last_run", datetime.now().isoformat())
            overall_status = status_data.get("status", "unknown")
            total_duration = status_data.get("total_duration_seconds", 0)
            steps_result = status_data.get("steps_result", {})
            tickers = status_data.get("tickers", [])

            # ç”Ÿæˆ run_id
            run_id = f"{last_run_date}_{int(datetime.fromisoformat(last_run.replace('Z', '+00:00')).timestamp())}"

            # æå–å„æ­¥éª¤çš„è€—æ—¶å’ŒçŠ¶æ€
            step_durations = {}
            step_statuses = {}
            for i in range(1, 8):
                step_key = f"step{i}_"
                step_data = {}
                for k, v in steps_result.items():
                    if k.startswith(step_key):
                        step_data = v
                        break

                step_durations[f"step{i}_duration"] = step_data.get("duration_seconds", 0.0)
                step_statuses[f"step{i}_status"] = step_data.get("status", "unknown")

            # æ’å…¥åˆ°æ•°æ®åº“
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            cursor.execute("""
                INSERT OR REPLACE INTO run_metrics (
                    run_id, date, timestamp, tickers, status, total_duration_seconds,
                    step1_duration, step2_duration, step3_duration, step4_duration,
                    step5_duration, step6_duration, step7_duration,
                    step1_status, step2_status, step3_status, step4_status,
                    step5_status, step6_status, step7_status,
                    report_quality_score, agent_count
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                run_id,
                last_run_date,
                last_run,
                json.dumps(tickers),
                overall_status,
                total_duration,
                step_durations.get("step1_duration", 0),
                step_durations.get("step2_duration", 0),
                step_durations.get("step3_duration", 0),
                step_durations.get("step4_duration", 0),
                step_durations.get("step5_duration", 0),
                step_durations.get("step6_duration", 0),
                step_durations.get("step7_duration", 0),
                step_statuses.get("step1_status", "unknown"),
                step_statuses.get("step2_status", "unknown"),
                step_statuses.get("step3_status", "unknown"),
                step_statuses.get("step4_status", "unknown"),
                step_statuses.get("step5_status", "unknown"),
                step_statuses.get("step6_status", "unknown"),
                step_statuses.get("step7_status", "unknown"),
                report_quality_score,
                agent_count,
            ))

            conn.commit()
            conn.close()

            print(f"âœ… æ€§èƒ½æŒ‡æ ‡å·²è®°å½•ï¼š{run_id}")
            print(f"   è€—æ—¶ï¼š{total_duration}s | çŠ¶æ€ï¼š{overall_status} | Agentsï¼š{agent_count} | æŠ¥å‘Šåˆ†ï¼š{report_quality_score}")
            return True

        except Exception as e:
            print(f"âŒ è®°å½•å¤±è´¥ï¼š{str(e)}")
            traceback.print_exc()
            return False

    def get_trend(self, days: int = 7) -> List[Dict]:
        """
        è·å–è¿‘ N å¤©çš„è¶‹åŠ¿æ•°æ®

        Args:
            days: å›æº¯å¤©æ•°

        Returns:
            è¶‹åŠ¿æ•°æ®åˆ—è¡¨
        """
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            start_date = (datetime.now() - timedelta(days=days)).strftime("%Y-%m-%d")

            cursor.execute("""
                SELECT date, AVG(total_duration_seconds) as avg_duration,
                       AVG(report_quality_score) as avg_quality,
                       COUNT(*) as run_count,
                       SUM(CASE WHEN status = 'success' THEN 1 ELSE 0 END) as success_count
                FROM run_metrics
                WHERE date >= ?
                GROUP BY date
                ORDER BY date DESC
            """, (start_date,))

            rows = cursor.fetchall()
            conn.close()

            trend = []
            for row in rows:
                trend.append({
                    "date": row[0],
                    "avg_duration_seconds": round(row[1], 2),
                    "avg_quality_score": round(row[2], 1),
                    "total_runs": row[3],
                    "successful_runs": row[4],
                    "success_rate": f"{(row[4] / row[3] * 100):.1f}%"
                })

            return trend

        except Exception as e:
            print(f"âš ï¸ è¶‹åŠ¿æŸ¥è¯¢å¤±è´¥ï¼š{str(e)}")
            return []

    def get_summary(self, days: int = 7) -> Dict:
        """
        è·å– N å¤©å†…çš„æ±‡æ€»ç»Ÿè®¡

        Args:
            days: å›æº¯å¤©æ•°

        Returns:
            æ±‡æ€»ç»Ÿè®¡æ•°æ®
        """
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            start_date = (datetime.now() - timedelta(days=days)).strftime("%Y-%m-%d")

            cursor.execute("""
                SELECT
                    COUNT(*) as total_runs,
                    SUM(CASE WHEN status = 'success' THEN 1 ELSE 0 END) as successful_runs,
                    AVG(total_duration_seconds) as avg_duration,
                    MAX(total_duration_seconds) as max_duration,
                    MIN(total_duration_seconds) as min_duration,
                    AVG(report_quality_score) as avg_quality,
                    AVG(agent_count) as avg_agent_count
                FROM run_metrics
                WHERE date >= ?
            """, (start_date,))

            row = cursor.fetchone()
            conn.close()

            if row and row[0] > 0:
                return {
                    "period_days": days,
                    "total_runs": row[0],
                    "successful_runs": row[1],
                    "success_rate": f"{(row[1] / row[0] * 100):.1f}%",
                    "avg_duration_seconds": round(row[2], 2),
                    "max_duration_seconds": round(row[3], 2) if row[3] else 0,
                    "min_duration_seconds": round(row[4], 2) if row[4] else 0,
                    "avg_quality_score": round(row[5], 1),
                    "avg_agent_count": round(row[6], 0)
                }
            else:
                return {
                    "period_days": days,
                    "total_runs": 0,
                    "message": "No data available"
                }

        except Exception as e:
            print(f"âš ï¸ æ±‡æ€»æŸ¥è¯¢å¤±è´¥ï¼š{str(e)}")
            return {"error": str(e)}

    def cleanup(self, retention_days: int = None) -> int:
        """
        æ¸…ç†æ—§æ•°æ®ï¼Œä»…ä¿ç•™æŒ‡å®šå¤©æ•°å†…çš„è®°å½•

        Args:
            retention_days: ä¿ç•™å¤©æ•°ï¼ˆé»˜è®¤ä½¿ç”¨é…ç½®å€¼ï¼‰

        Returns:
            åˆ é™¤çš„è®°å½•æ•°
        """
        retention_days = retention_days or self.retention_days

        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            cutoff_date = (datetime.now() - timedelta(days=retention_days)).strftime("%Y-%m-%d")

            cursor.execute("DELETE FROM run_metrics WHERE date < ?", (cutoff_date,))
            deleted_count = cursor.rowcount

            conn.commit()
            conn.close()

            if deleted_count > 0:
                print(f"âœ… æ¸…ç†å®Œæˆï¼šåˆ é™¤äº† {deleted_count} æ¡æ—§è®°å½•ï¼ˆ>{retention_days}å¤©ï¼‰")
            else:
                print(f"âœ… æ— éœ€æ¸…ç†ï¼ˆæ‰€æœ‰è®°å½•éƒ½åœ¨ {retention_days} å¤©å†…ï¼‰")

            return deleted_count

        except Exception as e:
            print(f"âš ï¸ æ¸…ç†å¤±è´¥ï¼š{str(e)}")
            return 0

    def print_summary(self, days: int = 7):
        """æ‰“å°æ±‡æ€»ä¿¡æ¯"""
        summary = self.get_summary(days)
        print("\n" + "=" * 70)
        print(f"ğŸ“Š æ€§èƒ½æŒ‡æ ‡ç»Ÿè®¡ï¼ˆæœ€è¿‘ {days} å¤©ï¼‰")
        print("=" * 70)
        for key, value in summary.items():
            print(f"  {key}: {value}")
        print("=" * 70 + "\n")


def main():
    """ä¸»å…¥å£"""
    parser = argparse.ArgumentParser(
        description="Alpha Hive æ€§èƒ½ç›‘æ§ç³»ç»Ÿ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•ï¼š
  # è®°å½•æœ¬æ¬¡è¿è¡Œçš„æ€§èƒ½æŒ‡æ ‡
  python3 metrics_collector.py --record --status-json /path/to/status.json

  # æŸ¥çœ‹è¿‘ 7 å¤©çš„è¶‹åŠ¿
  python3 metrics_collector.py --trend --days 7

  # æŸ¥çœ‹è¿‘ 30 å¤©çš„æ±‡æ€»ç»Ÿè®¡
  python3 metrics_collector.py --summary --days 30

  # æ¸…ç†è¶…è¿‡ 90 å¤©çš„æ•°æ®
  python3 metrics_collector.py --cleanup --retention-days 90
        """
    )

    parser.add_argument('--record', action='store_true', help='è®°å½•ä¸€æ¬¡è¿è¡Œçš„æ€§èƒ½æŒ‡æ ‡')
    parser.add_argument('--status-json', type=str, help='status.json æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--agent-count', type=int, default=10, help='æœ¬æ¬¡ Agent æ•°é‡')
    parser.add_argument('--quality-score', type=float, default=7.0, help='æŠ¥å‘Šè´¨é‡åˆ†ï¼ˆ0-10ï¼‰')

    parser.add_argument('--trend', action='store_true', help='æ˜¾ç¤ºæ€§èƒ½è¶‹åŠ¿')
    parser.add_argument('--summary', action='store_true', help='æ˜¾ç¤ºæ±‡æ€»ç»Ÿè®¡')
    parser.add_argument('--cleanup', action='store_true', help='æ¸…ç†æ—§æ•°æ®')
    parser.add_argument('--days', type=int, default=7, help='å›æº¯å¤©æ•°æˆ–ä¿ç•™å¤©æ•°')
    parser.add_argument('--retention-days', type=int, default=90, help='æ•°æ®ä¿ç•™å¤©æ•°')

    args = parser.parse_args()

    collector = MetricsCollector()

    # æ‰§è¡Œæ“ä½œ
    if args.record:
        if not args.status_json:
            print("âŒ --record éœ€è¦æŒ‡å®š --status-json")
            sys.exit(1)
        collector.record(args.status_json, args.agent_count, args.quality_score)

    elif args.trend:
        trend = collector.get_trend(args.days)
        print("\nğŸ“ˆ æ€§èƒ½è¶‹åŠ¿ï¼ˆæœ€è¿‘ {} å¤©ï¼‰".format(args.days))
        print("=" * 70)
        for item in trend:
            print(f"  ğŸ“… {item['date']}: å¹³å‡è€—æ—¶ {item['avg_duration_seconds']}s | "
                  f"è´¨é‡åˆ† {item['avg_quality_score']}/10 | "
                  f"æˆåŠŸç‡ {item['success_rate']} ({item['successful_runs']}/{item['total_runs']})")
        print("=" * 70 + "\n")

    elif args.summary:
        collector.print_summary(args.days)

    elif args.cleanup:
        collector.cleanup(args.retention_days)

    else:
        # é»˜è®¤æ˜¾ç¤ºæ±‡æ€»
        collector.print_summary(7)


if __name__ == "__main__":
    main()
